{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b75MRT8AOr-7"
      },
      "source": [
        "# **미니프로젝트 4차 1대1 문의 내용 유형 분류기**\n",
        "# 단계3 : Text classification\n",
        "\n",
        "### 문제 정의\n",
        "> 1:1 문의 내용 분류 문제<br>\n",
        "> 1. 문의 내용 분석\n",
        "> 2. 문의 내용 분류 모델 성능 평가\n",
        "### 학습 데이터\n",
        "> * 1:1 문의 내용 데이터 : train.csv\n",
        "\n",
        "### 변수 소개\n",
        "> * text : 문의 내용\n",
        "> * label : 문의 유형\n",
        "\n",
        "### References\n",
        "> * Machine Learning\n",
        ">> * [sklearn-tutorial](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)\n",
        "> * Deep Learning\n",
        ">> * [Google Tutorial](https://developers.google.com/machine-learning/guides/text-classification)\n",
        ">> * [Tensorflow Tutorial](https://www.tensorflow.org/tutorials/keras/text_classification)\n",
        ">> * [Keras-tutorial](https://keras.io/examples/nlp/text_classification_from_scratch/)\n",
        ">> * [BERT-tutorial](https://www.tensorflow.org/text/guide/bert_preprocessing_guide)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlRWJB2w6Ip6"
      },
      "source": [
        "## 1. 개발 환경 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygLFt7ExOr_D"
      },
      "source": [
        "### 1-1. 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZRi07u9Or_D",
        "outputId": "a78db4e6-8d0a-4fd6-a78f-e76c5707f611"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "     --------------------------------------- 19.4/19.4 MB 10.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (1.4.4)\n",
            "Requirement already satisfied: seaborn in c:\\users\\user\\anaconda3\\lib\\site-packages (0.11.2)\n",
            "Requirement already satisfied: gensim in c:\\users\\user\\anaconda3\\lib\\site-packages (4.1.2)\n",
            "Collecting wordcloud\n",
            "  Downloading wordcloud-1.8.2.2-cp39-cp39-win_amd64.whl (153 kB)\n",
            "     -------------------------------------- 153.1/153.1 kB 8.9 MB/s eta 0:00:00\n",
            "Collecting python-mecab-ko\n",
            "  Downloading python_mecab_ko-1.3.3-cp39-cp39-win_amd64.whl (810 kB)\n",
            "     ------------------------------------- 810.6/810.6 kB 10.3 MB/s eta 0:00:00\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.1-cp39-cp39-win_amd64.whl (345 kB)\n",
            "     ------------------------------------- 345.2/345.2 kB 10.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy>=1.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from konlpy) (1.21.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from seaborn) (3.5.2)\n",
            "Requirement already satisfied: scipy>=1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from seaborn) (1.9.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: pillow in c:\\users\\user\\anaconda3\\lib\\site-packages (from wordcloud) (9.2.0)\n",
            "Collecting python-mecab-ko-dic\n",
            "  Downloading python_mecab_ko_dic-2.1.1.post2-py3-none-any.whl (34.5 MB)\n",
            "     --------------------------------------- 34.5/34.5 MB 10.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (4.25.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.4.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py): started\n",
            "  Building wheel for wget (setup.py): finished with status 'done'\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=00ed3768fbc3a86b2a07c0e05f28548ea35996b72a35b8990f1767425a36143d\n",
            "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\04\\5f\\3e\\46cc37c5d698415694d83f607f833f83f0149e49b3af9d0f38\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, python-mecab-ko-dic, python-mecab-ko, JPype1, wordcloud, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0 python-mecab-ko-1.3.3 python-mecab-ko-dic-2.1.1.post2 wget-3.2 wordcloud-1.8.2.2\n"
          ]
        }
      ],
      "source": [
        "# 필요 라이브러리부터 설치할께요.\n",
        "! pip install konlpy pandas seaborn gensim wordcloud python-mecab-ko wget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHL6PI8VOr_G"
      },
      "source": [
        "### 1-2. 라이브러리 import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZUph5rJOOr_G"
      },
      "outputs": [],
      "source": [
        "from mecab import MeCab\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import wget,os\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import matplotlib.font_manager as fm\n",
        "import matplotlib.pyplot as plt\n",
        "#import tensorflow as tf\n",
        "import nltk\n",
        "import wget,os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgdWF9k4Or_H"
      },
      "source": [
        "### 1-3. 한글 글꼴 설정(Windows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvvDOexzOr_J"
      },
      "outputs": [],
      "source": [
        "# if not os.path.exists(\"malgun.ttf\"): \n",
        "#     wget.download(\"https://www.wfonts.com/download/data/2016/06/13/malgun-gothic/malgun.ttf\")\n",
        "# if 'malgun' not in fm.fontManager.findfont(\"Malgun Gothic\"):\n",
        "#     fm.fontManager.addfont(\"malgun.ttf\")\n",
        "# if plt.rcParams['font.family']!= [\"Malgun Gothic\"]:\n",
        "#     plt.rcParams['font.family']= [font for font in fm.fontManager.ttflist if 'malgun.ttf' in font.fname][-1].name\n",
        "# plt.rcParams['axes.unicode_minus'] = False #한글 폰트 사용시 마이너스 폰트 깨짐 해결\n",
        "# assert plt.rcParams['font.family'] == [\"Malgun Gothic\"], \"한글 폰트가 설정되지 않았습니다.\"\n",
        "# FONT_PATH = \"malgun.ttf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlNmAHejOr_K"
      },
      "outputs": [],
      "source": [
        "# !sudo apt-get install -y fonts-nanum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQWWsueGOr_K"
      },
      "source": [
        "### 1-4. 자바 경로 설정(Windows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Gn5Ob1vGOr_L"
      },
      "outputs": [],
      "source": [
        "os.environ['JAVA_HOME'] = \"C:\\Program Files\\jdk-20\" #\"C:\\Program Files\\Java\\jdk-20\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_LYfeoWOr_L"
      },
      "source": [
        "### 1-3. 한글 글꼴 설정(Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmSye627Or_M",
        "outputId": "925b37cf-941f-41cf-fc42-0053be895d9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-525\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 23 not upgraded.\n",
            "Need to get 9,599 kB of archives.\n",
            "After this operation, 29.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 fonts-nanum all 20180306-3 [9,599 kB]\n",
            "Fetched 9,599 kB in 1s (8,268 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 128293 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20180306-3_all.deb ...\n",
            "Unpacking fonts-nanum (20180306-3) ...\n",
            "Setting up fonts-nanum (20180306-3) ...\n",
            "Processing triggers for fontconfig (2.13.1-2ubuntu3) ...\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install -y fonts-nanum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28gtrmzwOr_M",
        "outputId": "c8f9f470-0c1a-45a0-d7d4-0e022f58bd66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NanumGothic\n"
          ]
        }
      ],
      "source": [
        "FONT_PATH = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "font_name = fm.FontProperties(fname=FONT_PATH, size=10).get_name()\n",
        "print(font_name)\n",
        "plt.rcParams['font.family']=font_name\n",
        "assert plt.rcParams['font.family'] == [font_name], \"한글 폰트가 설정되지 않았습니다.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3NGHWznOr_N"
      },
      "source": [
        "### 1-4. 구글드라이브 연결(Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC2iWEAlOr_N",
        "outputId": "7fe82016-c041-43fa-88c4-a3e423f9aa57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r0bi4YyOr_N"
      },
      "source": [
        "## 2. 전처리한 데이터 불러오기\n",
        "* 1, 2일차에 전처리한 데이터를 불러옵니다.\n",
        "* sparse data에 대해서는 scipy.sparse.load_npz 활용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\User\\\\Desktop\\\\에이블\\\\4월\\\\0407\\\\mp'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2LADJNo1Or_N"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('c:\\\\Users\\\\User\\\\Desktop\\\\에이블\\\\4월\\\\0407\\\\mp\\\\train.csv')\n",
        "test = pd.read_csv('c:\\\\Users\\\\User\\\\Desktop\\\\에이블\\\\4월\\\\0407\\\\mp\\\\test.csv')\n",
        "submission = pd.read_csv('c:\\\\Users\\\\User\\\\Desktop\\\\에이블\\\\4월\\\\0407\\\\mp\\\\random_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xHj-QdBkz-Vs"
      },
      "outputs": [],
      "source": [
        "label_dict = {\n",
        "    '코드1': 0,\n",
        "    '코드2': 0,\n",
        "    '웹': 1,\n",
        "    '이론': 2,\n",
        "    '시스템 운영': 3,\n",
        "    '원격': 4\n",
        "}\n",
        "\n",
        "train = train.replace({'label' : label_dict}).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "kvZMR00jz6cI"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# X_train, X_val, y_train, y_val = train_test_split(preprocessed_df['text'], preprocessed_df['label'], test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "J9wPfQ6qP6Nr"
      },
      "outputs": [],
      "source": [
        "import re \n",
        "\n",
        "def clean_text(texts): \n",
        "    corpus = [] \n",
        "    for i in range(0, len(texts)): \n",
        "\n",
        "        review = re.sub(r'[@%\\\\*=()/~#&\\+á?\\xc3\\xa1\\-\\|\\.\\:\\;\\!\\-\\,\\_\\~\\$\\'\\\"\\n\\>\\<]', '',texts[i]) #@%*=()/+ 와 같은 문장부호 제거 ]\\[\\은 예외처리\n",
        "        review = re.sub(r'\\d+','', review)#숫자 제거\n",
        "        review = texts[i].lower() #소문자 변환\n",
        "        review = re.sub(r'\\s+', ' ', review) #extra space 제거\n",
        "        review = re.sub(r'<[^>]+>','',review) #Html tags 제거\n",
        "        review = re.sub(r'\\s+', ' ', review) #spaces 제거\n",
        "        review = re.sub(r\"^\\s+\", '', review) #space from start 제거\n",
        "        review = re.sub(r'\\s+$', '', review) #space from the end 제거\n",
        "        review = re.sub(r'_', ' ', review) #space from the end 제거\n",
        "        corpus.append(review) \n",
        "        \n",
        "    return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "KieMQ8VrWDzs",
        "outputId": "65d7316e-5391-48b0-e39b-ece79eea4fab"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>self.convs1 = nn.ModuleList([nn.Conv2d(1, Co, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>현재 이미지를 여러개 업로드 하기 위해 자바스크립트로 동적으로 폼 여러개 생성하는데...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>glob.glob(PATH) 를 사용할 때 질문입니다.\\n\\nPATH에 [ ] 가 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tmpp = tmp.groupby(by = 'Addr1', as_index=Fals...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>filename = TEST_IMAGE + str(round(frame_sec)) ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3701</th>\n",
              "      <td>토큰화 이후 train val 를 분리하고 각 train set, val set에 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3702</th>\n",
              "      <td>올린 값들 중 최고점인 건가요? 아니면 최근에 올린 파일로 무조건 갱신인가요?\\n최...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3703</th>\n",
              "      <td>수업에서 cacoo랑 packet tracer를 배우는 이유가\\n\\n1. IT 인프...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3704</th>\n",
              "      <td>inplace =True 해도 값이 변경이 안되고 none으로 뜹니다. 혹시 원격지...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3705</th>\n",
              "      <td>상관관계는 그렇게 크지 않게 나오는데 p -value 값은 관련이 있게 나오는데 \\...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3706 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  label\n",
              "0     self.convs1 = nn.ModuleList([nn.Conv2d(1, Co, ...      0\n",
              "1     현재 이미지를 여러개 업로드 하기 위해 자바스크립트로 동적으로 폼 여러개 생성하는데...      1\n",
              "2     glob.glob(PATH) 를 사용할 때 질문입니다.\\n\\nPATH에 [ ] 가 ...      0\n",
              "3     tmpp = tmp.groupby(by = 'Addr1', as_index=Fals...      0\n",
              "4     filename = TEST_IMAGE + str(round(frame_sec)) ...      0\n",
              "...                                                 ...    ...\n",
              "3701  토큰화 이후 train val 를 분리하고 각 train set, val set에 ...      0\n",
              "3702  올린 값들 중 최고점인 건가요? 아니면 최근에 올린 파일로 무조건 갱신인가요?\\n최...      3\n",
              "3703  수업에서 cacoo랑 packet tracer를 배우는 이유가\\n\\n1. IT 인프...      2\n",
              "3704  inplace =True 해도 값이 변경이 안되고 none으로 뜹니다. 혹시 원격지...      4\n",
              "3705  상관관계는 그렇게 크지 않게 나오는데 p -value 값은 관련이 있게 나오는데 \\...      2\n",
              "\n",
              "[3706 rows x 2 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NqKBDmV9WNiR"
      },
      "outputs": [],
      "source": [
        "train['text'] = clean_text(train['text'])\n",
        "test['text'] = clean_text(test['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "cCLWNPDCWPcZ",
        "outputId": "6e9b2c0c-1b2c-4525-c1a6-06e6bcc4728b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>self.convs1 = nn.modulelist([nn.conv2d(1, co, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>현재 이미지를 여러개 업로드 하기 위해 자바스크립트로 동적으로 폼 여러개 생성하는데...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>glob.glob(path) 를 사용할 때 질문입니다. path에 [ ] 가 포함되...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tmpp = tmp.groupby(by = 'addr1', as index=fals...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>filename = test image + str(round(frame sec)) ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3701</th>\n",
              "      <td>토큰화 이후 train val 를 분리하고 각 train set, val set에 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3702</th>\n",
              "      <td>올린 값들 중 최고점인 건가요? 아니면 최근에 올린 파일로 무조건 갱신인가요? 최고...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3703</th>\n",
              "      <td>수업에서 cacoo랑 packet tracer를 배우는 이유가 1. it 인프라 구...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3704</th>\n",
              "      <td>inplace =true 해도 값이 변경이 안되고 none으로 뜹니다. 혹시 원격지...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3705</th>\n",
              "      <td>상관관계는 그렇게 크지 않게 나오는데 p -value 값은 관련이 있게 나오는데 이...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3706 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  label\n",
              "0     self.convs1 = nn.modulelist([nn.conv2d(1, co, ...      0\n",
              "1     현재 이미지를 여러개 업로드 하기 위해 자바스크립트로 동적으로 폼 여러개 생성하는데...      1\n",
              "2     glob.glob(path) 를 사용할 때 질문입니다. path에 [ ] 가 포함되...      0\n",
              "3     tmpp = tmp.groupby(by = 'addr1', as index=fals...      0\n",
              "4     filename = test image + str(round(frame sec)) ...      0\n",
              "...                                                 ...    ...\n",
              "3701  토큰화 이후 train val 를 분리하고 각 train set, val set에 ...      0\n",
              "3702  올린 값들 중 최고점인 건가요? 아니면 최근에 올린 파일로 무조건 갱신인가요? 최고...      3\n",
              "3703  수업에서 cacoo랑 packet tracer를 배우는 이유가 1. it 인프라 구...      2\n",
              "3704  inplace =true 해도 값이 변경이 안되고 none으로 뜹니다. 혹시 원격지...      4\n",
              "3705  상관관계는 그렇게 크지 않게 나오는데 p -value 값은 관련이 있게 나오는데 이...      2\n",
              "\n",
              "[3706 rows x 2 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "Rb-tIEfqP6LP"
      },
      "outputs": [],
      "source": [
        "# X_train = clean_text(X_train.values)\n",
        "# X_val = clean_text(X_val.values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxs4rUwZ1OaS",
        "outputId": "f2567268-f3e8-47ee-c732-3a0e3769b714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "한국어 형태소 분석 결과(어간 추출X) ==> ['오늘', '도', '열심히', '코딩', '을', '해볼까', '요', '?', '같이', '힘내서', '자연어', '처리', '고수', '가', '됩시다', '!', 'ㅎㅎ']\n",
            "한국어 형태소 분석 결과(어간 추출O) ==> ['오늘', '도', '열심히', '코딩', '을', '해보다', '요', '?', '같이', '힘내다', '자연어', '처리', '고수', '가', '되다', '!', 'ㅎㅎ']\n"
          ]
        }
      ],
      "source": [
        "from konlpy.tag import Okt \n",
        "\n",
        "han_sentence = \"오늘도 열심히 코딩을 해볼까요? 같이 힘내서 자연어 처리 고수가 됩시다! ㅎㅎ\"\n",
        "okt = Okt() # 인스턴스 할당\n",
        "print(\"한국어 형태소 분석 결과(어간 추출X) ==>\", okt.morphs(han_sentence, stem = False)) # 형태소 단위로 분리\n",
        "print(\"한국어 형태소 분석 결과(어간 추출O) ==>\", okt.morphs(han_sentence, stem = True)) # 형태소 단위로 분리 후 어간 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "! conda install -c conda-forge jpype1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PMRPBln81QJm"
      },
      "outputs": [],
      "source": [
        "tokenized = [] # 데이터프레임의 한 컬럼으로 추가할 리스트\n",
        "for sentence in train['text']: # 전처리된 리뷰들을 하나씩 꺼내옵니다\n",
        "    tokens = okt.morphs(sentence, stem = True) # 형태소 분석 (stem = True로 설정해 어간 추출을 해주었습니다)\n",
        "    tokenize = \" \".join(tokens) # tokens라는 리스트 안의 형태소들을 띄어쓰기로 분리된 하나의 문자열로 join시켜줍니다.\n",
        "    tokenized.append(tokenize) # 형태소 단위로 띄어쓰기된 문자열을 최종 리스트에 추가해줍니다\n",
        "X_train = pd.DataFrame(tokenized) # 리스트를 데이터프레임으로 변환해 tokenized_stem라는 컬럼명으로 추가해줍니다.\n",
        "X_train = X_train[0]\n",
        "#train.head() # 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "upOXE_zH1zEx"
      },
      "outputs": [],
      "source": [
        "tokenized = [] # 데이터프레임의 한 컬럼으로 추가할 리스트\n",
        "for sentence in test['text']: # 전처리된 리뷰들을 하나씩 꺼내옵니다\n",
        "    tokens = okt.morphs(sentence, stem = True) # 형태소 분석 (stem = True로 설정해 어간 추출을 해주었습니다)\n",
        "    tokenize = \" \".join(tokens) # tokens라는 리스트 안의 형태소들을 띄어쓰기로 분리된 하나의 문자열로 join시켜줍니다.\n",
        "    tokenized.append(tokenize) # 형태소 단위로 띄어쓰기된 문자열을 최종 리스트에 추가해줍니다\n",
        "X_test = pd.DataFrame(tokenized) # 리스트를 데이터프레임으로 변환해 tokenized_stem라는 컬럼명으로 추가해줍니다.\n",
        "X_test = X_test[0]\n",
        "#train.head() # 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "up6IL2zmWcOC"
      },
      "outputs": [],
      "source": [
        "# X = X_train.copy()\n",
        "y_train = train['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfGauIy9Or_O"
      },
      "source": [
        "## 3. Machine Learning(N-grams)\n",
        "* N-gram으로 전처리한 데이터를 이용하여 3개 이상의 Machine Learning 모델 학습 및 성능 분석\n",
        "> * [sklearn-tutorial](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTFRqObO0hE4",
        "outputId": "1b83c423-1da2-4e35-ff94-cc6f435f616d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25892\\1219035492.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# TF-IDF Vectorization 적용하여 학습 데이터셋과 테스트 데이터 셋 변환.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtfidf_vect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mmin_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'char'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msublinear_tf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtfidf_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mX_train_tfidf_vect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# TF-IDF Vectorization 적용하여 학습 데이터셋과 테스트 데이터 셋 변환. \n",
        "tfidf_vect = TfidfVectorizer(ngram_range=(1,4),  min_df = 1, max_df=500, analyzer = 'char', sublinear_tf = False)\n",
        "tfidf_vect.fit(X_train)\n",
        "\n",
        "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
        "X_test_tfidf_vect = tfidf_vect.transform(X_test) # train셋으로 fit한 벡터라이저 이용해 transform\n",
        "print('학습 & 테스트 데이터 Text의 TfidfVectorizer Shape:',X_train_tfidf_vect.shape, X_test_tfidf_vect.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcmM9fTXOr_O"
      },
      "source": [
        "### 3-1. Model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sj2cpjEHgs_u",
        "outputId": "fa0a04dc-4d83-4840-ea9f-0f6ec3f4d2e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<3706x8883 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 82541 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_tfidf_vect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "qE8dthvzgaki"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "#X_train_tfidf_vect = pd.DataFrame(X_train_tfidf_vect)\n",
        "X_resample, y_resampled = SMOTE().fit_resample(X_train_tfidf_vect, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbFjfzDkhCJe",
        "outputId": "0afca059-8060-40b9-d235-ad202a3bae68"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X_resample' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7128\\520639679.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mlr_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'liblinear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# 성능 지표는 정확도(accuracy) , 교차 검증 세트는 5개\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_clf\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mX_resample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'교차 검증별 정확도:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'X_resample' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression #모델 불러오기\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "# LogisticRegression을 이용하여 학습/예측/평가 수행. \n",
        "lr_clf = LogisticRegression(solver='liblinear', C = 10) \n",
        "# 성능 지표는 정확도(accuracy) , 교차 검증 세트는 5개 \n",
        "scores = cross_val_score(lr_clf , X_resample, y_resampled, scoring='accuracy',cv=5)\n",
        "\n",
        "print('교차 검증별 정확도:',np.round(scores, 4))\n",
        "print('평균 검증 정확도:', np.round(np.mean(scores),4))\n",
        "\n",
        "#print('TF-IDF Logistic Regression 의 예측 정확도는 {0:.3f}'.format(metrics.accuracy_score(y_val ,pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "OooficNLhIHE"
      },
      "outputs": [],
      "source": [
        "lr_clf.fit(X_resample , y_resampled)\n",
        "pred = lr_clf.predict(X_test_tfidf_vect)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "6koSKTI-hJDM"
      },
      "outputs": [],
      "source": [
        "submission['label'] = pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4TZEQFEbhQns",
        "outputId": "d07e9e35-3313-4c79-9201-5240bacc6572"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fdeddd47-39c0-4e8e-9685-802200d62c18\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdeddd47-39c0-4e8e-9685-802200d62c18')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fdeddd47-39c0-4e8e-9685-802200d62c18 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fdeddd47-39c0-4e8e-9685-802200d62c18');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id  label\n",
              "0   0      3\n",
              "1   1      3\n",
              "2   2      0\n",
              "3   3      0\n",
              "4   4      1"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "g6TWB2i1hLS_"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('world_submission_2.csv', index = False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "awZU8uJyhjQN"
      },
      "source": [
        "### 3-1. Model 1-2 (제출)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcOZn1veOr_O",
        "outputId": "45fcc72a-03ec-412d-c339-a5dd243d11ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "교차 검증별 정확도: [0.8518 0.8394 0.8367 0.8543 0.8367]\n",
            "평균 검증 정확도: 0.8438\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression #모델 불러오기\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "# LogisticRegression을 이용하여 학습/예측/평가 수행. \n",
        "lr_clf = LogisticRegression(solver='liblinear', C = 10, penalty = 'l2', max_iter = 500) \n",
        "# 성능 지표는 정확도(accuracy) , 교차 검증 세트는 5개 \n",
        "scores = cross_val_score(lr_clf , X_train_tfidf_vect, y_train, scoring='accuracy',cv=5)\n",
        "\n",
        "print('교차 검증별 정확도:',np.round(scores, 4))\n",
        "print('평균 검증 정확도:', np.round(np.mean(scores),4))\n",
        "\n",
        "#print('TF-IDF Logistic Regression 의 예측 정확도는 {0:.3f}'.format(metrics.accuracy_score(y_val ,pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "BGEMSQbeXPUd"
      },
      "outputs": [],
      "source": [
        "lr_clf.fit(X_train_tfidf_vect , y_train)\n",
        "pred = lr_clf.predict(X_test_tfidf_vect)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "my-fLdqObnqo"
      },
      "outputs": [],
      "source": [
        "submission['label'] = pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "KLFJj5Sjbr-h",
        "outputId": "e098309e-302d-4118-90b4-bf2ddc43b686"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>924</th>\n",
              "      <td>924</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>925</th>\n",
              "      <td>925</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>926</th>\n",
              "      <td>926</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>927</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>928</th>\n",
              "      <td>928</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>929 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  label\n",
              "0      0      3\n",
              "1      1      3\n",
              "2      2      0\n",
              "3      3      0\n",
              "4      4      0\n",
              "..   ...    ...\n",
              "924  924      3\n",
              "925  925      0\n",
              "926  926      3\n",
              "927  927      1\n",
              "928  928      0\n",
              "\n",
              "[929 rows x 2 columns]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "QQWJ0EcOcbxA"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('world_submission_4.csv', index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcWiPXipoYIL"
      },
      "source": [
        "### Model 1-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {
        "id": "pLxOE6tDoa-2"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "## 하이퍼파라미터 튜닝용 함수\n",
        "def logistic_tuning(train_sprs, y, params):\n",
        "    model = LogisticRegression(random_state = 99) # 파라미터 튜닝(train data 전체를 넣어서 5-fold cv)\n",
        "    grid = GridSearchCV(model, params, scoring ='roc_auc', cv = 5)\n",
        "    grid.fit(train_sprs, y)\n",
        "\n",
        "    print(grid.best_params_)\n",
        "    print(grid.best_score_)\n",
        "\n",
        "    return grid.best_estimator_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAb0wKSlotWy"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "param1 = {'penalty':['l2', 'l1'], 'C':[0.01, 0.1, 1, 5, 10], 'max_iter': [100, 500]}\n",
        "logistic_tuning(X_train_tfidf_vect, y_train,  params = param1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bfj9QkXJOr_O"
      },
      "source": [
        "### 3-2. Model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNuxI8u7fTCw",
        "outputId": "5d0e44f5-43c7-4c16-d3d3-134f96edc86b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.1653005464480874"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train['label'].value_counts()[0] / train['label'].value_counts()[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMfYA2U3fQD2"
      },
      "outputs": [],
      "source": [
        "# xgboost 학습 파라미터\n",
        "scale_pos_weight = train_df['Class'].value_counts()[0] / train_df['Class'].value_counts()[1]\n",
        "print(scale_pos_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jnuf4O15Or_O",
        "outputId": "c37104e6-376a-465b-ec46-746dd4892514"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "교차 검증별 정확도: [0.7992 0.7881 0.7935 0.7935 0.7841]\n",
            "평균 검증 정확도: 0.7917\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb \n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "xg = xgb.XGBClassifier()\n",
        "\n",
        "# 성능 지표는 정확도(accuracy) , 교차 검증 세트는 5개 \n",
        "scores = cross_val_score(xg , X_train_tfidf_vect, y_train, scoring='accuracy',cv=5)\n",
        "\n",
        "print('교차 검증별 정확도:',np.round(scores, 4))\n",
        "print('평균 검증 정확도:', np.round(np.mean(scores),4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWV_BW-COr_P"
      },
      "source": [
        "### 3-3. Model 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlkqqikvX0O9",
        "outputId": "df005bef-630e-4db6-cb02-8db2fcf37daa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in c:\\users\\user\\anaconda3\\lib\\site-packages (1.1.1)\n",
            "Requirement already satisfied: graphviz in c:\\users\\user\\anaconda3\\lib\\site-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from catboost) (1.4.4)\n",
            "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from catboost) (1.21.5)\n",
            "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from catboost) (1.9.1)\n",
            "Requirement already satisfied: plotly in c:\\users\\user\\anaconda3\\lib\\site-packages (from catboost) (5.9.0)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from catboost) (3.5.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (21.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (9.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DSElZ0SlX6yJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# 불균형한 클래스인 것으로 확인되어 class_weight = 'balanced'로 설정해준다. \n",
        "classes = np.unique(y_train)\n",
        "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "class_weights = dict(zip(classes, weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "1CTkZ8y9Or_P",
        "outputId": "05c2e732-5e1a-4ad1-a4d9-2f0431bd0f37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rate set to 0.081655\n",
            "0:\tlearn: 1.5324484\ttotal: 258ms\tremaining: 4m 17s\n",
            "1:\tlearn: 1.4824278\ttotal: 451ms\tremaining: 3m 45s\n",
            "2:\tlearn: 1.4325725\ttotal: 623ms\tremaining: 3m 27s\n",
            "3:\tlearn: 1.3851768\ttotal: 793ms\tremaining: 3m 17s\n",
            "4:\tlearn: 1.3599460\ttotal: 961ms\tremaining: 3m 11s\n",
            "5:\tlearn: 1.3262484\ttotal: 1.28s\tremaining: 3m 32s\n",
            "6:\tlearn: 1.3043470\ttotal: 1.47s\tremaining: 3m 29s\n",
            "7:\tlearn: 1.2916342\ttotal: 1.67s\tremaining: 3m 26s\n",
            "8:\tlearn: 1.2712087\ttotal: 1.98s\tremaining: 3m 37s\n",
            "9:\tlearn: 1.2497579\ttotal: 2.2s\tremaining: 3m 38s\n",
            "10:\tlearn: 1.2322129\ttotal: 2.42s\tremaining: 3m 37s\n",
            "11:\tlearn: 1.2192273\ttotal: 2.62s\tremaining: 3m 35s\n",
            "12:\tlearn: 1.2007566\ttotal: 2.83s\tremaining: 3m 34s\n",
            "13:\tlearn: 1.1892686\ttotal: 2.98s\tremaining: 3m 29s\n",
            "14:\tlearn: 1.1742389\ttotal: 3.13s\tremaining: 3m 25s\n",
            "15:\tlearn: 1.1629466\ttotal: 3.29s\tremaining: 3m 22s\n",
            "16:\tlearn: 1.1499170\ttotal: 3.44s\tremaining: 3m 18s\n",
            "17:\tlearn: 1.1352493\ttotal: 3.64s\tremaining: 3m 18s\n",
            "18:\tlearn: 1.1237722\ttotal: 3.83s\tremaining: 3m 17s\n",
            "19:\tlearn: 1.1114293\ttotal: 3.99s\tremaining: 3m 15s\n",
            "20:\tlearn: 1.1043444\ttotal: 4.14s\tremaining: 3m 12s\n",
            "21:\tlearn: 1.0966918\ttotal: 4.29s\tremaining: 3m 10s\n",
            "22:\tlearn: 1.0906946\ttotal: 4.49s\tremaining: 3m 10s\n",
            "23:\tlearn: 1.0823305\ttotal: 4.66s\tremaining: 3m 9s\n",
            "24:\tlearn: 1.0766229\ttotal: 4.81s\tremaining: 3m 7s\n",
            "25:\tlearn: 1.0667765\ttotal: 4.96s\tremaining: 3m 5s\n",
            "26:\tlearn: 1.0578157\ttotal: 5.11s\tremaining: 3m 4s\n",
            "27:\tlearn: 1.0517260\ttotal: 5.26s\tremaining: 3m 2s\n",
            "28:\tlearn: 1.0399542\ttotal: 5.42s\tremaining: 3m 1s\n",
            "29:\tlearn: 1.0341610\ttotal: 5.58s\tremaining: 3m\n",
            "30:\tlearn: 1.0281857\ttotal: 5.73s\tremaining: 2m 59s\n",
            "31:\tlearn: 1.0220657\ttotal: 5.88s\tremaining: 2m 57s\n",
            "32:\tlearn: 1.0176957\ttotal: 6.04s\tremaining: 2m 56s\n",
            "33:\tlearn: 1.0130348\ttotal: 6.21s\tremaining: 2m 56s\n",
            "34:\tlearn: 1.0079258\ttotal: 6.38s\tremaining: 2m 55s\n",
            "35:\tlearn: 1.0034139\ttotal: 6.53s\tremaining: 2m 54s\n",
            "36:\tlearn: 0.9970728\ttotal: 6.66s\tremaining: 2m 53s\n",
            "37:\tlearn: 0.9934319\ttotal: 6.8s\tremaining: 2m 52s\n",
            "38:\tlearn: 0.9840255\ttotal: 6.94s\tremaining: 2m 50s\n",
            "39:\tlearn: 0.9793253\ttotal: 7.08s\tremaining: 2m 49s\n",
            "40:\tlearn: 0.9745584\ttotal: 7.28s\tremaining: 2m 50s\n",
            "41:\tlearn: 0.9701588\ttotal: 7.46s\tremaining: 2m 50s\n",
            "42:\tlearn: 0.9660025\ttotal: 7.63s\tremaining: 2m 49s\n",
            "43:\tlearn: 0.9621951\ttotal: 7.8s\tremaining: 2m 49s\n",
            "44:\tlearn: 0.9578207\ttotal: 8.02s\tremaining: 2m 50s\n",
            "45:\tlearn: 0.9532477\ttotal: 8.22s\tremaining: 2m 50s\n",
            "46:\tlearn: 0.9495847\ttotal: 8.39s\tremaining: 2m 50s\n",
            "47:\tlearn: 0.9457515\ttotal: 8.53s\tremaining: 2m 49s\n",
            "48:\tlearn: 0.9402516\ttotal: 8.7s\tremaining: 2m 48s\n",
            "49:\tlearn: 0.9365508\ttotal: 8.88s\tremaining: 2m 48s\n",
            "50:\tlearn: 0.9310016\ttotal: 9.11s\tremaining: 2m 49s\n",
            "51:\tlearn: 0.9264785\ttotal: 9.29s\tremaining: 2m 49s\n",
            "52:\tlearn: 0.9225562\ttotal: 9.46s\tremaining: 2m 49s\n",
            "53:\tlearn: 0.9191420\ttotal: 9.62s\tremaining: 2m 48s\n",
            "54:\tlearn: 0.9155005\ttotal: 9.76s\tremaining: 2m 47s\n",
            "55:\tlearn: 0.9121528\ttotal: 9.94s\tremaining: 2m 47s\n",
            "56:\tlearn: 0.9090268\ttotal: 10.2s\tremaining: 2m 48s\n",
            "57:\tlearn: 0.9060049\ttotal: 10.3s\tremaining: 2m 47s\n",
            "58:\tlearn: 0.9027045\ttotal: 10.5s\tremaining: 2m 47s\n",
            "59:\tlearn: 0.8991395\ttotal: 10.6s\tremaining: 2m 46s\n",
            "60:\tlearn: 0.8947971\ttotal: 10.8s\tremaining: 2m 46s\n",
            "61:\tlearn: 0.8912567\ttotal: 11s\tremaining: 2m 45s\n",
            "62:\tlearn: 0.8882868\ttotal: 11.2s\tremaining: 2m 45s\n",
            "63:\tlearn: 0.8853583\ttotal: 11.3s\tremaining: 2m 45s\n",
            "64:\tlearn: 0.8811504\ttotal: 11.5s\tremaining: 2m 44s\n",
            "65:\tlearn: 0.8780532\ttotal: 11.6s\tremaining: 2m 44s\n",
            "66:\tlearn: 0.8751359\ttotal: 11.7s\tremaining: 2m 43s\n",
            "67:\tlearn: 0.8699930\ttotal: 11.9s\tremaining: 2m 43s\n",
            "68:\tlearn: 0.8672106\ttotal: 12.1s\tremaining: 2m 43s\n",
            "69:\tlearn: 0.8632326\ttotal: 12.3s\tremaining: 2m 43s\n",
            "70:\tlearn: 0.8597455\ttotal: 12.4s\tremaining: 2m 42s\n",
            "71:\tlearn: 0.8566460\ttotal: 12.6s\tremaining: 2m 42s\n",
            "72:\tlearn: 0.8527927\ttotal: 12.7s\tremaining: 2m 41s\n",
            "73:\tlearn: 0.8506483\ttotal: 12.9s\tremaining: 2m 41s\n",
            "74:\tlearn: 0.8479537\ttotal: 13.1s\tremaining: 2m 41s\n",
            "75:\tlearn: 0.8450377\ttotal: 13.3s\tremaining: 2m 41s\n",
            "76:\tlearn: 0.8417185\ttotal: 13.4s\tremaining: 2m 40s\n",
            "77:\tlearn: 0.8390511\ttotal: 13.5s\tremaining: 2m 40s\n",
            "78:\tlearn: 0.8364391\ttotal: 13.7s\tremaining: 2m 39s\n",
            "79:\tlearn: 0.8345801\ttotal: 13.8s\tremaining: 2m 39s\n",
            "80:\tlearn: 0.8301919\ttotal: 14s\tremaining: 2m 39s\n",
            "81:\tlearn: 0.8272787\ttotal: 14.2s\tremaining: 2m 39s\n",
            "82:\tlearn: 0.8226602\ttotal: 14.4s\tremaining: 2m 39s\n",
            "83:\tlearn: 0.8189818\ttotal: 14.6s\tremaining: 2m 39s\n",
            "84:\tlearn: 0.8164462\ttotal: 14.8s\tremaining: 2m 39s\n",
            "85:\tlearn: 0.8136795\ttotal: 15s\tremaining: 2m 39s\n",
            "86:\tlearn: 0.8096717\ttotal: 15.1s\tremaining: 2m 38s\n",
            "87:\tlearn: 0.8066513\ttotal: 15.3s\tremaining: 2m 38s\n",
            "88:\tlearn: 0.7998819\ttotal: 15.5s\tremaining: 2m 38s\n",
            "89:\tlearn: 0.7972407\ttotal: 15.6s\tremaining: 2m 38s\n",
            "90:\tlearn: 0.7952527\ttotal: 15.8s\tremaining: 2m 38s\n",
            "91:\tlearn: 0.7919226\ttotal: 16s\tremaining: 2m 37s\n",
            "92:\tlearn: 0.7891667\ttotal: 16.2s\tremaining: 2m 37s\n",
            "93:\tlearn: 0.7869058\ttotal: 16.3s\tremaining: 2m 37s\n",
            "94:\tlearn: 0.7846031\ttotal: 16.5s\tremaining: 2m 36s\n",
            "95:\tlearn: 0.7822984\ttotal: 16.6s\tremaining: 2m 36s\n",
            "96:\tlearn: 0.7795209\ttotal: 16.8s\tremaining: 2m 36s\n",
            "97:\tlearn: 0.7765360\ttotal: 16.9s\tremaining: 2m 35s\n",
            "98:\tlearn: 0.7727831\ttotal: 17.1s\tremaining: 2m 35s\n",
            "99:\tlearn: 0.7688510\ttotal: 17.2s\tremaining: 2m 34s\n",
            "100:\tlearn: 0.7664912\ttotal: 17.3s\tremaining: 2m 34s\n",
            "101:\tlearn: 0.7637471\ttotal: 17.5s\tremaining: 2m 33s\n",
            "102:\tlearn: 0.7616118\ttotal: 17.7s\tremaining: 2m 33s\n",
            "103:\tlearn: 0.7580362\ttotal: 17.9s\tremaining: 2m 33s\n",
            "104:\tlearn: 0.7555152\ttotal: 18s\tremaining: 2m 33s\n",
            "105:\tlearn: 0.7524017\ttotal: 18.2s\tremaining: 2m 33s\n",
            "106:\tlearn: 0.7499739\ttotal: 18.3s\tremaining: 2m 33s\n",
            "107:\tlearn: 0.7473479\ttotal: 18.5s\tremaining: 2m 32s\n",
            "108:\tlearn: 0.7451421\ttotal: 18.7s\tremaining: 2m 32s\n",
            "109:\tlearn: 0.7427960\ttotal: 18.9s\tremaining: 2m 32s\n",
            "110:\tlearn: 0.7405100\ttotal: 19s\tremaining: 2m 32s\n",
            "111:\tlearn: 0.7388263\ttotal: 19.1s\tremaining: 2m 31s\n",
            "112:\tlearn: 0.7359571\ttotal: 19.3s\tremaining: 2m 31s\n",
            "113:\tlearn: 0.7316712\ttotal: 19.4s\tremaining: 2m 30s\n",
            "114:\tlearn: 0.7280871\ttotal: 19.6s\tremaining: 2m 30s\n",
            "115:\tlearn: 0.7261427\ttotal: 19.7s\tremaining: 2m 30s\n",
            "116:\tlearn: 0.7242596\ttotal: 19.9s\tremaining: 2m 29s\n",
            "117:\tlearn: 0.7220497\ttotal: 20s\tremaining: 2m 29s\n",
            "118:\tlearn: 0.7188020\ttotal: 20.2s\tremaining: 2m 29s\n",
            "119:\tlearn: 0.7141946\ttotal: 20.3s\tremaining: 2m 28s\n",
            "120:\tlearn: 0.7122913\ttotal: 20.5s\tremaining: 2m 28s\n",
            "121:\tlearn: 0.7092717\ttotal: 20.7s\tremaining: 2m 28s\n",
            "122:\tlearn: 0.7076128\ttotal: 20.9s\tremaining: 2m 28s\n",
            "123:\tlearn: 0.7055926\ttotal: 21s\tremaining: 2m 28s\n",
            "124:\tlearn: 0.7035253\ttotal: 21.2s\tremaining: 2m 28s\n",
            "125:\tlearn: 0.7005279\ttotal: 21.3s\tremaining: 2m 28s\n",
            "126:\tlearn: 0.6973783\ttotal: 21.5s\tremaining: 2m 27s\n",
            "127:\tlearn: 0.6960233\ttotal: 21.7s\tremaining: 2m 27s\n",
            "128:\tlearn: 0.6947841\ttotal: 21.9s\tremaining: 2m 27s\n",
            "129:\tlearn: 0.6930148\ttotal: 22s\tremaining: 2m 27s\n",
            "130:\tlearn: 0.6914039\ttotal: 22.2s\tremaining: 2m 26s\n",
            "131:\tlearn: 0.6895105\ttotal: 22.3s\tremaining: 2m 26s\n",
            "132:\tlearn: 0.6873127\ttotal: 22.5s\tremaining: 2m 26s\n",
            "133:\tlearn: 0.6848770\ttotal: 22.7s\tremaining: 2m 26s\n",
            "134:\tlearn: 0.6829728\ttotal: 22.9s\tremaining: 2m 26s\n",
            "135:\tlearn: 0.6807609\ttotal: 23s\tremaining: 2m 26s\n",
            "136:\tlearn: 0.6792873\ttotal: 23.2s\tremaining: 2m 26s\n",
            "137:\tlearn: 0.6773636\ttotal: 23.4s\tremaining: 2m 26s\n",
            "138:\tlearn: 0.6752755\ttotal: 23.6s\tremaining: 2m 26s\n",
            "139:\tlearn: 0.6723980\ttotal: 23.7s\tremaining: 2m 25s\n",
            "140:\tlearn: 0.6711296\ttotal: 23.9s\tremaining: 2m 25s\n",
            "141:\tlearn: 0.6697706\ttotal: 24s\tremaining: 2m 25s\n",
            "142:\tlearn: 0.6672342\ttotal: 24.2s\tremaining: 2m 24s\n",
            "143:\tlearn: 0.6651804\ttotal: 24.3s\tremaining: 2m 24s\n",
            "144:\tlearn: 0.6640341\ttotal: 24.5s\tremaining: 2m 24s\n",
            "145:\tlearn: 0.6622229\ttotal: 24.7s\tremaining: 2m 24s\n",
            "146:\tlearn: 0.6608944\ttotal: 24.8s\tremaining: 2m 23s\n",
            "147:\tlearn: 0.6592205\ttotal: 24.9s\tremaining: 2m 23s\n",
            "148:\tlearn: 0.6575127\ttotal: 25.1s\tremaining: 2m 23s\n",
            "149:\tlearn: 0.6554255\ttotal: 25.3s\tremaining: 2m 23s\n",
            "150:\tlearn: 0.6544585\ttotal: 25.5s\tremaining: 2m 23s\n",
            "151:\tlearn: 0.6528324\ttotal: 25.6s\tremaining: 2m 23s\n",
            "152:\tlearn: 0.6517175\ttotal: 25.8s\tremaining: 2m 22s\n",
            "153:\tlearn: 0.6503128\ttotal: 25.9s\tremaining: 2m 22s\n",
            "154:\tlearn: 0.6493860\ttotal: 26.1s\tremaining: 2m 22s\n",
            "155:\tlearn: 0.6456678\ttotal: 26.2s\tremaining: 2m 21s\n",
            "156:\tlearn: 0.6447393\ttotal: 26.4s\tremaining: 2m 21s\n",
            "157:\tlearn: 0.6439515\ttotal: 26.5s\tremaining: 2m 21s\n",
            "158:\tlearn: 0.6423725\ttotal: 26.7s\tremaining: 2m 21s\n",
            "159:\tlearn: 0.6405777\ttotal: 26.9s\tremaining: 2m 21s\n",
            "160:\tlearn: 0.6388482\ttotal: 27.1s\tremaining: 2m 21s\n",
            "161:\tlearn: 0.6360547\ttotal: 27.3s\tremaining: 2m 21s\n",
            "162:\tlearn: 0.6351825\ttotal: 27.5s\tremaining: 2m 21s\n",
            "163:\tlearn: 0.6338165\ttotal: 27.9s\tremaining: 2m 22s\n",
            "164:\tlearn: 0.6320656\ttotal: 28.3s\tremaining: 2m 23s\n",
            "165:\tlearn: 0.6305667\ttotal: 28.7s\tremaining: 2m 23s\n",
            "166:\tlearn: 0.6293748\ttotal: 29s\tremaining: 2m 24s\n",
            "167:\tlearn: 0.6284408\ttotal: 29.2s\tremaining: 2m 24s\n",
            "168:\tlearn: 0.6275777\ttotal: 29.3s\tremaining: 2m 24s\n",
            "169:\tlearn: 0.6249136\ttotal: 29.5s\tremaining: 2m 23s\n",
            "170:\tlearn: 0.6236521\ttotal: 29.7s\tremaining: 2m 24s\n",
            "171:\tlearn: 0.6215124\ttotal: 29.9s\tremaining: 2m 24s\n",
            "172:\tlearn: 0.6201561\ttotal: 30.1s\tremaining: 2m 23s\n",
            "173:\tlearn: 0.6183730\ttotal: 30.3s\tremaining: 2m 23s\n",
            "174:\tlearn: 0.6167420\ttotal: 30.5s\tremaining: 2m 23s\n",
            "175:\tlearn: 0.6156382\ttotal: 30.7s\tremaining: 2m 23s\n",
            "176:\tlearn: 0.6149087\ttotal: 30.9s\tremaining: 2m 23s\n",
            "177:\tlearn: 0.6134958\ttotal: 31.1s\tremaining: 2m 23s\n",
            "178:\tlearn: 0.6100471\ttotal: 31.2s\tremaining: 2m 23s\n",
            "179:\tlearn: 0.6091739\ttotal: 31.4s\tremaining: 2m 23s\n",
            "180:\tlearn: 0.6079753\ttotal: 31.7s\tremaining: 2m 23s\n",
            "181:\tlearn: 0.6072545\ttotal: 31.9s\tremaining: 2m 23s\n",
            "182:\tlearn: 0.6059520\ttotal: 32.1s\tremaining: 2m 23s\n",
            "183:\tlearn: 0.6042658\ttotal: 32.4s\tremaining: 2m 23s\n",
            "184:\tlearn: 0.6033944\ttotal: 32.6s\tremaining: 2m 23s\n",
            "185:\tlearn: 0.6021801\ttotal: 32.8s\tremaining: 2m 23s\n",
            "186:\tlearn: 0.6009596\ttotal: 33s\tremaining: 2m 23s\n",
            "187:\tlearn: 0.5997143\ttotal: 33.1s\tremaining: 2m 23s\n",
            "188:\tlearn: 0.5980026\ttotal: 33.3s\tremaining: 2m 23s\n",
            "189:\tlearn: 0.5963821\ttotal: 33.6s\tremaining: 2m 23s\n",
            "190:\tlearn: 0.5955401\ttotal: 33.8s\tremaining: 2m 23s\n",
            "191:\tlearn: 0.5940116\ttotal: 34s\tremaining: 2m 22s\n",
            "192:\tlearn: 0.5922949\ttotal: 34.2s\tremaining: 2m 23s\n",
            "193:\tlearn: 0.5914608\ttotal: 34.4s\tremaining: 2m 23s\n",
            "194:\tlearn: 0.5902386\ttotal: 34.6s\tremaining: 2m 23s\n",
            "195:\tlearn: 0.5893893\ttotal: 34.9s\tremaining: 2m 23s\n",
            "196:\tlearn: 0.5887680\ttotal: 35.2s\tremaining: 2m 23s\n",
            "197:\tlearn: 0.5874110\ttotal: 35.4s\tremaining: 2m 23s\n",
            "198:\tlearn: 0.5865668\ttotal: 35.6s\tremaining: 2m 23s\n",
            "199:\tlearn: 0.5858798\ttotal: 35.8s\tremaining: 2m 23s\n",
            "200:\tlearn: 0.5847718\ttotal: 36s\tremaining: 2m 23s\n",
            "201:\tlearn: 0.5840687\ttotal: 36.2s\tremaining: 2m 23s\n",
            "202:\tlearn: 0.5834152\ttotal: 36.4s\tremaining: 2m 22s\n",
            "203:\tlearn: 0.5825943\ttotal: 36.6s\tremaining: 2m 22s\n",
            "204:\tlearn: 0.5813488\ttotal: 36.8s\tremaining: 2m 22s\n",
            "205:\tlearn: 0.5804874\ttotal: 37s\tremaining: 2m 22s\n",
            "206:\tlearn: 0.5798189\ttotal: 37.2s\tremaining: 2m 22s\n",
            "207:\tlearn: 0.5783514\ttotal: 37.3s\tremaining: 2m 22s\n",
            "208:\tlearn: 0.5771721\ttotal: 37.5s\tremaining: 2m 21s\n",
            "209:\tlearn: 0.5760357\ttotal: 37.7s\tremaining: 2m 21s\n",
            "210:\tlearn: 0.5748604\ttotal: 38s\tremaining: 2m 22s\n",
            "211:\tlearn: 0.5733684\ttotal: 38.2s\tremaining: 2m 21s\n",
            "212:\tlearn: 0.5729009\ttotal: 38.4s\tremaining: 2m 21s\n",
            "213:\tlearn: 0.5723174\ttotal: 38.6s\tremaining: 2m 21s\n",
            "214:\tlearn: 0.5706337\ttotal: 38.8s\tremaining: 2m 21s\n",
            "215:\tlearn: 0.5687314\ttotal: 39.1s\tremaining: 2m 21s\n",
            "216:\tlearn: 0.5679426\ttotal: 39.4s\tremaining: 2m 22s\n",
            "217:\tlearn: 0.5674265\ttotal: 39.5s\tremaining: 2m 21s\n",
            "218:\tlearn: 0.5664286\ttotal: 39.7s\tremaining: 2m 21s\n",
            "219:\tlearn: 0.5657036\ttotal: 39.9s\tremaining: 2m 21s\n",
            "220:\tlearn: 0.5638919\ttotal: 40.1s\tremaining: 2m 21s\n",
            "221:\tlearn: 0.5630552\ttotal: 40.3s\tremaining: 2m 21s\n",
            "222:\tlearn: 0.5615005\ttotal: 40.5s\tremaining: 2m 21s\n",
            "223:\tlearn: 0.5609101\ttotal: 40.6s\tremaining: 2m 20s\n",
            "224:\tlearn: 0.5604357\ttotal: 40.8s\tremaining: 2m 20s\n",
            "225:\tlearn: 0.5598422\ttotal: 41s\tremaining: 2m 20s\n",
            "226:\tlearn: 0.5593225\ttotal: 41.2s\tremaining: 2m 20s\n",
            "227:\tlearn: 0.5585476\ttotal: 41.3s\tremaining: 2m 19s\n",
            "228:\tlearn: 0.5580159\ttotal: 41.5s\tremaining: 2m 19s\n",
            "229:\tlearn: 0.5567030\ttotal: 41.7s\tremaining: 2m 19s\n",
            "230:\tlearn: 0.5555011\ttotal: 41.9s\tremaining: 2m 19s\n",
            "231:\tlearn: 0.5541054\ttotal: 42.1s\tremaining: 2m 19s\n",
            "232:\tlearn: 0.5523969\ttotal: 42.3s\tremaining: 2m 19s\n",
            "233:\tlearn: 0.5520095\ttotal: 42.5s\tremaining: 2m 19s\n",
            "234:\tlearn: 0.5512021\ttotal: 42.7s\tremaining: 2m 19s\n",
            "235:\tlearn: 0.5503278\ttotal: 42.9s\tremaining: 2m 18s\n",
            "236:\tlearn: 0.5496971\ttotal: 43.1s\tremaining: 2m 18s\n",
            "237:\tlearn: 0.5491999\ttotal: 43.4s\tremaining: 2m 18s\n",
            "238:\tlearn: 0.5485914\ttotal: 43.6s\tremaining: 2m 18s\n",
            "239:\tlearn: 0.5476644\ttotal: 43.7s\tremaining: 2m 18s\n",
            "240:\tlearn: 0.5472946\ttotal: 43.9s\tremaining: 2m 18s\n",
            "241:\tlearn: 0.5465710\ttotal: 44.1s\tremaining: 2m 18s\n",
            "242:\tlearn: 0.5457944\ttotal: 44.2s\tremaining: 2m 17s\n",
            "243:\tlearn: 0.5448631\ttotal: 44.4s\tremaining: 2m 17s\n",
            "244:\tlearn: 0.5435715\ttotal: 44.6s\tremaining: 2m 17s\n",
            "245:\tlearn: 0.5431601\ttotal: 44.8s\tremaining: 2m 17s\n",
            "246:\tlearn: 0.5425644\ttotal: 45s\tremaining: 2m 17s\n",
            "247:\tlearn: 0.5414849\ttotal: 45.1s\tremaining: 2m 16s\n",
            "248:\tlearn: 0.5410730\ttotal: 45.3s\tremaining: 2m 16s\n",
            "249:\tlearn: 0.5400419\ttotal: 45.4s\tremaining: 2m 16s\n",
            "250:\tlearn: 0.5372972\ttotal: 45.7s\tremaining: 2m 16s\n",
            "251:\tlearn: 0.5366260\ttotal: 45.9s\tremaining: 2m 16s\n",
            "252:\tlearn: 0.5362952\ttotal: 46.1s\tremaining: 2m 16s\n",
            "253:\tlearn: 0.5351651\ttotal: 46.5s\tremaining: 2m 16s\n",
            "254:\tlearn: 0.5340150\ttotal: 46.7s\tremaining: 2m 16s\n",
            "255:\tlearn: 0.5334708\ttotal: 47s\tremaining: 2m 16s\n",
            "256:\tlearn: 0.5331537\ttotal: 47.2s\tremaining: 2m 16s\n",
            "257:\tlearn: 0.5328074\ttotal: 47.4s\tremaining: 2m 16s\n",
            "258:\tlearn: 0.5310008\ttotal: 47.6s\tremaining: 2m 16s\n",
            "259:\tlearn: 0.5304856\ttotal: 47.8s\tremaining: 2m 16s\n",
            "260:\tlearn: 0.5290085\ttotal: 48s\tremaining: 2m 15s\n",
            "261:\tlearn: 0.5279166\ttotal: 48.1s\tremaining: 2m 15s\n",
            "262:\tlearn: 0.5276172\ttotal: 48.3s\tremaining: 2m 15s\n",
            "263:\tlearn: 0.5272105\ttotal: 48.5s\tremaining: 2m 15s\n",
            "264:\tlearn: 0.5266865\ttotal: 48.7s\tremaining: 2m 15s\n",
            "265:\tlearn: 0.5258676\ttotal: 48.8s\tremaining: 2m 14s\n",
            "266:\tlearn: 0.5244497\ttotal: 49s\tremaining: 2m 14s\n",
            "267:\tlearn: 0.5230523\ttotal: 49.3s\tremaining: 2m 14s\n",
            "268:\tlearn: 0.5226091\ttotal: 49.4s\tremaining: 2m 14s\n",
            "269:\tlearn: 0.5220523\ttotal: 49.6s\tremaining: 2m 14s\n",
            "270:\tlearn: 0.5210282\ttotal: 49.8s\tremaining: 2m 13s\n",
            "271:\tlearn: 0.5202515\ttotal: 50s\tremaining: 2m 13s\n",
            "272:\tlearn: 0.5198860\ttotal: 50.2s\tremaining: 2m 13s\n",
            "273:\tlearn: 0.5194268\ttotal: 50.4s\tremaining: 2m 13s\n",
            "274:\tlearn: 0.5184130\ttotal: 50.5s\tremaining: 2m 13s\n",
            "275:\tlearn: 0.5177055\ttotal: 50.7s\tremaining: 2m 13s\n",
            "276:\tlearn: 0.5170669\ttotal: 50.9s\tremaining: 2m 12s\n",
            "277:\tlearn: 0.5161246\ttotal: 51.1s\tremaining: 2m 12s\n",
            "278:\tlearn: 0.5153345\ttotal: 51.3s\tremaining: 2m 12s\n",
            "279:\tlearn: 0.5148304\ttotal: 51.4s\tremaining: 2m 12s\n",
            "280:\tlearn: 0.5141625\ttotal: 51.6s\tremaining: 2m 11s\n",
            "281:\tlearn: 0.5138830\ttotal: 51.7s\tremaining: 2m 11s\n",
            "282:\tlearn: 0.5135972\ttotal: 51.9s\tremaining: 2m 11s\n",
            "283:\tlearn: 0.5131955\ttotal: 52.1s\tremaining: 2m 11s\n",
            "284:\tlearn: 0.5127053\ttotal: 52.3s\tremaining: 2m 11s\n",
            "285:\tlearn: 0.5123797\ttotal: 52.5s\tremaining: 2m 10s\n",
            "286:\tlearn: 0.5112869\ttotal: 52.6s\tremaining: 2m 10s\n",
            "287:\tlearn: 0.5106152\ttotal: 52.8s\tremaining: 2m 10s\n",
            "288:\tlearn: 0.5097479\ttotal: 53.1s\tremaining: 2m 10s\n",
            "289:\tlearn: 0.5089237\ttotal: 53.3s\tremaining: 2m 10s\n",
            "290:\tlearn: 0.5085957\ttotal: 53.5s\tremaining: 2m 10s\n",
            "291:\tlearn: 0.5080841\ttotal: 53.6s\tremaining: 2m 10s\n",
            "292:\tlearn: 0.5076701\ttotal: 53.8s\tremaining: 2m 9s\n",
            "293:\tlearn: 0.5071978\ttotal: 54s\tremaining: 2m 9s\n",
            "294:\tlearn: 0.5059733\ttotal: 54.2s\tremaining: 2m 9s\n",
            "295:\tlearn: 0.5045330\ttotal: 54.4s\tremaining: 2m 9s\n",
            "296:\tlearn: 0.5042710\ttotal: 54.6s\tremaining: 2m 9s\n",
            "297:\tlearn: 0.5026164\ttotal: 54.8s\tremaining: 2m 9s\n",
            "298:\tlearn: 0.5016701\ttotal: 55s\tremaining: 2m 8s\n",
            "299:\tlearn: 0.5013610\ttotal: 55.2s\tremaining: 2m 8s\n",
            "300:\tlearn: 0.5009803\ttotal: 55.4s\tremaining: 2m 8s\n",
            "301:\tlearn: 0.4998487\ttotal: 55.5s\tremaining: 2m 8s\n",
            "302:\tlearn: 0.4985618\ttotal: 55.7s\tremaining: 2m 8s\n",
            "303:\tlearn: 0.4981462\ttotal: 56s\tremaining: 2m 8s\n",
            "304:\tlearn: 0.4978932\ttotal: 56.2s\tremaining: 2m 7s\n",
            "305:\tlearn: 0.4973383\ttotal: 56.3s\tremaining: 2m 7s\n",
            "306:\tlearn: 0.4968310\ttotal: 56.5s\tremaining: 2m 7s\n",
            "307:\tlearn: 0.4962665\ttotal: 56.7s\tremaining: 2m 7s\n",
            "308:\tlearn: 0.4959732\ttotal: 56.9s\tremaining: 2m 7s\n",
            "309:\tlearn: 0.4946088\ttotal: 57.1s\tremaining: 2m 7s\n",
            "310:\tlearn: 0.4939913\ttotal: 57.2s\tremaining: 2m 6s\n",
            "311:\tlearn: 0.4930138\ttotal: 57.4s\tremaining: 2m 6s\n",
            "312:\tlearn: 0.4921323\ttotal: 57.6s\tremaining: 2m 6s\n",
            "313:\tlearn: 0.4918871\ttotal: 57.8s\tremaining: 2m 6s\n",
            "314:\tlearn: 0.4913671\ttotal: 57.9s\tremaining: 2m 6s\n",
            "315:\tlearn: 0.4906845\ttotal: 58.1s\tremaining: 2m 5s\n",
            "316:\tlearn: 0.4901156\ttotal: 58.3s\tremaining: 2m 5s\n",
            "317:\tlearn: 0.4879728\ttotal: 58.5s\tremaining: 2m 5s\n",
            "318:\tlearn: 0.4874292\ttotal: 58.6s\tremaining: 2m 5s\n",
            "319:\tlearn: 0.4869909\ttotal: 58.8s\tremaining: 2m 4s\n",
            "320:\tlearn: 0.4866892\ttotal: 59s\tremaining: 2m 4s\n",
            "321:\tlearn: 0.4862427\ttotal: 59.3s\tremaining: 2m 4s\n",
            "322:\tlearn: 0.4858403\ttotal: 59.5s\tremaining: 2m 4s\n",
            "323:\tlearn: 0.4853962\ttotal: 59.7s\tremaining: 2m 4s\n",
            "324:\tlearn: 0.4851733\ttotal: 59.9s\tremaining: 2m 4s\n",
            "325:\tlearn: 0.4848147\ttotal: 1m\tremaining: 2m 4s\n",
            "326:\tlearn: 0.4844033\ttotal: 1m\tremaining: 2m 4s\n",
            "327:\tlearn: 0.4838593\ttotal: 1m\tremaining: 2m 3s\n",
            "328:\tlearn: 0.4829923\ttotal: 1m\tremaining: 2m 3s\n",
            "329:\tlearn: 0.4822008\ttotal: 1m\tremaining: 2m 3s\n",
            "330:\tlearn: 0.4818692\ttotal: 1m 1s\tremaining: 2m 3s\n",
            "331:\tlearn: 0.4810909\ttotal: 1m 1s\tremaining: 2m 3s\n",
            "332:\tlearn: 0.4806017\ttotal: 1m 1s\tremaining: 2m 3s\n",
            "333:\tlearn: 0.4798441\ttotal: 1m 1s\tremaining: 2m 3s\n",
            "334:\tlearn: 0.4796062\ttotal: 1m 2s\tremaining: 2m 3s\n",
            "335:\tlearn: 0.4793761\ttotal: 1m 2s\tremaining: 2m 2s\n",
            "336:\tlearn: 0.4791883\ttotal: 1m 2s\tremaining: 2m 2s\n",
            "337:\tlearn: 0.4790029\ttotal: 1m 2s\tremaining: 2m 2s\n",
            "338:\tlearn: 0.4779959\ttotal: 1m 2s\tremaining: 2m 2s\n",
            "339:\tlearn: 0.4775693\ttotal: 1m 3s\tremaining: 2m 2s\n",
            "340:\tlearn: 0.4760264\ttotal: 1m 3s\tremaining: 2m 2s\n",
            "341:\tlearn: 0.4756315\ttotal: 1m 3s\tremaining: 2m 2s\n",
            "342:\tlearn: 0.4753599\ttotal: 1m 3s\tremaining: 2m 1s\n",
            "343:\tlearn: 0.4748520\ttotal: 1m 3s\tremaining: 2m 1s\n",
            "344:\tlearn: 0.4744303\ttotal: 1m 4s\tremaining: 2m 1s\n",
            "345:\tlearn: 0.4735210\ttotal: 1m 4s\tremaining: 2m 1s\n",
            "346:\tlearn: 0.4733360\ttotal: 1m 4s\tremaining: 2m 1s\n",
            "347:\tlearn: 0.4727515\ttotal: 1m 4s\tremaining: 2m\n",
            "348:\tlearn: 0.4722627\ttotal: 1m 4s\tremaining: 2m\n",
            "349:\tlearn: 0.4714359\ttotal: 1m 4s\tremaining: 2m\n",
            "350:\tlearn: 0.4705446\ttotal: 1m 5s\tremaining: 2m\n",
            "351:\tlearn: 0.4695232\ttotal: 1m 5s\tremaining: 2m\n",
            "352:\tlearn: 0.4690372\ttotal: 1m 5s\tremaining: 1m 59s\n",
            "353:\tlearn: 0.4687752\ttotal: 1m 5s\tremaining: 1m 59s\n",
            "354:\tlearn: 0.4679591\ttotal: 1m 5s\tremaining: 1m 59s\n",
            "355:\tlearn: 0.4672373\ttotal: 1m 5s\tremaining: 1m 59s\n",
            "356:\tlearn: 0.4667955\ttotal: 1m 6s\tremaining: 1m 59s\n",
            "357:\tlearn: 0.4666216\ttotal: 1m 6s\tremaining: 1m 59s\n",
            "358:\tlearn: 0.4662756\ttotal: 1m 6s\tremaining: 1m 58s\n",
            "359:\tlearn: 0.4657837\ttotal: 1m 6s\tremaining: 1m 58s\n",
            "360:\tlearn: 0.4655901\ttotal: 1m 6s\tremaining: 1m 58s\n",
            "361:\tlearn: 0.4647106\ttotal: 1m 7s\tremaining: 1m 58s\n",
            "362:\tlearn: 0.4637835\ttotal: 1m 7s\tremaining: 1m 58s\n",
            "363:\tlearn: 0.4634886\ttotal: 1m 7s\tremaining: 1m 58s\n",
            "364:\tlearn: 0.4633252\ttotal: 1m 7s\tremaining: 1m 57s\n",
            "365:\tlearn: 0.4622330\ttotal: 1m 7s\tremaining: 1m 57s\n",
            "366:\tlearn: 0.4617565\ttotal: 1m 8s\tremaining: 1m 57s\n",
            "367:\tlearn: 0.4610797\ttotal: 1m 8s\tremaining: 1m 57s\n",
            "368:\tlearn: 0.4608318\ttotal: 1m 8s\tremaining: 1m 57s\n",
            "369:\tlearn: 0.4603390\ttotal: 1m 8s\tremaining: 1m 56s\n",
            "370:\tlearn: 0.4598655\ttotal: 1m 8s\tremaining: 1m 56s\n",
            "371:\tlearn: 0.4592204\ttotal: 1m 8s\tremaining: 1m 56s\n",
            "372:\tlearn: 0.4590676\ttotal: 1m 9s\tremaining: 1m 56s\n",
            "373:\tlearn: 0.4587569\ttotal: 1m 9s\tremaining: 1m 55s\n",
            "374:\tlearn: 0.4576777\ttotal: 1m 9s\tremaining: 1m 55s\n",
            "375:\tlearn: 0.4575079\ttotal: 1m 9s\tremaining: 1m 55s\n",
            "376:\tlearn: 0.4573523\ttotal: 1m 9s\tremaining: 1m 55s\n",
            "377:\tlearn: 0.4571288\ttotal: 1m 9s\tremaining: 1m 55s\n",
            "378:\tlearn: 0.4566464\ttotal: 1m 10s\tremaining: 1m 54s\n",
            "379:\tlearn: 0.4563479\ttotal: 1m 10s\tremaining: 1m 54s\n",
            "380:\tlearn: 0.4556309\ttotal: 1m 10s\tremaining: 1m 54s\n",
            "381:\tlearn: 0.4552169\ttotal: 1m 10s\tremaining: 1m 54s\n",
            "382:\tlearn: 0.4547989\ttotal: 1m 10s\tremaining: 1m 53s\n",
            "383:\tlearn: 0.4542123\ttotal: 1m 10s\tremaining: 1m 53s\n",
            "384:\tlearn: 0.4537549\ttotal: 1m 11s\tremaining: 1m 53s\n",
            "385:\tlearn: 0.4535316\ttotal: 1m 11s\tremaining: 1m 53s\n",
            "386:\tlearn: 0.4527507\ttotal: 1m 11s\tremaining: 1m 53s\n",
            "387:\tlearn: 0.4525740\ttotal: 1m 11s\tremaining: 1m 52s\n",
            "388:\tlearn: 0.4519149\ttotal: 1m 11s\tremaining: 1m 52s\n",
            "389:\tlearn: 0.4517499\ttotal: 1m 11s\tremaining: 1m 52s\n",
            "390:\tlearn: 0.4515155\ttotal: 1m 12s\tremaining: 1m 52s\n",
            "391:\tlearn: 0.4512051\ttotal: 1m 12s\tremaining: 1m 52s\n",
            "392:\tlearn: 0.4499705\ttotal: 1m 12s\tremaining: 1m 52s\n",
            "393:\tlearn: 0.4491318\ttotal: 1m 12s\tremaining: 1m 52s\n",
            "394:\tlearn: 0.4482032\ttotal: 1m 13s\tremaining: 1m 51s\n",
            "395:\tlearn: 0.4478877\ttotal: 1m 13s\tremaining: 1m 51s\n",
            "396:\tlearn: 0.4476154\ttotal: 1m 13s\tremaining: 1m 51s\n",
            "397:\tlearn: 0.4473448\ttotal: 1m 13s\tremaining: 1m 51s\n",
            "398:\tlearn: 0.4469693\ttotal: 1m 13s\tremaining: 1m 51s\n",
            "399:\tlearn: 0.4467909\ttotal: 1m 14s\tremaining: 1m 51s\n",
            "400:\tlearn: 0.4466565\ttotal: 1m 14s\tremaining: 1m 50s\n",
            "401:\tlearn: 0.4458683\ttotal: 1m 14s\tremaining: 1m 50s\n",
            "402:\tlearn: 0.4455278\ttotal: 1m 14s\tremaining: 1m 50s\n",
            "403:\tlearn: 0.4451906\ttotal: 1m 14s\tremaining: 1m 50s\n",
            "404:\tlearn: 0.4450172\ttotal: 1m 15s\tremaining: 1m 50s\n",
            "405:\tlearn: 0.4442613\ttotal: 1m 15s\tremaining: 1m 50s\n",
            "406:\tlearn: 0.4438368\ttotal: 1m 15s\tremaining: 1m 49s\n",
            "407:\tlearn: 0.4435516\ttotal: 1m 15s\tremaining: 1m 49s\n",
            "408:\tlearn: 0.4431003\ttotal: 1m 15s\tremaining: 1m 49s\n",
            "409:\tlearn: 0.4427022\ttotal: 1m 15s\tremaining: 1m 49s\n",
            "410:\tlearn: 0.4421199\ttotal: 1m 16s\tremaining: 1m 49s\n",
            "411:\tlearn: 0.4411873\ttotal: 1m 16s\tremaining: 1m 49s\n",
            "412:\tlearn: 0.4408874\ttotal: 1m 16s\tremaining: 1m 48s\n",
            "413:\tlearn: 0.4405475\ttotal: 1m 16s\tremaining: 1m 48s\n",
            "414:\tlearn: 0.4402696\ttotal: 1m 16s\tremaining: 1m 48s\n",
            "415:\tlearn: 0.4400685\ttotal: 1m 17s\tremaining: 1m 48s\n",
            "416:\tlearn: 0.4399408\ttotal: 1m 17s\tremaining: 1m 48s\n",
            "417:\tlearn: 0.4393187\ttotal: 1m 17s\tremaining: 1m 47s\n",
            "418:\tlearn: 0.4389765\ttotal: 1m 17s\tremaining: 1m 47s\n",
            "419:\tlearn: 0.4387064\ttotal: 1m 17s\tremaining: 1m 47s\n",
            "420:\tlearn: 0.4384774\ttotal: 1m 18s\tremaining: 1m 47s\n",
            "421:\tlearn: 0.4383335\ttotal: 1m 18s\tremaining: 1m 47s\n",
            "422:\tlearn: 0.4380689\ttotal: 1m 18s\tremaining: 1m 46s\n",
            "423:\tlearn: 0.4373117\ttotal: 1m 18s\tremaining: 1m 46s\n",
            "424:\tlearn: 0.4370583\ttotal: 1m 18s\tremaining: 1m 46s\n",
            "425:\tlearn: 0.4367548\ttotal: 1m 19s\tremaining: 1m 46s\n",
            "426:\tlearn: 0.4360637\ttotal: 1m 19s\tremaining: 1m 46s\n",
            "427:\tlearn: 0.4358280\ttotal: 1m 19s\tremaining: 1m 46s\n",
            "428:\tlearn: 0.4347236\ttotal: 1m 19s\tremaining: 1m 45s\n",
            "429:\tlearn: 0.4341273\ttotal: 1m 19s\tremaining: 1m 45s\n",
            "430:\tlearn: 0.4337957\ttotal: 1m 19s\tremaining: 1m 45s\n",
            "431:\tlearn: 0.4335797\ttotal: 1m 20s\tremaining: 1m 45s\n",
            "432:\tlearn: 0.4333076\ttotal: 1m 20s\tremaining: 1m 45s\n",
            "433:\tlearn: 0.4330877\ttotal: 1m 20s\tremaining: 1m 44s\n",
            "434:\tlearn: 0.4320796\ttotal: 1m 20s\tremaining: 1m 44s\n",
            "435:\tlearn: 0.4318627\ttotal: 1m 20s\tremaining: 1m 44s\n",
            "436:\tlearn: 0.4315352\ttotal: 1m 20s\tremaining: 1m 44s\n",
            "437:\tlearn: 0.4311602\ttotal: 1m 21s\tremaining: 1m 44s\n",
            "438:\tlearn: 0.4310268\ttotal: 1m 21s\tremaining: 1m 44s\n",
            "439:\tlearn: 0.4305858\ttotal: 1m 21s\tremaining: 1m 43s\n",
            "440:\tlearn: 0.4303498\ttotal: 1m 21s\tremaining: 1m 43s\n",
            "441:\tlearn: 0.4301460\ttotal: 1m 22s\tremaining: 1m 43s\n",
            "442:\tlearn: 0.4300174\ttotal: 1m 22s\tremaining: 1m 43s\n",
            "443:\tlearn: 0.4297812\ttotal: 1m 22s\tremaining: 1m 43s\n",
            "444:\tlearn: 0.4294711\ttotal: 1m 22s\tremaining: 1m 43s\n",
            "445:\tlearn: 0.4288537\ttotal: 1m 23s\tremaining: 1m 43s\n",
            "446:\tlearn: 0.4283914\ttotal: 1m 23s\tremaining: 1m 43s\n",
            "447:\tlearn: 0.4280519\ttotal: 1m 23s\tremaining: 1m 43s\n",
            "448:\tlearn: 0.4277539\ttotal: 1m 23s\tremaining: 1m 42s\n",
            "449:\tlearn: 0.4271851\ttotal: 1m 24s\tremaining: 1m 42s\n",
            "450:\tlearn: 0.4264144\ttotal: 1m 24s\tremaining: 1m 42s\n",
            "451:\tlearn: 0.4261202\ttotal: 1m 24s\tremaining: 1m 42s\n",
            "452:\tlearn: 0.4255446\ttotal: 1m 24s\tremaining: 1m 42s\n",
            "453:\tlearn: 0.4253209\ttotal: 1m 24s\tremaining: 1m 42s\n",
            "454:\tlearn: 0.4251893\ttotal: 1m 25s\tremaining: 1m 42s\n",
            "455:\tlearn: 0.4250213\ttotal: 1m 25s\tremaining: 1m 41s\n",
            "456:\tlearn: 0.4248959\ttotal: 1m 25s\tremaining: 1m 41s\n",
            "457:\tlearn: 0.4243487\ttotal: 1m 25s\tremaining: 1m 41s\n",
            "458:\tlearn: 0.4238174\ttotal: 1m 25s\tremaining: 1m 41s\n",
            "459:\tlearn: 0.4233789\ttotal: 1m 26s\tremaining: 1m 41s\n",
            "460:\tlearn: 0.4232014\ttotal: 1m 26s\tremaining: 1m 40s\n",
            "461:\tlearn: 0.4227966\ttotal: 1m 26s\tremaining: 1m 40s\n",
            "462:\tlearn: 0.4218553\ttotal: 1m 26s\tremaining: 1m 40s\n",
            "463:\tlearn: 0.4213349\ttotal: 1m 26s\tremaining: 1m 40s\n",
            "464:\tlearn: 0.4202930\ttotal: 1m 27s\tremaining: 1m 40s\n",
            "465:\tlearn: 0.4201318\ttotal: 1m 27s\tremaining: 1m 40s\n",
            "466:\tlearn: 0.4199738\ttotal: 1m 27s\tremaining: 1m 40s\n",
            "467:\tlearn: 0.4195255\ttotal: 1m 27s\tremaining: 1m 39s\n",
            "468:\tlearn: 0.4193020\ttotal: 1m 28s\tremaining: 1m 39s\n",
            "469:\tlearn: 0.4191756\ttotal: 1m 28s\tremaining: 1m 39s\n",
            "470:\tlearn: 0.4189769\ttotal: 1m 28s\tremaining: 1m 39s\n",
            "471:\tlearn: 0.4187286\ttotal: 1m 28s\tremaining: 1m 39s\n",
            "472:\tlearn: 0.4183485\ttotal: 1m 28s\tremaining: 1m 39s\n",
            "473:\tlearn: 0.4173454\ttotal: 1m 29s\tremaining: 1m 38s\n",
            "474:\tlearn: 0.4170788\ttotal: 1m 29s\tremaining: 1m 38s\n",
            "475:\tlearn: 0.4169171\ttotal: 1m 29s\tremaining: 1m 38s\n",
            "476:\tlearn: 0.4166244\ttotal: 1m 29s\tremaining: 1m 38s\n",
            "477:\tlearn: 0.4164153\ttotal: 1m 29s\tremaining: 1m 38s\n",
            "478:\tlearn: 0.4160800\ttotal: 1m 30s\tremaining: 1m 37s\n",
            "479:\tlearn: 0.4158139\ttotal: 1m 30s\tremaining: 1m 37s\n",
            "480:\tlearn: 0.4151940\ttotal: 1m 30s\tremaining: 1m 37s\n",
            "481:\tlearn: 0.4149673\ttotal: 1m 30s\tremaining: 1m 37s\n",
            "482:\tlearn: 0.4148077\ttotal: 1m 30s\tremaining: 1m 37s\n",
            "483:\tlearn: 0.4145910\ttotal: 1m 30s\tremaining: 1m 36s\n",
            "484:\tlearn: 0.4144335\ttotal: 1m 31s\tremaining: 1m 36s\n",
            "485:\tlearn: 0.4141520\ttotal: 1m 31s\tremaining: 1m 36s\n",
            "486:\tlearn: 0.4139401\ttotal: 1m 31s\tremaining: 1m 36s\n",
            "487:\tlearn: 0.4138212\ttotal: 1m 31s\tremaining: 1m 36s\n",
            "488:\tlearn: 0.4137028\ttotal: 1m 31s\tremaining: 1m 35s\n",
            "489:\tlearn: 0.4135002\ttotal: 1m 32s\tremaining: 1m 35s\n",
            "490:\tlearn: 0.4133281\ttotal: 1m 32s\tremaining: 1m 35s\n",
            "491:\tlearn: 0.4131157\ttotal: 1m 32s\tremaining: 1m 35s\n",
            "492:\tlearn: 0.4126281\ttotal: 1m 32s\tremaining: 1m 35s\n",
            "493:\tlearn: 0.4125105\ttotal: 1m 32s\tremaining: 1m 35s\n",
            "494:\tlearn: 0.4121896\ttotal: 1m 32s\tremaining: 1m 34s\n",
            "495:\tlearn: 0.4115758\ttotal: 1m 33s\tremaining: 1m 34s\n",
            "496:\tlearn: 0.4113018\ttotal: 1m 33s\tremaining: 1m 34s\n",
            "497:\tlearn: 0.4110930\ttotal: 1m 33s\tremaining: 1m 34s\n",
            "498:\tlearn: 0.4107886\ttotal: 1m 33s\tremaining: 1m 34s\n",
            "499:\tlearn: 0.4106322\ttotal: 1m 33s\tremaining: 1m 33s\n",
            "500:\tlearn: 0.4095860\ttotal: 1m 34s\tremaining: 1m 33s\n",
            "501:\tlearn: 0.4090894\ttotal: 1m 34s\tremaining: 1m 33s\n",
            "502:\tlearn: 0.4089420\ttotal: 1m 34s\tremaining: 1m 33s\n",
            "503:\tlearn: 0.4086581\ttotal: 1m 34s\tremaining: 1m 33s\n",
            "504:\tlearn: 0.4083562\ttotal: 1m 34s\tremaining: 1m 32s\n",
            "505:\tlearn: 0.4082378\ttotal: 1m 34s\tremaining: 1m 32s\n",
            "506:\tlearn: 0.4078016\ttotal: 1m 35s\tremaining: 1m 32s\n",
            "507:\tlearn: 0.4072333\ttotal: 1m 35s\tremaining: 1m 32s\n",
            "508:\tlearn: 0.4067266\ttotal: 1m 35s\tremaining: 1m 32s\n",
            "509:\tlearn: 0.4065322\ttotal: 1m 35s\tremaining: 1m 31s\n",
            "510:\tlearn: 0.4061567\ttotal: 1m 35s\tremaining: 1m 31s\n",
            "511:\tlearn: 0.4059018\ttotal: 1m 35s\tremaining: 1m 31s\n",
            "512:\tlearn: 0.4052195\ttotal: 1m 36s\tremaining: 1m 31s\n",
            "513:\tlearn: 0.4045920\ttotal: 1m 36s\tremaining: 1m 31s\n",
            "514:\tlearn: 0.4043414\ttotal: 1m 36s\tremaining: 1m 30s\n",
            "515:\tlearn: 0.4036520\ttotal: 1m 36s\tremaining: 1m 30s\n",
            "516:\tlearn: 0.4031467\ttotal: 1m 36s\tremaining: 1m 30s\n",
            "517:\tlearn: 0.4030265\ttotal: 1m 36s\tremaining: 1m 30s\n",
            "518:\tlearn: 0.4028714\ttotal: 1m 37s\tremaining: 1m 29s\n",
            "519:\tlearn: 0.4027736\ttotal: 1m 37s\tremaining: 1m 29s\n",
            "520:\tlearn: 0.4025319\ttotal: 1m 37s\tremaining: 1m 29s\n",
            "521:\tlearn: 0.4023087\ttotal: 1m 37s\tremaining: 1m 29s\n",
            "522:\tlearn: 0.4021430\ttotal: 1m 37s\tremaining: 1m 29s\n",
            "523:\tlearn: 0.4020354\ttotal: 1m 37s\tremaining: 1m 28s\n",
            "524:\tlearn: 0.4019269\ttotal: 1m 38s\tremaining: 1m 28s\n",
            "525:\tlearn: 0.4016251\ttotal: 1m 38s\tremaining: 1m 28s\n",
            "526:\tlearn: 0.4014501\ttotal: 1m 38s\tremaining: 1m 28s\n",
            "527:\tlearn: 0.4010296\ttotal: 1m 38s\tremaining: 1m 28s\n",
            "528:\tlearn: 0.4008619\ttotal: 1m 38s\tremaining: 1m 27s\n",
            "529:\tlearn: 0.4005359\ttotal: 1m 38s\tremaining: 1m 27s\n",
            "530:\tlearn: 0.4002320\ttotal: 1m 39s\tremaining: 1m 27s\n",
            "531:\tlearn: 0.4000681\ttotal: 1m 39s\tremaining: 1m 27s\n",
            "532:\tlearn: 0.3997689\ttotal: 1m 39s\tremaining: 1m 27s\n",
            "533:\tlearn: 0.3996169\ttotal: 1m 39s\tremaining: 1m 26s\n",
            "534:\tlearn: 0.3991135\ttotal: 1m 39s\tremaining: 1m 26s\n",
            "535:\tlearn: 0.3990107\ttotal: 1m 39s\tremaining: 1m 26s\n",
            "536:\tlearn: 0.3989155\ttotal: 1m 39s\tremaining: 1m 26s\n",
            "537:\tlearn: 0.3987276\ttotal: 1m 40s\tremaining: 1m 25s\n",
            "538:\tlearn: 0.3985516\ttotal: 1m 40s\tremaining: 1m 25s\n",
            "539:\tlearn: 0.3983853\ttotal: 1m 40s\tremaining: 1m 25s\n",
            "540:\tlearn: 0.3981589\ttotal: 1m 40s\tremaining: 1m 25s\n",
            "541:\tlearn: 0.3975362\ttotal: 1m 40s\tremaining: 1m 25s\n",
            "542:\tlearn: 0.3969935\ttotal: 1m 40s\tremaining: 1m 24s\n",
            "543:\tlearn: 0.3962388\ttotal: 1m 41s\tremaining: 1m 24s\n",
            "544:\tlearn: 0.3960634\ttotal: 1m 41s\tremaining: 1m 24s\n",
            "545:\tlearn: 0.3959677\ttotal: 1m 41s\tremaining: 1m 24s\n",
            "546:\tlearn: 0.3958216\ttotal: 1m 41s\tremaining: 1m 24s\n",
            "547:\tlearn: 0.3949974\ttotal: 1m 41s\tremaining: 1m 23s\n",
            "548:\tlearn: 0.3947981\ttotal: 1m 41s\tremaining: 1m 23s\n",
            "549:\tlearn: 0.3945840\ttotal: 1m 41s\tremaining: 1m 23s\n",
            "550:\tlearn: 0.3940738\ttotal: 1m 42s\tremaining: 1m 23s\n",
            "551:\tlearn: 0.3938049\ttotal: 1m 42s\tremaining: 1m 23s\n",
            "552:\tlearn: 0.3929519\ttotal: 1m 42s\tremaining: 1m 22s\n",
            "553:\tlearn: 0.3928535\ttotal: 1m 42s\tremaining: 1m 22s\n",
            "554:\tlearn: 0.3926485\ttotal: 1m 42s\tremaining: 1m 22s\n",
            "555:\tlearn: 0.3924131\ttotal: 1m 42s\tremaining: 1m 22s\n",
            "556:\tlearn: 0.3922663\ttotal: 1m 43s\tremaining: 1m 22s\n",
            "557:\tlearn: 0.3913736\ttotal: 1m 43s\tremaining: 1m 21s\n",
            "558:\tlearn: 0.3912367\ttotal: 1m 43s\tremaining: 1m 21s\n",
            "559:\tlearn: 0.3904426\ttotal: 1m 43s\tremaining: 1m 21s\n",
            "560:\tlearn: 0.3903474\ttotal: 1m 43s\tremaining: 1m 21s\n",
            "561:\tlearn: 0.3901562\ttotal: 1m 43s\tremaining: 1m 21s\n",
            "562:\tlearn: 0.3900564\ttotal: 1m 44s\tremaining: 1m 20s\n",
            "563:\tlearn: 0.3893572\ttotal: 1m 44s\tremaining: 1m 20s\n",
            "564:\tlearn: 0.3891824\ttotal: 1m 44s\tremaining: 1m 20s\n",
            "565:\tlearn: 0.3890946\ttotal: 1m 44s\tremaining: 1m 20s\n",
            "566:\tlearn: 0.3889359\ttotal: 1m 44s\tremaining: 1m 20s\n",
            "567:\tlearn: 0.3884457\ttotal: 1m 44s\tremaining: 1m 19s\n",
            "568:\tlearn: 0.3878393\ttotal: 1m 45s\tremaining: 1m 19s\n",
            "569:\tlearn: 0.3876506\ttotal: 1m 45s\tremaining: 1m 19s\n",
            "570:\tlearn: 0.3875611\ttotal: 1m 45s\tremaining: 1m 19s\n",
            "571:\tlearn: 0.3871253\ttotal: 1m 45s\tremaining: 1m 19s\n",
            "572:\tlearn: 0.3869343\ttotal: 1m 45s\tremaining: 1m 18s\n",
            "573:\tlearn: 0.3867288\ttotal: 1m 45s\tremaining: 1m 18s\n",
            "574:\tlearn: 0.3864336\ttotal: 1m 46s\tremaining: 1m 18s\n",
            "575:\tlearn: 0.3859502\ttotal: 1m 46s\tremaining: 1m 18s\n",
            "576:\tlearn: 0.3858590\ttotal: 1m 46s\tremaining: 1m 17s\n",
            "577:\tlearn: 0.3856440\ttotal: 1m 46s\tremaining: 1m 17s\n",
            "578:\tlearn: 0.3853239\ttotal: 1m 46s\tremaining: 1m 17s\n",
            "579:\tlearn: 0.3851454\ttotal: 1m 46s\tremaining: 1m 17s\n",
            "580:\tlearn: 0.3849815\ttotal: 1m 46s\tremaining: 1m 17s\n",
            "581:\tlearn: 0.3846385\ttotal: 1m 47s\tremaining: 1m 16s\n",
            "582:\tlearn: 0.3843743\ttotal: 1m 47s\tremaining: 1m 16s\n",
            "583:\tlearn: 0.3838396\ttotal: 1m 47s\tremaining: 1m 16s\n",
            "584:\tlearn: 0.3837087\ttotal: 1m 47s\tremaining: 1m 16s\n",
            "585:\tlearn: 0.3835778\ttotal: 1m 47s\tremaining: 1m 16s\n",
            "586:\tlearn: 0.3832618\ttotal: 1m 47s\tremaining: 1m 15s\n",
            "587:\tlearn: 0.3825959\ttotal: 1m 48s\tremaining: 1m 15s\n",
            "588:\tlearn: 0.3824663\ttotal: 1m 48s\tremaining: 1m 15s\n",
            "589:\tlearn: 0.3819197\ttotal: 1m 48s\tremaining: 1m 15s\n",
            "590:\tlearn: 0.3815840\ttotal: 1m 48s\tremaining: 1m 15s\n",
            "591:\tlearn: 0.3814338\ttotal: 1m 48s\tremaining: 1m 14s\n",
            "592:\tlearn: 0.3809233\ttotal: 1m 48s\tremaining: 1m 14s\n",
            "593:\tlearn: 0.3808241\ttotal: 1m 48s\tremaining: 1m 14s\n",
            "594:\tlearn: 0.3806333\ttotal: 1m 49s\tremaining: 1m 14s\n",
            "595:\tlearn: 0.3805562\ttotal: 1m 49s\tremaining: 1m 14s\n",
            "596:\tlearn: 0.3799750\ttotal: 1m 49s\tremaining: 1m 13s\n",
            "597:\tlearn: 0.3795282\ttotal: 1m 49s\tremaining: 1m 13s\n",
            "598:\tlearn: 0.3787854\ttotal: 1m 49s\tremaining: 1m 13s\n",
            "599:\tlearn: 0.3785417\ttotal: 1m 49s\tremaining: 1m 13s\n",
            "600:\tlearn: 0.3784251\ttotal: 1m 50s\tremaining: 1m 13s\n",
            "601:\tlearn: 0.3777976\ttotal: 1m 50s\tremaining: 1m 12s\n",
            "602:\tlearn: 0.3777117\ttotal: 1m 50s\tremaining: 1m 12s\n",
            "603:\tlearn: 0.3775908\ttotal: 1m 50s\tremaining: 1m 12s\n",
            "604:\tlearn: 0.3774183\ttotal: 1m 50s\tremaining: 1m 12s\n",
            "605:\tlearn: 0.3772536\ttotal: 1m 50s\tremaining: 1m 12s\n",
            "606:\tlearn: 0.3770602\ttotal: 1m 51s\tremaining: 1m 11s\n",
            "607:\tlearn: 0.3759298\ttotal: 1m 51s\tremaining: 1m 11s\n",
            "608:\tlearn: 0.3744034\ttotal: 1m 51s\tremaining: 1m 11s\n",
            "609:\tlearn: 0.3740568\ttotal: 1m 51s\tremaining: 1m 11s\n",
            "610:\tlearn: 0.3736205\ttotal: 1m 51s\tremaining: 1m 11s\n",
            "611:\tlearn: 0.3734287\ttotal: 1m 51s\tremaining: 1m 10s\n",
            "612:\tlearn: 0.3731867\ttotal: 1m 52s\tremaining: 1m 10s\n",
            "613:\tlearn: 0.3731030\ttotal: 1m 52s\tremaining: 1m 10s\n",
            "614:\tlearn: 0.3730014\ttotal: 1m 52s\tremaining: 1m 10s\n",
            "615:\tlearn: 0.3727266\ttotal: 1m 52s\tremaining: 1m 10s\n",
            "616:\tlearn: 0.3726491\ttotal: 1m 52s\tremaining: 1m 9s\n",
            "617:\tlearn: 0.3724182\ttotal: 1m 52s\tremaining: 1m 9s\n",
            "618:\tlearn: 0.3722867\ttotal: 1m 53s\tremaining: 1m 9s\n",
            "619:\tlearn: 0.3721613\ttotal: 1m 53s\tremaining: 1m 9s\n",
            "620:\tlearn: 0.3717629\ttotal: 1m 53s\tremaining: 1m 9s\n",
            "621:\tlearn: 0.3716857\ttotal: 1m 53s\tremaining: 1m 8s\n",
            "622:\tlearn: 0.3715591\ttotal: 1m 53s\tremaining: 1m 8s\n",
            "623:\tlearn: 0.3710407\ttotal: 1m 53s\tremaining: 1m 8s\n",
            "624:\tlearn: 0.3708199\ttotal: 1m 53s\tremaining: 1m 8s\n",
            "625:\tlearn: 0.3702142\ttotal: 1m 54s\tremaining: 1m 8s\n",
            "626:\tlearn: 0.3701200\ttotal: 1m 54s\tremaining: 1m 7s\n",
            "627:\tlearn: 0.3692296\ttotal: 1m 54s\tremaining: 1m 7s\n",
            "628:\tlearn: 0.3691542\ttotal: 1m 54s\tremaining: 1m 7s\n",
            "629:\tlearn: 0.3689985\ttotal: 1m 54s\tremaining: 1m 7s\n",
            "630:\tlearn: 0.3688717\ttotal: 1m 54s\tremaining: 1m 7s\n",
            "631:\tlearn: 0.3686480\ttotal: 1m 55s\tremaining: 1m 6s\n",
            "632:\tlearn: 0.3685570\ttotal: 1m 55s\tremaining: 1m 6s\n",
            "633:\tlearn: 0.3680575\ttotal: 1m 55s\tremaining: 1m 6s\n",
            "634:\tlearn: 0.3679028\ttotal: 1m 55s\tremaining: 1m 6s\n",
            "635:\tlearn: 0.3678112\ttotal: 1m 55s\tremaining: 1m 6s\n",
            "636:\tlearn: 0.3674268\ttotal: 1m 55s\tremaining: 1m 6s\n",
            "637:\tlearn: 0.3671171\ttotal: 1m 56s\tremaining: 1m 5s\n",
            "638:\tlearn: 0.3667588\ttotal: 1m 56s\tremaining: 1m 5s\n",
            "639:\tlearn: 0.3662768\ttotal: 1m 56s\tremaining: 1m 5s\n",
            "640:\tlearn: 0.3661496\ttotal: 1m 56s\tremaining: 1m 5s\n",
            "641:\tlearn: 0.3659924\ttotal: 1m 56s\tremaining: 1m 5s\n",
            "642:\tlearn: 0.3654992\ttotal: 1m 56s\tremaining: 1m 4s\n",
            "643:\tlearn: 0.3654108\ttotal: 1m 57s\tremaining: 1m 4s\n",
            "644:\tlearn: 0.3652002\ttotal: 1m 57s\tremaining: 1m 4s\n",
            "645:\tlearn: 0.3650196\ttotal: 1m 57s\tremaining: 1m 4s\n",
            "646:\tlearn: 0.3649529\ttotal: 1m 57s\tremaining: 1m 4s\n",
            "647:\tlearn: 0.3648135\ttotal: 1m 57s\tremaining: 1m 3s\n",
            "648:\tlearn: 0.3647293\ttotal: 1m 57s\tremaining: 1m 3s\n",
            "649:\tlearn: 0.3646033\ttotal: 1m 57s\tremaining: 1m 3s\n",
            "650:\tlearn: 0.3645307\ttotal: 1m 58s\tremaining: 1m 3s\n",
            "651:\tlearn: 0.3643129\ttotal: 1m 58s\tremaining: 1m 3s\n",
            "652:\tlearn: 0.3642240\ttotal: 1m 58s\tremaining: 1m 2s\n",
            "653:\tlearn: 0.3640159\ttotal: 1m 58s\tremaining: 1m 2s\n",
            "654:\tlearn: 0.3638599\ttotal: 1m 58s\tremaining: 1m 2s\n",
            "655:\tlearn: 0.3637431\ttotal: 1m 58s\tremaining: 1m 2s\n",
            "656:\tlearn: 0.3621953\ttotal: 1m 59s\tremaining: 1m 2s\n",
            "657:\tlearn: 0.3613652\ttotal: 1m 59s\tremaining: 1m 1s\n",
            "658:\tlearn: 0.3613121\ttotal: 1m 59s\tremaining: 1m 1s\n",
            "659:\tlearn: 0.3610924\ttotal: 1m 59s\tremaining: 1m 1s\n",
            "660:\tlearn: 0.3608804\ttotal: 1m 59s\tremaining: 1m 1s\n",
            "661:\tlearn: 0.3607549\ttotal: 1m 59s\tremaining: 1m 1s\n",
            "662:\tlearn: 0.3605747\ttotal: 1m 59s\tremaining: 1m\n",
            "663:\tlearn: 0.3603759\ttotal: 2m\tremaining: 1m\n",
            "664:\tlearn: 0.3603078\ttotal: 2m\tremaining: 1m\n",
            "665:\tlearn: 0.3598804\ttotal: 2m\tremaining: 1m\n",
            "666:\tlearn: 0.3596813\ttotal: 2m\tremaining: 1m\n",
            "667:\tlearn: 0.3591596\ttotal: 2m\tremaining: 60s\n",
            "668:\tlearn: 0.3589239\ttotal: 2m\tremaining: 59.8s\n",
            "669:\tlearn: 0.3587197\ttotal: 2m 1s\tremaining: 59.6s\n",
            "670:\tlearn: 0.3585039\ttotal: 2m 1s\tremaining: 59.4s\n",
            "671:\tlearn: 0.3580724\ttotal: 2m 1s\tremaining: 59.2s\n",
            "672:\tlearn: 0.3579549\ttotal: 2m 1s\tremaining: 59s\n",
            "673:\tlearn: 0.3578075\ttotal: 2m 1s\tremaining: 58.9s\n",
            "674:\tlearn: 0.3574671\ttotal: 2m 1s\tremaining: 58.7s\n",
            "675:\tlearn: 0.3572784\ttotal: 2m 2s\tremaining: 58.5s\n",
            "676:\tlearn: 0.3572287\ttotal: 2m 2s\tremaining: 58.3s\n",
            "677:\tlearn: 0.3570507\ttotal: 2m 2s\tremaining: 58.1s\n",
            "678:\tlearn: 0.3567710\ttotal: 2m 2s\tremaining: 57.9s\n",
            "679:\tlearn: 0.3566270\ttotal: 2m 2s\tremaining: 57.7s\n",
            "680:\tlearn: 0.3562483\ttotal: 2m 2s\tremaining: 57.6s\n",
            "681:\tlearn: 0.3561609\ttotal: 2m 3s\tremaining: 57.4s\n",
            "682:\tlearn: 0.3558697\ttotal: 2m 3s\tremaining: 57.2s\n",
            "683:\tlearn: 0.3557404\ttotal: 2m 3s\tremaining: 57s\n",
            "684:\tlearn: 0.3556895\ttotal: 2m 3s\tremaining: 56.8s\n",
            "685:\tlearn: 0.3556455\ttotal: 2m 3s\tremaining: 56.6s\n",
            "686:\tlearn: 0.3555912\ttotal: 2m 3s\tremaining: 56.4s\n",
            "687:\tlearn: 0.3553931\ttotal: 2m 4s\tremaining: 56.2s\n",
            "688:\tlearn: 0.3553421\ttotal: 2m 4s\tremaining: 56s\n",
            "689:\tlearn: 0.3546527\ttotal: 2m 4s\tremaining: 55.8s\n",
            "690:\tlearn: 0.3544825\ttotal: 2m 4s\tremaining: 55.6s\n",
            "691:\tlearn: 0.3543686\ttotal: 2m 4s\tremaining: 55.5s\n",
            "692:\tlearn: 0.3539698\ttotal: 2m 4s\tremaining: 55.3s\n",
            "693:\tlearn: 0.3536931\ttotal: 2m 4s\tremaining: 55.1s\n",
            "694:\tlearn: 0.3535551\ttotal: 2m 5s\tremaining: 54.9s\n",
            "695:\tlearn: 0.3533380\ttotal: 2m 5s\tremaining: 54.7s\n",
            "696:\tlearn: 0.3532508\ttotal: 2m 5s\tremaining: 54.5s\n",
            "697:\tlearn: 0.3531060\ttotal: 2m 5s\tremaining: 54.3s\n",
            "698:\tlearn: 0.3525788\ttotal: 2m 5s\tremaining: 54.1s\n",
            "699:\tlearn: 0.3524341\ttotal: 2m 5s\tremaining: 53.9s\n",
            "700:\tlearn: 0.3523968\ttotal: 2m 6s\tremaining: 53.8s\n",
            "701:\tlearn: 0.3521309\ttotal: 2m 6s\tremaining: 53.6s\n",
            "702:\tlearn: 0.3520870\ttotal: 2m 6s\tremaining: 53.4s\n",
            "703:\tlearn: 0.3520338\ttotal: 2m 6s\tremaining: 53.2s\n",
            "704:\tlearn: 0.3514198\ttotal: 2m 6s\tremaining: 53.1s\n",
            "705:\tlearn: 0.3513036\ttotal: 2m 7s\tremaining: 52.9s\n",
            "706:\tlearn: 0.3510456\ttotal: 2m 7s\tremaining: 52.7s\n",
            "707:\tlearn: 0.3502663\ttotal: 2m 7s\tremaining: 52.6s\n",
            "708:\tlearn: 0.3500296\ttotal: 2m 7s\tremaining: 52.4s\n",
            "709:\tlearn: 0.3499195\ttotal: 2m 7s\tremaining: 52.2s\n",
            "710:\tlearn: 0.3498118\ttotal: 2m 8s\tremaining: 52.1s\n",
            "711:\tlearn: 0.3496541\ttotal: 2m 8s\tremaining: 51.9s\n",
            "712:\tlearn: 0.3496301\ttotal: 2m 8s\tremaining: 51.7s\n",
            "713:\tlearn: 0.3494589\ttotal: 2m 8s\tremaining: 51.5s\n",
            "714:\tlearn: 0.3489485\ttotal: 2m 8s\tremaining: 51.4s\n",
            "715:\tlearn: 0.3489110\ttotal: 2m 9s\tremaining: 51.2s\n",
            "716:\tlearn: 0.3486257\ttotal: 2m 9s\tremaining: 51s\n",
            "717:\tlearn: 0.3484486\ttotal: 2m 9s\tremaining: 50.8s\n",
            "718:\tlearn: 0.3483653\ttotal: 2m 9s\tremaining: 50.6s\n",
            "719:\tlearn: 0.3479922\ttotal: 2m 9s\tremaining: 50.4s\n",
            "720:\tlearn: 0.3478428\ttotal: 2m 9s\tremaining: 50.3s\n",
            "721:\tlearn: 0.3477820\ttotal: 2m 10s\tremaining: 50.1s\n",
            "722:\tlearn: 0.3474922\ttotal: 2m 10s\tremaining: 49.9s\n",
            "723:\tlearn: 0.3473814\ttotal: 2m 10s\tremaining: 49.7s\n",
            "724:\tlearn: 0.3472959\ttotal: 2m 10s\tremaining: 49.5s\n",
            "725:\tlearn: 0.3469829\ttotal: 2m 10s\tremaining: 49.3s\n",
            "726:\tlearn: 0.3468585\ttotal: 2m 10s\tremaining: 49.1s\n",
            "727:\tlearn: 0.3468073\ttotal: 2m 10s\tremaining: 48.9s\n",
            "728:\tlearn: 0.3467578\ttotal: 2m 11s\tremaining: 48.7s\n",
            "729:\tlearn: 0.3465591\ttotal: 2m 11s\tremaining: 48.5s\n",
            "730:\tlearn: 0.3465344\ttotal: 2m 11s\tremaining: 48.4s\n",
            "731:\tlearn: 0.3464783\ttotal: 2m 11s\tremaining: 48.2s\n",
            "732:\tlearn: 0.3461161\ttotal: 2m 11s\tremaining: 48s\n",
            "733:\tlearn: 0.3459605\ttotal: 2m 11s\tremaining: 47.8s\n",
            "734:\tlearn: 0.3458070\ttotal: 2m 12s\tremaining: 47.6s\n",
            "735:\tlearn: 0.3457705\ttotal: 2m 12s\tremaining: 47.4s\n",
            "736:\tlearn: 0.3457279\ttotal: 2m 12s\tremaining: 47.2s\n",
            "737:\tlearn: 0.3456756\ttotal: 2m 12s\tremaining: 47s\n",
            "738:\tlearn: 0.3453735\ttotal: 2m 12s\tremaining: 46.8s\n",
            "739:\tlearn: 0.3452051\ttotal: 2m 12s\tremaining: 46.7s\n",
            "740:\tlearn: 0.3450426\ttotal: 2m 12s\tremaining: 46.5s\n",
            "741:\tlearn: 0.3448661\ttotal: 2m 13s\tremaining: 46.3s\n",
            "742:\tlearn: 0.3444264\ttotal: 2m 13s\tremaining: 46.1s\n",
            "743:\tlearn: 0.3443359\ttotal: 2m 13s\tremaining: 45.9s\n",
            "744:\tlearn: 0.3442214\ttotal: 2m 13s\tremaining: 45.7s\n",
            "745:\tlearn: 0.3440667\ttotal: 2m 13s\tremaining: 45.5s\n",
            "746:\tlearn: 0.3437016\ttotal: 2m 13s\tremaining: 45.3s\n",
            "747:\tlearn: 0.3435324\ttotal: 2m 13s\tremaining: 45.1s\n",
            "748:\tlearn: 0.3435078\ttotal: 2m 14s\tremaining: 44.9s\n",
            "749:\tlearn: 0.3428714\ttotal: 2m 14s\tremaining: 44.7s\n",
            "750:\tlearn: 0.3427159\ttotal: 2m 14s\tremaining: 44.6s\n",
            "751:\tlearn: 0.3426671\ttotal: 2m 14s\tremaining: 44.4s\n",
            "752:\tlearn: 0.3425334\ttotal: 2m 14s\tremaining: 44.2s\n",
            "753:\tlearn: 0.3425095\ttotal: 2m 15s\tremaining: 44s\n",
            "754:\tlearn: 0.3423136\ttotal: 2m 15s\tremaining: 43.9s\n",
            "755:\tlearn: 0.3421952\ttotal: 2m 15s\tremaining: 43.7s\n",
            "756:\tlearn: 0.3417808\ttotal: 2m 15s\tremaining: 43.5s\n",
            "757:\tlearn: 0.3416983\ttotal: 2m 15s\tremaining: 43.3s\n",
            "758:\tlearn: 0.3416745\ttotal: 2m 15s\tremaining: 43.1s\n",
            "759:\tlearn: 0.3411000\ttotal: 2m 15s\tremaining: 42.9s\n",
            "760:\tlearn: 0.3410153\ttotal: 2m 16s\tremaining: 42.7s\n",
            "761:\tlearn: 0.3409637\ttotal: 2m 16s\tremaining: 42.6s\n",
            "762:\tlearn: 0.3408820\ttotal: 2m 16s\tremaining: 42.4s\n",
            "763:\tlearn: 0.3407663\ttotal: 2m 16s\tremaining: 42.2s\n",
            "764:\tlearn: 0.3406801\ttotal: 2m 16s\tremaining: 42s\n",
            "765:\tlearn: 0.3402400\ttotal: 2m 16s\tremaining: 41.8s\n",
            "766:\tlearn: 0.3400788\ttotal: 2m 17s\tremaining: 41.6s\n",
            "767:\tlearn: 0.3400322\ttotal: 2m 17s\tremaining: 41.5s\n",
            "768:\tlearn: 0.3399767\ttotal: 2m 17s\tremaining: 41.3s\n",
            "769:\tlearn: 0.3399246\ttotal: 2m 17s\tremaining: 41.1s\n",
            "770:\tlearn: 0.3397950\ttotal: 2m 17s\tremaining: 40.9s\n",
            "771:\tlearn: 0.3397488\ttotal: 2m 17s\tremaining: 40.7s\n",
            "772:\tlearn: 0.3394473\ttotal: 2m 17s\tremaining: 40.5s\n",
            "773:\tlearn: 0.3393920\ttotal: 2m 18s\tremaining: 40.3s\n",
            "774:\tlearn: 0.3393115\ttotal: 2m 18s\tremaining: 40.2s\n",
            "775:\tlearn: 0.3392319\ttotal: 2m 18s\tremaining: 40s\n",
            "776:\tlearn: 0.3391791\ttotal: 2m 18s\tremaining: 39.8s\n",
            "777:\tlearn: 0.3384246\ttotal: 2m 18s\tremaining: 39.6s\n",
            "778:\tlearn: 0.3380168\ttotal: 2m 18s\tremaining: 39.4s\n",
            "779:\tlearn: 0.3379649\ttotal: 2m 19s\tremaining: 39.2s\n",
            "780:\tlearn: 0.3377579\ttotal: 2m 19s\tremaining: 39s\n",
            "781:\tlearn: 0.3374011\ttotal: 2m 19s\tremaining: 38.9s\n",
            "782:\tlearn: 0.3372066\ttotal: 2m 19s\tremaining: 38.7s\n",
            "783:\tlearn: 0.3370997\ttotal: 2m 19s\tremaining: 38.5s\n",
            "784:\tlearn: 0.3367997\ttotal: 2m 19s\tremaining: 38.3s\n",
            "785:\tlearn: 0.3365996\ttotal: 2m 19s\tremaining: 38.1s\n",
            "786:\tlearn: 0.3365523\ttotal: 2m 20s\tremaining: 37.9s\n",
            "787:\tlearn: 0.3365036\ttotal: 2m 20s\tremaining: 37.7s\n",
            "788:\tlearn: 0.3364178\ttotal: 2m 20s\tremaining: 37.6s\n",
            "789:\tlearn: 0.3363027\ttotal: 2m 20s\tremaining: 37.4s\n",
            "790:\tlearn: 0.3362527\ttotal: 2m 20s\tremaining: 37.2s\n",
            "791:\tlearn: 0.3361487\ttotal: 2m 20s\tremaining: 37s\n",
            "792:\tlearn: 0.3358364\ttotal: 2m 21s\tremaining: 36.8s\n",
            "793:\tlearn: 0.3356798\ttotal: 2m 21s\tremaining: 36.6s\n",
            "794:\tlearn: 0.3356036\ttotal: 2m 21s\tremaining: 36.5s\n",
            "795:\tlearn: 0.3355801\ttotal: 2m 21s\tremaining: 36.3s\n",
            "796:\tlearn: 0.3353106\ttotal: 2m 21s\tremaining: 36.1s\n",
            "797:\tlearn: 0.3352655\ttotal: 2m 22s\tremaining: 36s\n",
            "798:\tlearn: 0.3346791\ttotal: 2m 22s\tremaining: 35.8s\n",
            "799:\tlearn: 0.3346332\ttotal: 2m 22s\tremaining: 35.6s\n",
            "800:\tlearn: 0.3344597\ttotal: 2m 22s\tremaining: 35.4s\n",
            "801:\tlearn: 0.3344123\ttotal: 2m 22s\tremaining: 35.3s\n",
            "802:\tlearn: 0.3343889\ttotal: 2m 22s\tremaining: 35.1s\n",
            "803:\tlearn: 0.3343657\ttotal: 2m 23s\tremaining: 34.9s\n",
            "804:\tlearn: 0.3340051\ttotal: 2m 23s\tremaining: 34.7s\n",
            "805:\tlearn: 0.3338952\ttotal: 2m 23s\tremaining: 34.5s\n",
            "806:\tlearn: 0.3335816\ttotal: 2m 23s\tremaining: 34.3s\n",
            "807:\tlearn: 0.3334749\ttotal: 2m 23s\tremaining: 34.2s\n",
            "808:\tlearn: 0.3334257\ttotal: 2m 23s\tremaining: 34s\n",
            "809:\tlearn: 0.3334028\ttotal: 2m 24s\tremaining: 33.8s\n",
            "810:\tlearn: 0.3330674\ttotal: 2m 24s\tremaining: 33.6s\n",
            "811:\tlearn: 0.3328362\ttotal: 2m 24s\tremaining: 33.4s\n",
            "812:\tlearn: 0.3326803\ttotal: 2m 24s\tremaining: 33.3s\n",
            "813:\tlearn: 0.3325329\ttotal: 2m 24s\tremaining: 33.1s\n",
            "814:\tlearn: 0.3324550\ttotal: 2m 24s\tremaining: 32.9s\n",
            "815:\tlearn: 0.3324020\ttotal: 2m 25s\tremaining: 32.7s\n",
            "816:\tlearn: 0.3323482\ttotal: 2m 25s\tremaining: 32.5s\n",
            "817:\tlearn: 0.3321847\ttotal: 2m 25s\tremaining: 32.3s\n",
            "818:\tlearn: 0.3319958\ttotal: 2m 25s\tremaining: 32.2s\n",
            "819:\tlearn: 0.3318872\ttotal: 2m 25s\tremaining: 32s\n",
            "820:\tlearn: 0.3318644\ttotal: 2m 25s\tremaining: 31.8s\n",
            "821:\tlearn: 0.3317092\ttotal: 2m 25s\tremaining: 31.6s\n",
            "822:\tlearn: 0.3316228\ttotal: 2m 26s\tremaining: 31.4s\n",
            "823:\tlearn: 0.3315696\ttotal: 2m 26s\tremaining: 31.2s\n",
            "824:\tlearn: 0.3314122\ttotal: 2m 26s\tremaining: 31s\n",
            "825:\tlearn: 0.3311641\ttotal: 2m 26s\tremaining: 30.9s\n",
            "826:\tlearn: 0.3310567\ttotal: 2m 26s\tremaining: 30.7s\n",
            "827:\tlearn: 0.3309240\ttotal: 2m 26s\tremaining: 30.5s\n",
            "828:\tlearn: 0.3303066\ttotal: 2m 27s\tremaining: 30.3s\n",
            "829:\tlearn: 0.3302299\ttotal: 2m 27s\tremaining: 30.2s\n",
            "830:\tlearn: 0.3300492\ttotal: 2m 27s\tremaining: 30s\n",
            "831:\tlearn: 0.3299747\ttotal: 2m 27s\tremaining: 29.8s\n",
            "832:\tlearn: 0.3299256\ttotal: 2m 27s\tremaining: 29.6s\n",
            "833:\tlearn: 0.3293634\ttotal: 2m 27s\tremaining: 29.4s\n",
            "834:\tlearn: 0.3293149\ttotal: 2m 28s\tremaining: 29.3s\n",
            "835:\tlearn: 0.3291090\ttotal: 2m 28s\tremaining: 29.1s\n",
            "836:\tlearn: 0.3288869\ttotal: 2m 28s\tremaining: 28.9s\n",
            "837:\tlearn: 0.3288159\ttotal: 2m 28s\tremaining: 28.7s\n",
            "838:\tlearn: 0.3287640\ttotal: 2m 28s\tremaining: 28.5s\n",
            "839:\tlearn: 0.3286204\ttotal: 2m 28s\tremaining: 28.4s\n",
            "840:\tlearn: 0.3285666\ttotal: 2m 29s\tremaining: 28.2s\n",
            "841:\tlearn: 0.3283733\ttotal: 2m 29s\tremaining: 28s\n",
            "842:\tlearn: 0.3281046\ttotal: 2m 29s\tremaining: 27.8s\n",
            "843:\tlearn: 0.3280591\ttotal: 2m 29s\tremaining: 27.7s\n",
            "844:\tlearn: 0.3275606\ttotal: 2m 29s\tremaining: 27.5s\n",
            "845:\tlearn: 0.3274547\ttotal: 2m 29s\tremaining: 27.3s\n",
            "846:\tlearn: 0.3274043\ttotal: 2m 30s\tremaining: 27.1s\n",
            "847:\tlearn: 0.3273467\ttotal: 2m 30s\tremaining: 26.9s\n",
            "848:\tlearn: 0.3272342\ttotal: 2m 30s\tremaining: 26.8s\n",
            "849:\tlearn: 0.3270976\ttotal: 2m 30s\tremaining: 26.6s\n",
            "850:\tlearn: 0.3268897\ttotal: 2m 30s\tremaining: 26.4s\n",
            "851:\tlearn: 0.3265916\ttotal: 2m 30s\tremaining: 26.2s\n",
            "852:\tlearn: 0.3264708\ttotal: 2m 30s\tremaining: 26s\n",
            "853:\tlearn: 0.3263623\ttotal: 2m 31s\tremaining: 25.8s\n",
            "854:\tlearn: 0.3262635\ttotal: 2m 31s\tremaining: 25.7s\n",
            "855:\tlearn: 0.3260317\ttotal: 2m 31s\tremaining: 25.5s\n",
            "856:\tlearn: 0.3258637\ttotal: 2m 31s\tremaining: 25.3s\n",
            "857:\tlearn: 0.3258094\ttotal: 2m 31s\tremaining: 25.1s\n",
            "858:\tlearn: 0.3256572\ttotal: 2m 31s\tremaining: 24.9s\n",
            "859:\tlearn: 0.3255812\ttotal: 2m 32s\tremaining: 24.8s\n",
            "860:\tlearn: 0.3254291\ttotal: 2m 32s\tremaining: 24.6s\n",
            "861:\tlearn: 0.3253294\ttotal: 2m 32s\tremaining: 24.4s\n",
            "862:\tlearn: 0.3252048\ttotal: 2m 32s\tremaining: 24.2s\n",
            "863:\tlearn: 0.3247444\ttotal: 2m 32s\tremaining: 24s\n",
            "864:\tlearn: 0.3246970\ttotal: 2m 32s\tremaining: 23.9s\n",
            "865:\tlearn: 0.3245488\ttotal: 2m 33s\tremaining: 23.7s\n",
            "866:\tlearn: 0.3243460\ttotal: 2m 33s\tremaining: 23.5s\n",
            "867:\tlearn: 0.3242973\ttotal: 2m 33s\tremaining: 23.3s\n",
            "868:\tlearn: 0.3238382\ttotal: 2m 33s\tremaining: 23.1s\n",
            "869:\tlearn: 0.3237364\ttotal: 2m 33s\tremaining: 23s\n",
            "870:\tlearn: 0.3236211\ttotal: 2m 33s\tremaining: 22.8s\n",
            "871:\tlearn: 0.3235508\ttotal: 2m 34s\tremaining: 22.6s\n",
            "872:\tlearn: 0.3234537\ttotal: 2m 34s\tremaining: 22.4s\n",
            "873:\tlearn: 0.3231745\ttotal: 2m 34s\tremaining: 22.2s\n",
            "874:\tlearn: 0.3231519\ttotal: 2m 34s\tremaining: 22.1s\n",
            "875:\tlearn: 0.3230550\ttotal: 2m 34s\tremaining: 21.9s\n",
            "876:\tlearn: 0.3227459\ttotal: 2m 34s\tremaining: 21.7s\n",
            "877:\tlearn: 0.3220934\ttotal: 2m 35s\tremaining: 21.5s\n",
            "878:\tlearn: 0.3217895\ttotal: 2m 35s\tremaining: 21.4s\n",
            "879:\tlearn: 0.3214314\ttotal: 2m 35s\tremaining: 21.2s\n",
            "880:\tlearn: 0.3213822\ttotal: 2m 35s\tremaining: 21s\n",
            "881:\tlearn: 0.3213349\ttotal: 2m 35s\tremaining: 20.8s\n",
            "882:\tlearn: 0.3212086\ttotal: 2m 35s\tremaining: 20.7s\n",
            "883:\tlearn: 0.3210580\ttotal: 2m 36s\tremaining: 20.5s\n",
            "884:\tlearn: 0.3209798\ttotal: 2m 36s\tremaining: 20.3s\n",
            "885:\tlearn: 0.3208374\ttotal: 2m 36s\tremaining: 20.1s\n",
            "886:\tlearn: 0.3207861\ttotal: 2m 36s\tremaining: 19.9s\n",
            "887:\tlearn: 0.3205838\ttotal: 2m 36s\tremaining: 19.8s\n",
            "888:\tlearn: 0.3199935\ttotal: 2m 36s\tremaining: 19.6s\n",
            "889:\tlearn: 0.3195680\ttotal: 2m 37s\tremaining: 19.4s\n",
            "890:\tlearn: 0.3188324\ttotal: 2m 37s\tremaining: 19.2s\n",
            "891:\tlearn: 0.3187399\ttotal: 2m 37s\tremaining: 19.1s\n",
            "892:\tlearn: 0.3186703\ttotal: 2m 37s\tremaining: 18.9s\n",
            "893:\tlearn: 0.3186479\ttotal: 2m 37s\tremaining: 18.7s\n",
            "894:\tlearn: 0.3182276\ttotal: 2m 37s\tremaining: 18.5s\n",
            "895:\tlearn: 0.3180875\ttotal: 2m 38s\tremaining: 18.3s\n",
            "896:\tlearn: 0.3176188\ttotal: 2m 38s\tremaining: 18.2s\n",
            "897:\tlearn: 0.3175961\ttotal: 2m 38s\tremaining: 18s\n",
            "898:\tlearn: 0.3175253\ttotal: 2m 38s\tremaining: 17.8s\n",
            "899:\tlearn: 0.3173826\ttotal: 2m 38s\tremaining: 17.6s\n",
            "900:\tlearn: 0.3167917\ttotal: 2m 38s\tremaining: 17.4s\n",
            "901:\tlearn: 0.3167454\ttotal: 2m 39s\tremaining: 17.3s\n",
            "902:\tlearn: 0.3167007\ttotal: 2m 39s\tremaining: 17.1s\n",
            "903:\tlearn: 0.3164663\ttotal: 2m 39s\tremaining: 16.9s\n",
            "904:\tlearn: 0.3164446\ttotal: 2m 39s\tremaining: 16.7s\n",
            "905:\tlearn: 0.3163372\ttotal: 2m 39s\tremaining: 16.6s\n",
            "906:\tlearn: 0.3162398\ttotal: 2m 39s\tremaining: 16.4s\n",
            "907:\tlearn: 0.3161885\ttotal: 2m 39s\tremaining: 16.2s\n",
            "908:\tlearn: 0.3161303\ttotal: 2m 40s\tremaining: 16s\n",
            "909:\tlearn: 0.3160600\ttotal: 2m 40s\tremaining: 15.8s\n",
            "910:\tlearn: 0.3158558\ttotal: 2m 40s\tremaining: 15.7s\n",
            "911:\tlearn: 0.3154779\ttotal: 2m 40s\tremaining: 15.5s\n",
            "912:\tlearn: 0.3154085\ttotal: 2m 40s\tremaining: 15.3s\n",
            "913:\tlearn: 0.3152813\ttotal: 2m 40s\tremaining: 15.1s\n",
            "914:\tlearn: 0.3151817\ttotal: 2m 41s\tremaining: 15s\n",
            "915:\tlearn: 0.3149600\ttotal: 2m 41s\tremaining: 14.8s\n",
            "916:\tlearn: 0.3148219\ttotal: 2m 41s\tremaining: 14.6s\n",
            "917:\tlearn: 0.3147548\ttotal: 2m 41s\tremaining: 14.4s\n",
            "918:\tlearn: 0.3145528\ttotal: 2m 41s\tremaining: 14.3s\n",
            "919:\tlearn: 0.3144147\ttotal: 2m 41s\tremaining: 14.1s\n",
            "920:\tlearn: 0.3143275\ttotal: 2m 42s\tremaining: 13.9s\n",
            "921:\tlearn: 0.3140473\ttotal: 2m 42s\tremaining: 13.7s\n",
            "922:\tlearn: 0.3138271\ttotal: 2m 42s\tremaining: 13.5s\n",
            "923:\tlearn: 0.3137828\ttotal: 2m 42s\tremaining: 13.4s\n",
            "924:\tlearn: 0.3136107\ttotal: 2m 42s\tremaining: 13.2s\n",
            "925:\tlearn: 0.3135351\ttotal: 2m 42s\tremaining: 13s\n",
            "926:\tlearn: 0.3130763\ttotal: 2m 43s\tremaining: 12.8s\n",
            "927:\tlearn: 0.3126221\ttotal: 2m 43s\tremaining: 12.7s\n",
            "928:\tlearn: 0.3125784\ttotal: 2m 43s\tremaining: 12.5s\n",
            "929:\tlearn: 0.3124546\ttotal: 2m 43s\tremaining: 12.3s\n",
            "930:\tlearn: 0.3122735\ttotal: 2m 43s\tremaining: 12.1s\n",
            "931:\tlearn: 0.3121760\ttotal: 2m 43s\tremaining: 12s\n",
            "932:\tlearn: 0.3116322\ttotal: 2m 44s\tremaining: 11.8s\n",
            "933:\tlearn: 0.3115338\ttotal: 2m 44s\tremaining: 11.6s\n",
            "934:\tlearn: 0.3113971\ttotal: 2m 44s\tremaining: 11.4s\n",
            "935:\tlearn: 0.3109293\ttotal: 2m 44s\tremaining: 11.2s\n",
            "936:\tlearn: 0.3103744\ttotal: 2m 44s\tremaining: 11.1s\n",
            "937:\tlearn: 0.3101091\ttotal: 2m 44s\tremaining: 10.9s\n",
            "938:\tlearn: 0.3099925\ttotal: 2m 44s\tremaining: 10.7s\n",
            "939:\tlearn: 0.3099488\ttotal: 2m 45s\tremaining: 10.5s\n",
            "940:\tlearn: 0.3097817\ttotal: 2m 45s\tremaining: 10.4s\n",
            "941:\tlearn: 0.3096406\ttotal: 2m 45s\tremaining: 10.2s\n",
            "942:\tlearn: 0.3092108\ttotal: 2m 45s\tremaining: 10s\n",
            "943:\tlearn: 0.3087289\ttotal: 2m 45s\tremaining: 9.83s\n",
            "944:\tlearn: 0.3080520\ttotal: 2m 45s\tremaining: 9.65s\n",
            "945:\tlearn: 0.3079408\ttotal: 2m 46s\tremaining: 9.47s\n",
            "946:\tlearn: 0.3078761\ttotal: 2m 46s\tremaining: 9.3s\n",
            "947:\tlearn: 0.3074246\ttotal: 2m 46s\tremaining: 9.12s\n",
            "948:\tlearn: 0.3072787\ttotal: 2m 46s\tremaining: 8.95s\n",
            "949:\tlearn: 0.3071643\ttotal: 2m 46s\tremaining: 8.77s\n",
            "950:\tlearn: 0.3070979\ttotal: 2m 46s\tremaining: 8.6s\n",
            "951:\tlearn: 0.3069867\ttotal: 2m 47s\tremaining: 8.42s\n",
            "952:\tlearn: 0.3069215\ttotal: 2m 47s\tremaining: 8.24s\n",
            "953:\tlearn: 0.3065880\ttotal: 2m 47s\tremaining: 8.07s\n",
            "954:\tlearn: 0.3062385\ttotal: 2m 47s\tremaining: 7.89s\n",
            "955:\tlearn: 0.3061611\ttotal: 2m 47s\tremaining: 7.71s\n",
            "956:\tlearn: 0.3059949\ttotal: 2m 47s\tremaining: 7.54s\n",
            "957:\tlearn: 0.3055130\ttotal: 2m 47s\tremaining: 7.36s\n",
            "958:\tlearn: 0.3054217\ttotal: 2m 48s\tremaining: 7.19s\n",
            "959:\tlearn: 0.3052713\ttotal: 2m 48s\tremaining: 7.01s\n",
            "960:\tlearn: 0.3052217\ttotal: 2m 48s\tremaining: 6.84s\n",
            "961:\tlearn: 0.3050146\ttotal: 2m 48s\tremaining: 6.66s\n",
            "962:\tlearn: 0.3047394\ttotal: 2m 48s\tremaining: 6.48s\n",
            "963:\tlearn: 0.3046708\ttotal: 2m 48s\tremaining: 6.31s\n",
            "964:\tlearn: 0.3042247\ttotal: 2m 49s\tremaining: 6.13s\n",
            "965:\tlearn: 0.3040868\ttotal: 2m 49s\tremaining: 5.96s\n",
            "966:\tlearn: 0.3039927\ttotal: 2m 49s\tremaining: 5.78s\n",
            "967:\tlearn: 0.3036322\ttotal: 2m 49s\tremaining: 5.61s\n",
            "968:\tlearn: 0.3031838\ttotal: 2m 49s\tremaining: 5.43s\n",
            "969:\tlearn: 0.3030148\ttotal: 2m 49s\tremaining: 5.25s\n",
            "970:\tlearn: 0.3028938\ttotal: 2m 50s\tremaining: 5.08s\n",
            "971:\tlearn: 0.3028166\ttotal: 2m 50s\tremaining: 4.9s\n",
            "972:\tlearn: 0.3027333\ttotal: 2m 50s\tremaining: 4.73s\n",
            "973:\tlearn: 0.3026817\ttotal: 2m 50s\tremaining: 4.55s\n",
            "974:\tlearn: 0.3025808\ttotal: 2m 50s\tremaining: 4.38s\n",
            "975:\tlearn: 0.3023357\ttotal: 2m 50s\tremaining: 4.2s\n",
            "976:\tlearn: 0.3022127\ttotal: 2m 50s\tremaining: 4.02s\n",
            "977:\tlearn: 0.3021906\ttotal: 2m 51s\tremaining: 3.85s\n",
            "978:\tlearn: 0.3021289\ttotal: 2m 51s\tremaining: 3.67s\n",
            "979:\tlearn: 0.3020849\ttotal: 2m 51s\tremaining: 3.5s\n",
            "980:\tlearn: 0.3017899\ttotal: 2m 51s\tremaining: 3.32s\n",
            "981:\tlearn: 0.3017412\ttotal: 2m 51s\tremaining: 3.15s\n",
            "982:\tlearn: 0.3016085\ttotal: 2m 51s\tremaining: 2.97s\n",
            "983:\tlearn: 0.3014797\ttotal: 2m 52s\tremaining: 2.8s\n",
            "984:\tlearn: 0.3014294\ttotal: 2m 52s\tremaining: 2.62s\n",
            "985:\tlearn: 0.3013283\ttotal: 2m 52s\tremaining: 2.45s\n",
            "986:\tlearn: 0.3011781\ttotal: 2m 52s\tremaining: 2.27s\n",
            "987:\tlearn: 0.3009244\ttotal: 2m 52s\tremaining: 2.1s\n",
            "988:\tlearn: 0.3008783\ttotal: 2m 52s\tremaining: 1.92s\n",
            "989:\tlearn: 0.3008106\ttotal: 2m 53s\tremaining: 1.75s\n",
            "990:\tlearn: 0.3007605\ttotal: 2m 53s\tremaining: 1.57s\n",
            "991:\tlearn: 0.3007106\ttotal: 2m 53s\tremaining: 1.4s\n",
            "992:\tlearn: 0.3005204\ttotal: 2m 53s\tremaining: 1.22s\n",
            "993:\tlearn: 0.3004720\ttotal: 2m 53s\tremaining: 1.05s\n",
            "994:\tlearn: 0.3003988\ttotal: 2m 53s\tremaining: 873ms\n",
            "995:\tlearn: 0.3000316\ttotal: 2m 54s\tremaining: 699ms\n",
            "996:\tlearn: 0.2999467\ttotal: 2m 54s\tremaining: 524ms\n",
            "997:\tlearn: 0.2997352\ttotal: 2m 54s\tremaining: 349ms\n",
            "998:\tlearn: 0.2996867\ttotal: 2m 54s\tremaining: 175ms\n",
            "999:\tlearn: 0.2992873\ttotal: 2m 54s\tremaining: 0us\n",
            "Learning rate set to 0.081655\n",
            "0:\tlearn: 1.5773177\ttotal: 159ms\tremaining: 2m 38s\n",
            "1:\tlearn: 1.5232475\ttotal: 307ms\tremaining: 2m 33s\n",
            "2:\tlearn: 1.5021108\ttotal: 484ms\tremaining: 2m 41s\n",
            "3:\tlearn: 1.4679752\ttotal: 655ms\tremaining: 2m 43s\n",
            "4:\tlearn: 1.4379564\ttotal: 801ms\tremaining: 2m 39s\n",
            "5:\tlearn: 1.4119021\ttotal: 947ms\tremaining: 2m 36s\n",
            "6:\tlearn: 1.3901024\ttotal: 1.1s\tremaining: 2m 35s\n",
            "7:\tlearn: 1.3733237\ttotal: 1.25s\tremaining: 2m 35s\n",
            "8:\tlearn: 1.3533016\ttotal: 1.4s\tremaining: 2m 34s\n",
            "9:\tlearn: 1.3411420\ttotal: 1.58s\tremaining: 2m 36s\n",
            "10:\tlearn: 1.3225954\ttotal: 1.74s\tremaining: 2m 36s\n",
            "11:\tlearn: 1.3038998\ttotal: 1.9s\tremaining: 2m 36s\n",
            "12:\tlearn: 1.2930928\ttotal: 2.04s\tremaining: 2m 34s\n",
            "13:\tlearn: 1.2788573\ttotal: 2.18s\tremaining: 2m 33s\n",
            "14:\tlearn: 1.2692516\ttotal: 2.33s\tremaining: 2m 33s\n",
            "15:\tlearn: 1.2635811\ttotal: 2.52s\tremaining: 2m 35s\n",
            "16:\tlearn: 1.2531015\ttotal: 2.68s\tremaining: 2m 34s\n",
            "17:\tlearn: 1.2454957\ttotal: 2.84s\tremaining: 2m 34s\n",
            "18:\tlearn: 1.2289818\ttotal: 2.98s\tremaining: 2m 33s\n",
            "19:\tlearn: 1.2178323\ttotal: 3.13s\tremaining: 2m 33s\n",
            "20:\tlearn: 1.2043419\ttotal: 3.3s\tremaining: 2m 33s\n",
            "21:\tlearn: 1.1983784\ttotal: 3.49s\tremaining: 2m 35s\n",
            "22:\tlearn: 1.1872658\ttotal: 3.65s\tremaining: 2m 34s\n",
            "23:\tlearn: 1.1768393\ttotal: 3.8s\tremaining: 2m 34s\n",
            "24:\tlearn: 1.1672116\ttotal: 3.94s\tremaining: 2m 33s\n",
            "25:\tlearn: 1.1626471\ttotal: 4.1s\tremaining: 2m 33s\n",
            "26:\tlearn: 1.1568916\ttotal: 4.26s\tremaining: 2m 33s\n",
            "27:\tlearn: 1.1510940\ttotal: 4.45s\tremaining: 2m 34s\n",
            "28:\tlearn: 1.1459629\ttotal: 4.62s\tremaining: 2m 34s\n",
            "29:\tlearn: 1.1390952\ttotal: 4.78s\tremaining: 2m 34s\n",
            "30:\tlearn: 1.1304392\ttotal: 4.95s\tremaining: 2m 34s\n",
            "31:\tlearn: 1.1250017\ttotal: 5.18s\tremaining: 2m 36s\n",
            "32:\tlearn: 1.1219181\ttotal: 5.38s\tremaining: 2m 37s\n",
            "33:\tlearn: 1.1153165\ttotal: 5.55s\tremaining: 2m 37s\n",
            "34:\tlearn: 1.1076687\ttotal: 5.7s\tremaining: 2m 37s\n",
            "35:\tlearn: 1.1007377\ttotal: 5.87s\tremaining: 2m 37s\n",
            "36:\tlearn: 1.0978162\ttotal: 6.05s\tremaining: 2m 37s\n",
            "37:\tlearn: 1.0923455\ttotal: 6.24s\tremaining: 2m 37s\n",
            "38:\tlearn: 1.0878794\ttotal: 6.39s\tremaining: 2m 37s\n",
            "39:\tlearn: 1.0821733\ttotal: 6.54s\tremaining: 2m 37s\n",
            "40:\tlearn: 1.0788729\ttotal: 6.69s\tremaining: 2m 36s\n",
            "41:\tlearn: 1.0720495\ttotal: 6.84s\tremaining: 2m 36s\n",
            "42:\tlearn: 1.0680014\ttotal: 6.98s\tremaining: 2m 35s\n",
            "43:\tlearn: 1.0647095\ttotal: 7.13s\tremaining: 2m 34s\n",
            "44:\tlearn: 1.0567830\ttotal: 7.32s\tremaining: 2m 35s\n",
            "45:\tlearn: 1.0490578\ttotal: 7.48s\tremaining: 2m 35s\n",
            "46:\tlearn: 1.0451691\ttotal: 7.63s\tremaining: 2m 34s\n",
            "47:\tlearn: 1.0405188\ttotal: 7.88s\tremaining: 2m 36s\n",
            "48:\tlearn: 1.0348526\ttotal: 8.11s\tremaining: 2m 37s\n",
            "49:\tlearn: 1.0285525\ttotal: 8.37s\tremaining: 2m 39s\n",
            "50:\tlearn: 1.0258369\ttotal: 8.65s\tremaining: 2m 41s\n",
            "51:\tlearn: 1.0221377\ttotal: 8.81s\tremaining: 2m 40s\n",
            "52:\tlearn: 1.0167607\ttotal: 8.97s\tremaining: 2m 40s\n",
            "53:\tlearn: 1.0131738\ttotal: 9.14s\tremaining: 2m 40s\n",
            "54:\tlearn: 1.0095977\ttotal: 9.33s\tremaining: 2m 40s\n",
            "55:\tlearn: 1.0051937\ttotal: 9.5s\tremaining: 2m 40s\n",
            "56:\tlearn: 0.9992085\ttotal: 9.7s\tremaining: 2m 40s\n",
            "57:\tlearn: 0.9951913\ttotal: 9.91s\tremaining: 2m 40s\n",
            "58:\tlearn: 0.9913426\ttotal: 10.1s\tremaining: 2m 40s\n",
            "59:\tlearn: 0.9891541\ttotal: 10.2s\tremaining: 2m 40s\n",
            "60:\tlearn: 0.9859136\ttotal: 10.4s\tremaining: 2m 39s\n",
            "61:\tlearn: 0.9829629\ttotal: 10.5s\tremaining: 2m 39s\n",
            "62:\tlearn: 0.9808620\ttotal: 10.7s\tremaining: 2m 39s\n",
            "63:\tlearn: 0.9774769\ttotal: 10.9s\tremaining: 2m 39s\n",
            "64:\tlearn: 0.9730090\ttotal: 11s\tremaining: 2m 38s\n",
            "65:\tlearn: 0.9705529\ttotal: 11.2s\tremaining: 2m 38s\n",
            "66:\tlearn: 0.9676345\ttotal: 11.4s\tremaining: 2m 38s\n",
            "67:\tlearn: 0.9643990\ttotal: 11.6s\tremaining: 2m 38s\n",
            "68:\tlearn: 0.9612118\ttotal: 11.8s\tremaining: 2m 38s\n",
            "69:\tlearn: 0.9584372\ttotal: 11.9s\tremaining: 2m 38s\n",
            "70:\tlearn: 0.9566569\ttotal: 12.1s\tremaining: 2m 38s\n",
            "71:\tlearn: 0.9529226\ttotal: 12.3s\tremaining: 2m 38s\n",
            "72:\tlearn: 0.9496400\ttotal: 12.5s\tremaining: 2m 38s\n",
            "73:\tlearn: 0.9469253\ttotal: 12.6s\tremaining: 2m 38s\n",
            "74:\tlearn: 0.9445946\ttotal: 12.8s\tremaining: 2m 37s\n",
            "75:\tlearn: 0.9414925\ttotal: 13s\tremaining: 2m 37s\n",
            "76:\tlearn: 0.9382617\ttotal: 13.1s\tremaining: 2m 37s\n",
            "77:\tlearn: 0.9345816\ttotal: 13.3s\tremaining: 2m 36s\n",
            "78:\tlearn: 0.9318482\ttotal: 13.4s\tremaining: 2m 36s\n",
            "79:\tlearn: 0.9285947\ttotal: 13.6s\tremaining: 2m 36s\n",
            "80:\tlearn: 0.9257041\ttotal: 13.8s\tremaining: 2m 36s\n",
            "81:\tlearn: 0.9223972\ttotal: 14s\tremaining: 2m 36s\n",
            "82:\tlearn: 0.9194862\ttotal: 14.2s\tremaining: 2m 36s\n",
            "83:\tlearn: 0.9151115\ttotal: 14.3s\tremaining: 2m 36s\n",
            "84:\tlearn: 0.9122297\ttotal: 14.5s\tremaining: 2m 35s\n",
            "85:\tlearn: 0.9094346\ttotal: 14.6s\tremaining: 2m 35s\n",
            "86:\tlearn: 0.9068799\ttotal: 14.8s\tremaining: 2m 35s\n",
            "87:\tlearn: 0.9033658\ttotal: 15s\tremaining: 2m 35s\n",
            "88:\tlearn: 0.8997974\ttotal: 15.1s\tremaining: 2m 35s\n",
            "89:\tlearn: 0.8951091\ttotal: 15.3s\tremaining: 2m 34s\n",
            "90:\tlearn: 0.8930977\ttotal: 15.4s\tremaining: 2m 34s\n",
            "91:\tlearn: 0.8896742\ttotal: 15.6s\tremaining: 2m 33s\n",
            "92:\tlearn: 0.8876254\ttotal: 15.7s\tremaining: 2m 33s\n",
            "93:\tlearn: 0.8841016\ttotal: 15.9s\tremaining: 2m 33s\n",
            "94:\tlearn: 0.8807438\ttotal: 16.1s\tremaining: 2m 33s\n",
            "95:\tlearn: 0.8776953\ttotal: 16.2s\tremaining: 2m 32s\n",
            "96:\tlearn: 0.8752059\ttotal: 16.4s\tremaining: 2m 32s\n",
            "97:\tlearn: 0.8720592\ttotal: 16.5s\tremaining: 2m 32s\n",
            "98:\tlearn: 0.8695417\ttotal: 16.7s\tremaining: 2m 31s\n",
            "99:\tlearn: 0.8664971\ttotal: 16.9s\tremaining: 2m 31s\n",
            "100:\tlearn: 0.8631669\ttotal: 17s\tremaining: 2m 31s\n",
            "101:\tlearn: 0.8590968\ttotal: 17.2s\tremaining: 2m 31s\n",
            "102:\tlearn: 0.8561771\ttotal: 17.3s\tremaining: 2m 31s\n",
            "103:\tlearn: 0.8537679\ttotal: 17.5s\tremaining: 2m 31s\n",
            "104:\tlearn: 0.8510211\ttotal: 17.7s\tremaining: 2m 31s\n",
            "105:\tlearn: 0.8439252\ttotal: 17.9s\tremaining: 2m 30s\n",
            "106:\tlearn: 0.8410685\ttotal: 18s\tremaining: 2m 30s\n",
            "107:\tlearn: 0.8378216\ttotal: 18.2s\tremaining: 2m 30s\n",
            "108:\tlearn: 0.8348788\ttotal: 18.4s\tremaining: 2m 30s\n",
            "109:\tlearn: 0.8295514\ttotal: 18.5s\tremaining: 2m 29s\n",
            "110:\tlearn: 0.8263802\ttotal: 18.7s\tremaining: 2m 29s\n",
            "111:\tlearn: 0.8228057\ttotal: 18.9s\tremaining: 2m 29s\n",
            "112:\tlearn: 0.8207068\ttotal: 19.1s\tremaining: 2m 29s\n",
            "113:\tlearn: 0.8179893\ttotal: 19.2s\tremaining: 2m 29s\n",
            "114:\tlearn: 0.8152044\ttotal: 19.4s\tremaining: 2m 29s\n",
            "115:\tlearn: 0.8108696\ttotal: 19.6s\tremaining: 2m 29s\n",
            "116:\tlearn: 0.8069081\ttotal: 19.7s\tremaining: 2m 29s\n",
            "117:\tlearn: 0.8032634\ttotal: 19.9s\tremaining: 2m 28s\n",
            "118:\tlearn: 0.8003092\ttotal: 20s\tremaining: 2m 28s\n",
            "119:\tlearn: 0.7951721\ttotal: 20.2s\tremaining: 2m 28s\n",
            "120:\tlearn: 0.7922682\ttotal: 20.4s\tremaining: 2m 27s\n",
            "121:\tlearn: 0.7889134\ttotal: 20.5s\tremaining: 2m 27s\n",
            "122:\tlearn: 0.7860455\ttotal: 20.7s\tremaining: 2m 27s\n",
            "123:\tlearn: 0.7831925\ttotal: 20.8s\tremaining: 2m 27s\n",
            "124:\tlearn: 0.7794718\ttotal: 21s\tremaining: 2m 26s\n",
            "125:\tlearn: 0.7768037\ttotal: 21.1s\tremaining: 2m 26s\n",
            "126:\tlearn: 0.7747595\ttotal: 21.3s\tremaining: 2m 26s\n",
            "127:\tlearn: 0.7725536\ttotal: 21.5s\tremaining: 2m 26s\n",
            "128:\tlearn: 0.7704369\ttotal: 21.6s\tremaining: 2m 26s\n",
            "129:\tlearn: 0.7680554\ttotal: 21.8s\tremaining: 2m 25s\n",
            "130:\tlearn: 0.7658272\ttotal: 21.9s\tremaining: 2m 25s\n",
            "131:\tlearn: 0.7638811\ttotal: 22.1s\tremaining: 2m 25s\n",
            "132:\tlearn: 0.7607972\ttotal: 22.2s\tremaining: 2m 24s\n",
            "133:\tlearn: 0.7586048\ttotal: 22.4s\tremaining: 2m 24s\n",
            "134:\tlearn: 0.7561922\ttotal: 22.6s\tremaining: 2m 24s\n",
            "135:\tlearn: 0.7531636\ttotal: 22.7s\tremaining: 2m 24s\n",
            "136:\tlearn: 0.7497722\ttotal: 22.9s\tremaining: 2m 24s\n",
            "137:\tlearn: 0.7473679\ttotal: 23s\tremaining: 2m 23s\n",
            "138:\tlearn: 0.7454488\ttotal: 23.2s\tremaining: 2m 23s\n",
            "139:\tlearn: 0.7427150\ttotal: 23.4s\tremaining: 2m 23s\n",
            "140:\tlearn: 0.7398922\ttotal: 23.5s\tremaining: 2m 23s\n",
            "141:\tlearn: 0.7382195\ttotal: 23.7s\tremaining: 2m 23s\n",
            "142:\tlearn: 0.7366107\ttotal: 23.9s\tremaining: 2m 23s\n",
            "143:\tlearn: 0.7343626\ttotal: 24s\tremaining: 2m 22s\n",
            "144:\tlearn: 0.7325378\ttotal: 24.2s\tremaining: 2m 22s\n",
            "145:\tlearn: 0.7288444\ttotal: 24.4s\tremaining: 2m 22s\n",
            "146:\tlearn: 0.7260235\ttotal: 24.6s\tremaining: 2m 22s\n",
            "147:\tlearn: 0.7242142\ttotal: 24.7s\tremaining: 2m 22s\n",
            "148:\tlearn: 0.7216598\ttotal: 24.9s\tremaining: 2m 22s\n",
            "149:\tlearn: 0.7199560\ttotal: 25.1s\tremaining: 2m 22s\n",
            "150:\tlearn: 0.7177419\ttotal: 25.2s\tremaining: 2m 21s\n",
            "151:\tlearn: 0.7159350\ttotal: 25.4s\tremaining: 2m 21s\n",
            "152:\tlearn: 0.7138140\ttotal: 25.6s\tremaining: 2m 21s\n",
            "153:\tlearn: 0.7124175\ttotal: 25.7s\tremaining: 2m 21s\n",
            "154:\tlearn: 0.7105797\ttotal: 26s\tremaining: 2m 21s\n",
            "155:\tlearn: 0.7078106\ttotal: 26.1s\tremaining: 2m 21s\n",
            "156:\tlearn: 0.7062433\ttotal: 26.3s\tremaining: 2m 21s\n",
            "157:\tlearn: 0.7040579\ttotal: 26.4s\tremaining: 2m 20s\n",
            "158:\tlearn: 0.6997929\ttotal: 26.6s\tremaining: 2m 20s\n",
            "159:\tlearn: 0.6983987\ttotal: 26.7s\tremaining: 2m 20s\n",
            "160:\tlearn: 0.6972476\ttotal: 26.9s\tremaining: 2m 20s\n",
            "161:\tlearn: 0.6946573\ttotal: 27s\tremaining: 2m 19s\n",
            "162:\tlearn: 0.6929480\ttotal: 27.2s\tremaining: 2m 19s\n",
            "163:\tlearn: 0.6913376\ttotal: 27.4s\tremaining: 2m 19s\n",
            "164:\tlearn: 0.6898993\ttotal: 27.6s\tremaining: 2m 19s\n",
            "165:\tlearn: 0.6882375\ttotal: 27.7s\tremaining: 2m 19s\n",
            "166:\tlearn: 0.6861567\ttotal: 27.9s\tremaining: 2m 18s\n",
            "167:\tlearn: 0.6849162\ttotal: 28s\tremaining: 2m 18s\n",
            "168:\tlearn: 0.6830327\ttotal: 28.2s\tremaining: 2m 18s\n",
            "169:\tlearn: 0.6817430\ttotal: 28.3s\tremaining: 2m 18s\n",
            "170:\tlearn: 0.6787696\ttotal: 28.5s\tremaining: 2m 18s\n",
            "171:\tlearn: 0.6770586\ttotal: 28.6s\tremaining: 2m 17s\n",
            "172:\tlearn: 0.6752862\ttotal: 28.8s\tremaining: 2m 17s\n",
            "173:\tlearn: 0.6735885\ttotal: 28.9s\tremaining: 2m 17s\n",
            "174:\tlearn: 0.6715242\ttotal: 29.1s\tremaining: 2m 17s\n",
            "175:\tlearn: 0.6699253\ttotal: 29.3s\tremaining: 2m 16s\n",
            "176:\tlearn: 0.6680192\ttotal: 29.4s\tremaining: 2m 16s\n",
            "177:\tlearn: 0.6658005\ttotal: 29.6s\tremaining: 2m 16s\n",
            "178:\tlearn: 0.6636655\ttotal: 29.8s\tremaining: 2m 16s\n",
            "179:\tlearn: 0.6616470\ttotal: 29.9s\tremaining: 2m 16s\n",
            "180:\tlearn: 0.6604329\ttotal: 30.1s\tremaining: 2m 16s\n",
            "181:\tlearn: 0.6584025\ttotal: 30.2s\tremaining: 2m 15s\n",
            "182:\tlearn: 0.6568217\ttotal: 30.4s\tremaining: 2m 15s\n",
            "183:\tlearn: 0.6556944\ttotal: 30.5s\tremaining: 2m 15s\n",
            "184:\tlearn: 0.6545410\ttotal: 30.7s\tremaining: 2m 15s\n",
            "185:\tlearn: 0.6532149\ttotal: 30.9s\tremaining: 2m 15s\n",
            "186:\tlearn: 0.6512310\ttotal: 31s\tremaining: 2m 14s\n",
            "187:\tlearn: 0.6493921\ttotal: 31.2s\tremaining: 2m 14s\n",
            "188:\tlearn: 0.6477182\ttotal: 31.4s\tremaining: 2m 14s\n",
            "189:\tlearn: 0.6461499\ttotal: 31.5s\tremaining: 2m 14s\n",
            "190:\tlearn: 0.6453366\ttotal: 31.7s\tremaining: 2m 14s\n",
            "191:\tlearn: 0.6442340\ttotal: 31.9s\tremaining: 2m 14s\n",
            "192:\tlearn: 0.6421965\ttotal: 32.1s\tremaining: 2m 14s\n",
            "193:\tlearn: 0.6400777\ttotal: 32.2s\tremaining: 2m 13s\n",
            "194:\tlearn: 0.6392384\ttotal: 32.4s\tremaining: 2m 13s\n",
            "195:\tlearn: 0.6377153\ttotal: 32.5s\tremaining: 2m 13s\n",
            "196:\tlearn: 0.6359512\ttotal: 32.8s\tremaining: 2m 13s\n",
            "197:\tlearn: 0.6343156\ttotal: 32.9s\tremaining: 2m 13s\n",
            "198:\tlearn: 0.6330692\ttotal: 33.1s\tremaining: 2m 13s\n",
            "199:\tlearn: 0.6322984\ttotal: 33.3s\tremaining: 2m 13s\n",
            "200:\tlearn: 0.6307928\ttotal: 33.4s\tremaining: 2m 12s\n",
            "201:\tlearn: 0.6289824\ttotal: 33.6s\tremaining: 2m 12s\n",
            "202:\tlearn: 0.6277614\ttotal: 33.7s\tremaining: 2m 12s\n",
            "203:\tlearn: 0.6262448\ttotal: 33.9s\tremaining: 2m 12s\n",
            "204:\tlearn: 0.6246897\ttotal: 34s\tremaining: 2m 12s\n",
            "205:\tlearn: 0.6239884\ttotal: 34.2s\tremaining: 2m 11s\n",
            "206:\tlearn: 0.6230519\ttotal: 34.3s\tremaining: 2m 11s\n",
            "207:\tlearn: 0.6217498\ttotal: 34.5s\tremaining: 2m 11s\n",
            "208:\tlearn: 0.6204145\ttotal: 34.6s\tremaining: 2m 11s\n",
            "209:\tlearn: 0.6189121\ttotal: 34.8s\tremaining: 2m 10s\n",
            "210:\tlearn: 0.6181083\ttotal: 34.9s\tremaining: 2m 10s\n",
            "211:\tlearn: 0.6167378\ttotal: 35.1s\tremaining: 2m 10s\n",
            "212:\tlearn: 0.6158474\ttotal: 35.3s\tremaining: 2m 10s\n",
            "213:\tlearn: 0.6150975\ttotal: 35.4s\tremaining: 2m 10s\n",
            "214:\tlearn: 0.6138758\ttotal: 35.5s\tremaining: 2m 9s\n",
            "215:\tlearn: 0.6125981\ttotal: 35.7s\tremaining: 2m 9s\n",
            "216:\tlearn: 0.6119139\ttotal: 35.8s\tremaining: 2m 9s\n",
            "217:\tlearn: 0.6110929\ttotal: 36s\tremaining: 2m 9s\n",
            "218:\tlearn: 0.6089598\ttotal: 36.2s\tremaining: 2m 9s\n",
            "219:\tlearn: 0.6084035\ttotal: 36.3s\tremaining: 2m 8s\n",
            "220:\tlearn: 0.6068001\ttotal: 36.5s\tremaining: 2m 8s\n",
            "221:\tlearn: 0.6055675\ttotal: 36.6s\tremaining: 2m 8s\n",
            "222:\tlearn: 0.6040431\ttotal: 36.8s\tremaining: 2m 8s\n",
            "223:\tlearn: 0.6032691\ttotal: 37s\tremaining: 2m 8s\n",
            "224:\tlearn: 0.6020607\ttotal: 37.2s\tremaining: 2m 7s\n",
            "225:\tlearn: 0.6004834\ttotal: 37.3s\tremaining: 2m 7s\n",
            "226:\tlearn: 0.5998626\ttotal: 37.5s\tremaining: 2m 7s\n",
            "227:\tlearn: 0.5992643\ttotal: 37.6s\tremaining: 2m 7s\n",
            "228:\tlearn: 0.5982223\ttotal: 37.8s\tremaining: 2m 7s\n",
            "229:\tlearn: 0.5965562\ttotal: 38s\tremaining: 2m 7s\n",
            "230:\tlearn: 0.5951686\ttotal: 38.2s\tremaining: 2m 7s\n",
            "231:\tlearn: 0.5934271\ttotal: 38.3s\tremaining: 2m 6s\n",
            "232:\tlearn: 0.5925545\ttotal: 38.5s\tremaining: 2m 6s\n",
            "233:\tlearn: 0.5915914\ttotal: 38.7s\tremaining: 2m 6s\n",
            "234:\tlearn: 0.5910775\ttotal: 38.9s\tremaining: 2m 6s\n",
            "235:\tlearn: 0.5904243\ttotal: 39s\tremaining: 2m 6s\n",
            "236:\tlearn: 0.5888489\ttotal: 39.2s\tremaining: 2m 6s\n",
            "237:\tlearn: 0.5875717\ttotal: 39.3s\tremaining: 2m 5s\n",
            "238:\tlearn: 0.5869618\ttotal: 39.5s\tremaining: 2m 5s\n",
            "239:\tlearn: 0.5854090\ttotal: 39.7s\tremaining: 2m 5s\n",
            "240:\tlearn: 0.5844648\ttotal: 39.8s\tremaining: 2m 5s\n",
            "241:\tlearn: 0.5831389\ttotal: 40s\tremaining: 2m 5s\n",
            "242:\tlearn: 0.5814803\ttotal: 40.1s\tremaining: 2m 4s\n",
            "243:\tlearn: 0.5800279\ttotal: 40.2s\tremaining: 2m 4s\n",
            "244:\tlearn: 0.5788738\ttotal: 40.4s\tremaining: 2m 4s\n",
            "245:\tlearn: 0.5777722\ttotal: 40.5s\tremaining: 2m 4s\n",
            "246:\tlearn: 0.5765342\ttotal: 40.7s\tremaining: 2m 4s\n",
            "247:\tlearn: 0.5757928\ttotal: 40.9s\tremaining: 2m 3s\n",
            "248:\tlearn: 0.5753361\ttotal: 41s\tremaining: 2m 3s\n",
            "249:\tlearn: 0.5745548\ttotal: 41.2s\tremaining: 2m 3s\n",
            "250:\tlearn: 0.5736874\ttotal: 41.3s\tremaining: 2m 3s\n",
            "251:\tlearn: 0.5724311\ttotal: 41.5s\tremaining: 2m 3s\n",
            "252:\tlearn: 0.5716799\ttotal: 41.7s\tremaining: 2m 3s\n",
            "253:\tlearn: 0.5700845\ttotal: 41.9s\tremaining: 2m 2s\n",
            "254:\tlearn: 0.5685816\ttotal: 42s\tremaining: 2m 2s\n",
            "255:\tlearn: 0.5680852\ttotal: 42.2s\tremaining: 2m 2s\n",
            "256:\tlearn: 0.5668294\ttotal: 42.4s\tremaining: 2m 2s\n",
            "257:\tlearn: 0.5657211\ttotal: 42.6s\tremaining: 2m 2s\n",
            "258:\tlearn: 0.5645897\ttotal: 42.7s\tremaining: 2m 2s\n",
            "259:\tlearn: 0.5641556\ttotal: 42.9s\tremaining: 2m 2s\n",
            "260:\tlearn: 0.5634424\ttotal: 43s\tremaining: 2m 1s\n",
            "261:\tlearn: 0.5628058\ttotal: 43.2s\tremaining: 2m 1s\n",
            "262:\tlearn: 0.5615996\ttotal: 43.4s\tremaining: 2m 1s\n",
            "263:\tlearn: 0.5610351\ttotal: 43.5s\tremaining: 2m 1s\n",
            "264:\tlearn: 0.5598497\ttotal: 43.7s\tremaining: 2m 1s\n",
            "265:\tlearn: 0.5594255\ttotal: 43.9s\tremaining: 2m 1s\n",
            "266:\tlearn: 0.5584817\ttotal: 44s\tremaining: 2m\n",
            "267:\tlearn: 0.5579571\ttotal: 44.2s\tremaining: 2m\n",
            "268:\tlearn: 0.5573805\ttotal: 44.4s\tremaining: 2m\n",
            "269:\tlearn: 0.5564982\ttotal: 44.6s\tremaining: 2m\n",
            "270:\tlearn: 0.5554024\ttotal: 44.8s\tremaining: 2m\n",
            "271:\tlearn: 0.5549028\ttotal: 44.9s\tremaining: 2m\n",
            "272:\tlearn: 0.5545208\ttotal: 45.1s\tremaining: 2m\n",
            "273:\tlearn: 0.5526031\ttotal: 45.2s\tremaining: 1m 59s\n",
            "274:\tlearn: 0.5519384\ttotal: 45.4s\tremaining: 1m 59s\n",
            "275:\tlearn: 0.5510068\ttotal: 45.6s\tremaining: 1m 59s\n",
            "276:\tlearn: 0.5505181\ttotal: 45.8s\tremaining: 1m 59s\n",
            "277:\tlearn: 0.5494409\ttotal: 45.9s\tremaining: 1m 59s\n",
            "278:\tlearn: 0.5490235\ttotal: 46.1s\tremaining: 1m 59s\n",
            "279:\tlearn: 0.5485527\ttotal: 46.2s\tremaining: 1m 58s\n",
            "280:\tlearn: 0.5479020\ttotal: 46.4s\tremaining: 1m 58s\n",
            "281:\tlearn: 0.5473751\ttotal: 46.6s\tremaining: 1m 58s\n",
            "282:\tlearn: 0.5466038\ttotal: 46.7s\tremaining: 1m 58s\n",
            "283:\tlearn: 0.5461356\ttotal: 46.9s\tremaining: 1m 58s\n",
            "284:\tlearn: 0.5458161\ttotal: 47s\tremaining: 1m 58s\n",
            "285:\tlearn: 0.5447672\ttotal: 47.2s\tremaining: 1m 57s\n",
            "286:\tlearn: 0.5443596\ttotal: 47.3s\tremaining: 1m 57s\n",
            "287:\tlearn: 0.5437194\ttotal: 47.5s\tremaining: 1m 57s\n",
            "288:\tlearn: 0.5432492\ttotal: 47.7s\tremaining: 1m 57s\n",
            "289:\tlearn: 0.5415098\ttotal: 47.8s\tremaining: 1m 57s\n",
            "290:\tlearn: 0.5399749\ttotal: 48s\tremaining: 1m 56s\n",
            "291:\tlearn: 0.5388491\ttotal: 48.1s\tremaining: 1m 56s\n",
            "292:\tlearn: 0.5381160\ttotal: 48.3s\tremaining: 1m 56s\n",
            "293:\tlearn: 0.5377959\ttotal: 48.4s\tremaining: 1m 56s\n",
            "294:\tlearn: 0.5365718\ttotal: 48.6s\tremaining: 1m 56s\n",
            "295:\tlearn: 0.5361588\ttotal: 48.8s\tremaining: 1m 55s\n",
            "296:\tlearn: 0.5349835\ttotal: 49s\tremaining: 1m 55s\n",
            "297:\tlearn: 0.5343918\ttotal: 49.1s\tremaining: 1m 55s\n",
            "298:\tlearn: 0.5333862\ttotal: 49.2s\tremaining: 1m 55s\n",
            "299:\tlearn: 0.5324651\ttotal: 49.4s\tremaining: 1m 55s\n",
            "300:\tlearn: 0.5316220\ttotal: 49.5s\tremaining: 1m 55s\n",
            "301:\tlearn: 0.5309523\ttotal: 49.7s\tremaining: 1m 54s\n",
            "302:\tlearn: 0.5306339\ttotal: 49.9s\tremaining: 1m 54s\n",
            "303:\tlearn: 0.5302669\ttotal: 50s\tremaining: 1m 54s\n",
            "304:\tlearn: 0.5299579\ttotal: 50.2s\tremaining: 1m 54s\n",
            "305:\tlearn: 0.5290421\ttotal: 50.4s\tremaining: 1m 54s\n",
            "306:\tlearn: 0.5286491\ttotal: 50.5s\tremaining: 1m 54s\n",
            "307:\tlearn: 0.5269948\ttotal: 50.7s\tremaining: 1m 53s\n",
            "308:\tlearn: 0.5255734\ttotal: 50.9s\tremaining: 1m 53s\n",
            "309:\tlearn: 0.5247668\ttotal: 51.1s\tremaining: 1m 53s\n",
            "310:\tlearn: 0.5241957\ttotal: 51.2s\tremaining: 1m 53s\n",
            "311:\tlearn: 0.5239009\ttotal: 51.4s\tremaining: 1m 53s\n",
            "312:\tlearn: 0.5228552\ttotal: 51.5s\tremaining: 1m 53s\n",
            "313:\tlearn: 0.5223854\ttotal: 51.7s\tremaining: 1m 53s\n",
            "314:\tlearn: 0.5220140\ttotal: 51.9s\tremaining: 1m 52s\n",
            "315:\tlearn: 0.5217360\ttotal: 52s\tremaining: 1m 52s\n",
            "316:\tlearn: 0.5213388\ttotal: 52.2s\tremaining: 1m 52s\n",
            "317:\tlearn: 0.5208272\ttotal: 52.3s\tremaining: 1m 52s\n",
            "318:\tlearn: 0.5204881\ttotal: 52.5s\tremaining: 1m 52s\n",
            "319:\tlearn: 0.5196846\ttotal: 52.7s\tremaining: 1m 51s\n",
            "320:\tlearn: 0.5187322\ttotal: 52.8s\tremaining: 1m 51s\n",
            "321:\tlearn: 0.5173955\ttotal: 52.9s\tremaining: 1m 51s\n",
            "322:\tlearn: 0.5162947\ttotal: 53.1s\tremaining: 1m 51s\n",
            "323:\tlearn: 0.5154581\ttotal: 53.2s\tremaining: 1m 51s\n",
            "324:\tlearn: 0.5145822\ttotal: 53.4s\tremaining: 1m 50s\n",
            "325:\tlearn: 0.5144164\ttotal: 53.6s\tremaining: 1m 50s\n",
            "326:\tlearn: 0.5137665\ttotal: 53.7s\tremaining: 1m 50s\n",
            "327:\tlearn: 0.5132949\ttotal: 53.9s\tremaining: 1m 50s\n",
            "328:\tlearn: 0.5128415\ttotal: 54s\tremaining: 1m 50s\n",
            "329:\tlearn: 0.5119509\ttotal: 54.2s\tremaining: 1m 49s\n",
            "330:\tlearn: 0.5115845\ttotal: 54.3s\tremaining: 1m 49s\n",
            "331:\tlearn: 0.5108809\ttotal: 54.5s\tremaining: 1m 49s\n",
            "332:\tlearn: 0.5101047\ttotal: 54.7s\tremaining: 1m 49s\n",
            "333:\tlearn: 0.5099523\ttotal: 54.8s\tremaining: 1m 49s\n",
            "334:\tlearn: 0.5098191\ttotal: 55s\tremaining: 1m 49s\n",
            "335:\tlearn: 0.5094925\ttotal: 55.1s\tremaining: 1m 48s\n",
            "336:\tlearn: 0.5093445\ttotal: 55.2s\tremaining: 1m 48s\n",
            "337:\tlearn: 0.5082497\ttotal: 55.4s\tremaining: 1m 48s\n",
            "338:\tlearn: 0.5078811\ttotal: 55.6s\tremaining: 1m 48s\n",
            "339:\tlearn: 0.5069317\ttotal: 55.8s\tremaining: 1m 48s\n",
            "340:\tlearn: 0.5063388\ttotal: 55.9s\tremaining: 1m 48s\n",
            "341:\tlearn: 0.5061895\ttotal: 56.1s\tremaining: 1m 47s\n",
            "342:\tlearn: 0.5058964\ttotal: 56.3s\tremaining: 1m 47s\n",
            "343:\tlearn: 0.5057640\ttotal: 56.5s\tremaining: 1m 47s\n",
            "344:\tlearn: 0.5053200\ttotal: 56.7s\tremaining: 1m 47s\n",
            "345:\tlearn: 0.5046952\ttotal: 56.8s\tremaining: 1m 47s\n",
            "346:\tlearn: 0.5045653\ttotal: 57s\tremaining: 1m 47s\n",
            "347:\tlearn: 0.5040917\ttotal: 57.1s\tremaining: 1m 47s\n",
            "348:\tlearn: 0.5031613\ttotal: 57.3s\tremaining: 1m 46s\n",
            "349:\tlearn: 0.5028021\ttotal: 57.5s\tremaining: 1m 46s\n",
            "350:\tlearn: 0.5022953\ttotal: 57.7s\tremaining: 1m 46s\n",
            "351:\tlearn: 0.5013197\ttotal: 57.9s\tremaining: 1m 46s\n",
            "352:\tlearn: 0.4997617\ttotal: 58s\tremaining: 1m 46s\n",
            "353:\tlearn: 0.4986974\ttotal: 58.2s\tremaining: 1m 46s\n",
            "354:\tlearn: 0.4983826\ttotal: 58.3s\tremaining: 1m 45s\n",
            "355:\tlearn: 0.4976411\ttotal: 58.5s\tremaining: 1m 45s\n",
            "356:\tlearn: 0.4973424\ttotal: 58.7s\tremaining: 1m 45s\n",
            "357:\tlearn: 0.4964795\ttotal: 58.9s\tremaining: 1m 45s\n",
            "358:\tlearn: 0.4956028\ttotal: 59.1s\tremaining: 1m 45s\n",
            "359:\tlearn: 0.4951514\ttotal: 59.3s\tremaining: 1m 45s\n",
            "360:\tlearn: 0.4948214\ttotal: 59.6s\tremaining: 1m 45s\n",
            "361:\tlearn: 0.4946621\ttotal: 59.8s\tremaining: 1m 45s\n",
            "362:\tlearn: 0.4945457\ttotal: 60s\tremaining: 1m 45s\n",
            "363:\tlearn: 0.4940381\ttotal: 1m\tremaining: 1m 45s\n",
            "364:\tlearn: 0.4938999\ttotal: 1m\tremaining: 1m 44s\n",
            "365:\tlearn: 0.4934754\ttotal: 1m\tremaining: 1m 44s\n",
            "366:\tlearn: 0.4932012\ttotal: 1m\tremaining: 1m 44s\n",
            "367:\tlearn: 0.4928354\ttotal: 1m\tremaining: 1m 44s\n",
            "368:\tlearn: 0.4914204\ttotal: 1m 1s\tremaining: 1m 44s\n",
            "369:\tlearn: 0.4911080\ttotal: 1m 1s\tremaining: 1m 44s\n",
            "370:\tlearn: 0.4907097\ttotal: 1m 1s\tremaining: 1m 44s\n",
            "371:\tlearn: 0.4905728\ttotal: 1m 1s\tremaining: 1m 43s\n",
            "372:\tlearn: 0.4900109\ttotal: 1m 1s\tremaining: 1m 43s\n",
            "373:\tlearn: 0.4885553\ttotal: 1m 1s\tremaining: 1m 43s\n",
            "374:\tlearn: 0.4880949\ttotal: 1m 2s\tremaining: 1m 43s\n",
            "375:\tlearn: 0.4871608\ttotal: 1m 2s\tremaining: 1m 43s\n",
            "376:\tlearn: 0.4868227\ttotal: 1m 2s\tremaining: 1m 42s\n",
            "377:\tlearn: 0.4862761\ttotal: 1m 2s\tremaining: 1m 42s\n",
            "378:\tlearn: 0.4861112\ttotal: 1m 2s\tremaining: 1m 42s\n",
            "379:\tlearn: 0.4852409\ttotal: 1m 2s\tremaining: 1m 42s\n",
            "380:\tlearn: 0.4845248\ttotal: 1m 3s\tremaining: 1m 42s\n",
            "381:\tlearn: 0.4838444\ttotal: 1m 3s\tremaining: 1m 42s\n",
            "382:\tlearn: 0.4836924\ttotal: 1m 3s\tremaining: 1m 41s\n",
            "383:\tlearn: 0.4833967\ttotal: 1m 3s\tremaining: 1m 41s\n",
            "384:\tlearn: 0.4822452\ttotal: 1m 3s\tremaining: 1m 41s\n",
            "385:\tlearn: 0.4815691\ttotal: 1m 3s\tremaining: 1m 41s\n",
            "386:\tlearn: 0.4811232\ttotal: 1m 4s\tremaining: 1m 41s\n",
            "387:\tlearn: 0.4809731\ttotal: 1m 4s\tremaining: 1m 41s\n",
            "388:\tlearn: 0.4807294\ttotal: 1m 4s\tremaining: 1m 41s\n",
            "389:\tlearn: 0.4803188\ttotal: 1m 4s\tremaining: 1m 40s\n",
            "390:\tlearn: 0.4800347\ttotal: 1m 4s\tremaining: 1m 40s\n",
            "391:\tlearn: 0.4799140\ttotal: 1m 4s\tremaining: 1m 40s\n",
            "392:\tlearn: 0.4797670\ttotal: 1m 5s\tremaining: 1m 40s\n",
            "393:\tlearn: 0.4795088\ttotal: 1m 5s\tremaining: 1m 40s\n",
            "394:\tlearn: 0.4791756\ttotal: 1m 5s\tremaining: 1m 40s\n",
            "395:\tlearn: 0.4786700\ttotal: 1m 5s\tremaining: 1m 40s\n",
            "396:\tlearn: 0.4785531\ttotal: 1m 5s\tremaining: 1m 39s\n",
            "397:\tlearn: 0.4777444\ttotal: 1m 5s\tremaining: 1m 39s\n",
            "398:\tlearn: 0.4774440\ttotal: 1m 6s\tremaining: 1m 39s\n",
            "399:\tlearn: 0.4769905\ttotal: 1m 6s\tremaining: 1m 39s\n",
            "400:\tlearn: 0.4761999\ttotal: 1m 6s\tremaining: 1m 39s\n",
            "401:\tlearn: 0.4759456\ttotal: 1m 6s\tremaining: 1m 39s\n",
            "402:\tlearn: 0.4747883\ttotal: 1m 6s\tremaining: 1m 38s\n",
            "403:\tlearn: 0.4744355\ttotal: 1m 6s\tremaining: 1m 38s\n",
            "404:\tlearn: 0.4738915\ttotal: 1m 7s\tremaining: 1m 38s\n",
            "405:\tlearn: 0.4736964\ttotal: 1m 7s\tremaining: 1m 38s\n",
            "406:\tlearn: 0.4729224\ttotal: 1m 7s\tremaining: 1m 38s\n",
            "407:\tlearn: 0.4719493\ttotal: 1m 7s\tremaining: 1m 37s\n",
            "408:\tlearn: 0.4712595\ttotal: 1m 7s\tremaining: 1m 37s\n",
            "409:\tlearn: 0.4701049\ttotal: 1m 7s\tremaining: 1m 37s\n",
            "410:\tlearn: 0.4697788\ttotal: 1m 8s\tremaining: 1m 37s\n",
            "411:\tlearn: 0.4693614\ttotal: 1m 8s\tremaining: 1m 37s\n",
            "412:\tlearn: 0.4690786\ttotal: 1m 8s\tremaining: 1m 37s\n",
            "413:\tlearn: 0.4688344\ttotal: 1m 8s\tremaining: 1m 37s\n",
            "414:\tlearn: 0.4685817\ttotal: 1m 8s\tremaining: 1m 36s\n",
            "415:\tlearn: 0.4671983\ttotal: 1m 8s\tremaining: 1m 36s\n",
            "416:\tlearn: 0.4667388\ttotal: 1m 9s\tremaining: 1m 36s\n",
            "417:\tlearn: 0.4663345\ttotal: 1m 9s\tremaining: 1m 36s\n",
            "418:\tlearn: 0.4660144\ttotal: 1m 9s\tremaining: 1m 36s\n",
            "419:\tlearn: 0.4658156\ttotal: 1m 9s\tremaining: 1m 36s\n",
            "420:\tlearn: 0.4655316\ttotal: 1m 9s\tremaining: 1m 36s\n",
            "421:\tlearn: 0.4652925\ttotal: 1m 10s\tremaining: 1m 35s\n",
            "422:\tlearn: 0.4644404\ttotal: 1m 10s\tremaining: 1m 35s\n",
            "423:\tlearn: 0.4634527\ttotal: 1m 10s\tremaining: 1m 35s\n",
            "424:\tlearn: 0.4627358\ttotal: 1m 10s\tremaining: 1m 35s\n",
            "425:\tlearn: 0.4622265\ttotal: 1m 10s\tremaining: 1m 35s\n",
            "426:\tlearn: 0.4613769\ttotal: 1m 10s\tremaining: 1m 35s\n",
            "427:\tlearn: 0.4608630\ttotal: 1m 11s\tremaining: 1m 34s\n",
            "428:\tlearn: 0.4605313\ttotal: 1m 11s\tremaining: 1m 34s\n",
            "429:\tlearn: 0.4597087\ttotal: 1m 11s\tremaining: 1m 34s\n",
            "430:\tlearn: 0.4594166\ttotal: 1m 11s\tremaining: 1m 34s\n",
            "431:\tlearn: 0.4591852\ttotal: 1m 11s\tremaining: 1m 34s\n",
            "432:\tlearn: 0.4584097\ttotal: 1m 11s\tremaining: 1m 34s\n",
            "433:\tlearn: 0.4582082\ttotal: 1m 12s\tremaining: 1m 34s\n",
            "434:\tlearn: 0.4575039\ttotal: 1m 12s\tremaining: 1m 33s\n",
            "435:\tlearn: 0.4572001\ttotal: 1m 12s\tremaining: 1m 33s\n",
            "436:\tlearn: 0.4567189\ttotal: 1m 12s\tremaining: 1m 33s\n",
            "437:\tlearn: 0.4562166\ttotal: 1m 12s\tremaining: 1m 33s\n",
            "438:\tlearn: 0.4559690\ttotal: 1m 12s\tremaining: 1m 33s\n",
            "439:\tlearn: 0.4557795\ttotal: 1m 13s\tremaining: 1m 33s\n",
            "440:\tlearn: 0.4555919\ttotal: 1m 13s\tremaining: 1m 32s\n",
            "441:\tlearn: 0.4554580\ttotal: 1m 13s\tremaining: 1m 32s\n",
            "442:\tlearn: 0.4550241\ttotal: 1m 13s\tremaining: 1m 32s\n",
            "443:\tlearn: 0.4547049\ttotal: 1m 13s\tremaining: 1m 32s\n",
            "444:\tlearn: 0.4542506\ttotal: 1m 13s\tremaining: 1m 32s\n",
            "445:\tlearn: 0.4539295\ttotal: 1m 14s\tremaining: 1m 31s\n",
            "446:\tlearn: 0.4537078\ttotal: 1m 14s\tremaining: 1m 31s\n",
            "447:\tlearn: 0.4535862\ttotal: 1m 14s\tremaining: 1m 31s\n",
            "448:\tlearn: 0.4530754\ttotal: 1m 14s\tremaining: 1m 31s\n",
            "449:\tlearn: 0.4525356\ttotal: 1m 14s\tremaining: 1m 31s\n",
            "450:\tlearn: 0.4524101\ttotal: 1m 14s\tremaining: 1m 31s\n",
            "451:\tlearn: 0.4513684\ttotal: 1m 15s\tremaining: 1m 30s\n",
            "452:\tlearn: 0.4511279\ttotal: 1m 15s\tremaining: 1m 30s\n",
            "453:\tlearn: 0.4508759\ttotal: 1m 15s\tremaining: 1m 30s\n",
            "454:\tlearn: 0.4505414\ttotal: 1m 15s\tremaining: 1m 30s\n",
            "455:\tlearn: 0.4500753\ttotal: 1m 15s\tremaining: 1m 30s\n",
            "456:\tlearn: 0.4497141\ttotal: 1m 15s\tremaining: 1m 30s\n",
            "457:\tlearn: 0.4493035\ttotal: 1m 15s\tremaining: 1m 29s\n",
            "458:\tlearn: 0.4486754\ttotal: 1m 16s\tremaining: 1m 29s\n",
            "459:\tlearn: 0.4484209\ttotal: 1m 16s\tremaining: 1m 29s\n",
            "460:\tlearn: 0.4477980\ttotal: 1m 16s\tremaining: 1m 29s\n",
            "461:\tlearn: 0.4474634\ttotal: 1m 16s\tremaining: 1m 29s\n",
            "462:\tlearn: 0.4473266\ttotal: 1m 16s\tremaining: 1m 29s\n",
            "463:\tlearn: 0.4468732\ttotal: 1m 16s\tremaining: 1m 28s\n",
            "464:\tlearn: 0.4464338\ttotal: 1m 17s\tremaining: 1m 28s\n",
            "465:\tlearn: 0.4461825\ttotal: 1m 17s\tremaining: 1m 28s\n",
            "466:\tlearn: 0.4453569\ttotal: 1m 17s\tremaining: 1m 28s\n",
            "467:\tlearn: 0.4451653\ttotal: 1m 17s\tremaining: 1m 28s\n",
            "468:\tlearn: 0.4450484\ttotal: 1m 17s\tremaining: 1m 28s\n",
            "469:\tlearn: 0.4446761\ttotal: 1m 17s\tremaining: 1m 27s\n",
            "470:\tlearn: 0.4444661\ttotal: 1m 18s\tremaining: 1m 27s\n",
            "471:\tlearn: 0.4439743\ttotal: 1m 18s\tremaining: 1m 27s\n",
            "472:\tlearn: 0.4430245\ttotal: 1m 18s\tremaining: 1m 27s\n",
            "473:\tlearn: 0.4429207\ttotal: 1m 18s\tremaining: 1m 27s\n",
            "474:\tlearn: 0.4420382\ttotal: 1m 18s\tremaining: 1m 27s\n",
            "475:\tlearn: 0.4414816\ttotal: 1m 18s\tremaining: 1m 26s\n",
            "476:\tlearn: 0.4412128\ttotal: 1m 19s\tremaining: 1m 26s\n",
            "477:\tlearn: 0.4409797\ttotal: 1m 19s\tremaining: 1m 26s\n",
            "478:\tlearn: 0.4406484\ttotal: 1m 19s\tremaining: 1m 26s\n",
            "479:\tlearn: 0.4401661\ttotal: 1m 19s\tremaining: 1m 26s\n",
            "480:\tlearn: 0.4398986\ttotal: 1m 19s\tremaining: 1m 26s\n",
            "481:\tlearn: 0.4395462\ttotal: 1m 19s\tremaining: 1m 25s\n",
            "482:\tlearn: 0.4394394\ttotal: 1m 20s\tremaining: 1m 25s\n",
            "483:\tlearn: 0.4391469\ttotal: 1m 20s\tremaining: 1m 25s\n",
            "484:\tlearn: 0.4389337\ttotal: 1m 20s\tremaining: 1m 25s\n",
            "485:\tlearn: 0.4384767\ttotal: 1m 20s\tremaining: 1m 25s\n",
            "486:\tlearn: 0.4380809\ttotal: 1m 20s\tremaining: 1m 25s\n",
            "487:\tlearn: 0.4373356\ttotal: 1m 20s\tremaining: 1m 24s\n",
            "488:\tlearn: 0.4365610\ttotal: 1m 20s\tremaining: 1m 24s\n",
            "489:\tlearn: 0.4363959\ttotal: 1m 21s\tremaining: 1m 24s\n",
            "490:\tlearn: 0.4359727\ttotal: 1m 21s\tremaining: 1m 24s\n",
            "491:\tlearn: 0.4358182\ttotal: 1m 21s\tremaining: 1m 24s\n",
            "492:\tlearn: 0.4352287\ttotal: 1m 21s\tremaining: 1m 23s\n",
            "493:\tlearn: 0.4351225\ttotal: 1m 21s\tremaining: 1m 23s\n",
            "494:\tlearn: 0.4347868\ttotal: 1m 21s\tremaining: 1m 23s\n",
            "495:\tlearn: 0.4345680\ttotal: 1m 22s\tremaining: 1m 23s\n",
            "496:\tlearn: 0.4339950\ttotal: 1m 22s\tremaining: 1m 23s\n",
            "497:\tlearn: 0.4338934\ttotal: 1m 22s\tremaining: 1m 23s\n",
            "498:\tlearn: 0.4337054\ttotal: 1m 22s\tremaining: 1m 22s\n",
            "499:\tlearn: 0.4334162\ttotal: 1m 22s\tremaining: 1m 22s\n",
            "500:\tlearn: 0.4329476\ttotal: 1m 22s\tremaining: 1m 22s\n",
            "501:\tlearn: 0.4326848\ttotal: 1m 23s\tremaining: 1m 22s\n",
            "502:\tlearn: 0.4325775\ttotal: 1m 23s\tremaining: 1m 22s\n",
            "503:\tlearn: 0.4316765\ttotal: 1m 23s\tremaining: 1m 22s\n",
            "504:\tlearn: 0.4312642\ttotal: 1m 23s\tremaining: 1m 22s\n",
            "505:\tlearn: 0.4310469\ttotal: 1m 23s\tremaining: 1m 21s\n",
            "506:\tlearn: 0.4307732\ttotal: 1m 23s\tremaining: 1m 21s\n",
            "507:\tlearn: 0.4304816\ttotal: 1m 24s\tremaining: 1m 21s\n",
            "508:\tlearn: 0.4297832\ttotal: 1m 24s\tremaining: 1m 21s\n",
            "509:\tlearn: 0.4294572\ttotal: 1m 24s\tremaining: 1m 21s\n",
            "510:\tlearn: 0.4287409\ttotal: 1m 24s\tremaining: 1m 21s\n",
            "511:\tlearn: 0.4285509\ttotal: 1m 24s\tremaining: 1m 20s\n",
            "512:\tlearn: 0.4282850\ttotal: 1m 25s\tremaining: 1m 20s\n",
            "513:\tlearn: 0.4280927\ttotal: 1m 25s\tremaining: 1m 20s\n",
            "514:\tlearn: 0.4278393\ttotal: 1m 25s\tremaining: 1m 20s\n",
            "515:\tlearn: 0.4272580\ttotal: 1m 25s\tremaining: 1m 20s\n",
            "516:\tlearn: 0.4266298\ttotal: 1m 25s\tremaining: 1m 20s\n",
            "517:\tlearn: 0.4262808\ttotal: 1m 25s\tremaining: 1m 19s\n",
            "518:\tlearn: 0.4255571\ttotal: 1m 25s\tremaining: 1m 19s\n",
            "519:\tlearn: 0.4254111\ttotal: 1m 26s\tremaining: 1m 19s\n",
            "520:\tlearn: 0.4249853\ttotal: 1m 26s\tremaining: 1m 19s\n",
            "521:\tlearn: 0.4246316\ttotal: 1m 26s\tremaining: 1m 19s\n",
            "522:\tlearn: 0.4245224\ttotal: 1m 26s\tremaining: 1m 19s\n",
            "523:\tlearn: 0.4239290\ttotal: 1m 26s\tremaining: 1m 18s\n",
            "524:\tlearn: 0.4236096\ttotal: 1m 26s\tremaining: 1m 18s\n",
            "525:\tlearn: 0.4233938\ttotal: 1m 27s\tremaining: 1m 18s\n",
            "526:\tlearn: 0.4232428\ttotal: 1m 27s\tremaining: 1m 18s\n",
            "527:\tlearn: 0.4230406\ttotal: 1m 27s\tremaining: 1m 18s\n",
            "528:\tlearn: 0.4227069\ttotal: 1m 27s\tremaining: 1m 17s\n",
            "529:\tlearn: 0.4225996\ttotal: 1m 27s\tremaining: 1m 17s\n",
            "530:\tlearn: 0.4223066\ttotal: 1m 27s\tremaining: 1m 17s\n",
            "531:\tlearn: 0.4222203\ttotal: 1m 28s\tremaining: 1m 17s\n",
            "532:\tlearn: 0.4214174\ttotal: 1m 28s\tremaining: 1m 17s\n",
            "533:\tlearn: 0.4211631\ttotal: 1m 28s\tremaining: 1m 17s\n",
            "534:\tlearn: 0.4207841\ttotal: 1m 28s\tremaining: 1m 16s\n",
            "535:\tlearn: 0.4205607\ttotal: 1m 28s\tremaining: 1m 16s\n",
            "536:\tlearn: 0.4204101\ttotal: 1m 28s\tremaining: 1m 16s\n",
            "537:\tlearn: 0.4195100\ttotal: 1m 28s\tremaining: 1m 16s\n",
            "538:\tlearn: 0.4193224\ttotal: 1m 29s\tremaining: 1m 16s\n",
            "539:\tlearn: 0.4183431\ttotal: 1m 29s\tremaining: 1m 16s\n",
            "540:\tlearn: 0.4178188\ttotal: 1m 29s\tremaining: 1m 15s\n",
            "541:\tlearn: 0.4175087\ttotal: 1m 29s\tremaining: 1m 15s\n",
            "542:\tlearn: 0.4171603\ttotal: 1m 29s\tremaining: 1m 15s\n",
            "543:\tlearn: 0.4169271\ttotal: 1m 29s\tremaining: 1m 15s\n",
            "544:\tlearn: 0.4163379\ttotal: 1m 30s\tremaining: 1m 15s\n",
            "545:\tlearn: 0.4162330\ttotal: 1m 30s\tremaining: 1m 15s\n",
            "546:\tlearn: 0.4159965\ttotal: 1m 30s\tremaining: 1m 14s\n",
            "547:\tlearn: 0.4158100\ttotal: 1m 30s\tremaining: 1m 14s\n",
            "548:\tlearn: 0.4155609\ttotal: 1m 30s\tremaining: 1m 14s\n",
            "549:\tlearn: 0.4154577\ttotal: 1m 31s\tremaining: 1m 14s\n",
            "550:\tlearn: 0.4150485\ttotal: 1m 31s\tremaining: 1m 14s\n",
            "551:\tlearn: 0.4146676\ttotal: 1m 31s\tremaining: 1m 14s\n",
            "552:\tlearn: 0.4141601\ttotal: 1m 31s\tremaining: 1m 14s\n",
            "553:\tlearn: 0.4139873\ttotal: 1m 31s\tremaining: 1m 13s\n",
            "554:\tlearn: 0.4138147\ttotal: 1m 31s\tremaining: 1m 13s\n",
            "555:\tlearn: 0.4137126\ttotal: 1m 32s\tremaining: 1m 13s\n",
            "556:\tlearn: 0.4135731\ttotal: 1m 32s\tremaining: 1m 13s\n",
            "557:\tlearn: 0.4132270\ttotal: 1m 32s\tremaining: 1m 13s\n",
            "558:\tlearn: 0.4124003\ttotal: 1m 32s\tremaining: 1m 13s\n",
            "559:\tlearn: 0.4117950\ttotal: 1m 32s\tremaining: 1m 12s\n",
            "560:\tlearn: 0.4115152\ttotal: 1m 32s\tremaining: 1m 12s\n",
            "561:\tlearn: 0.4109559\ttotal: 1m 33s\tremaining: 1m 12s\n",
            "562:\tlearn: 0.4102914\ttotal: 1m 33s\tremaining: 1m 12s\n",
            "563:\tlearn: 0.4099435\ttotal: 1m 33s\tremaining: 1m 12s\n",
            "564:\tlearn: 0.4094078\ttotal: 1m 33s\tremaining: 1m 12s\n",
            "565:\tlearn: 0.4090178\ttotal: 1m 33s\tremaining: 1m 11s\n",
            "566:\tlearn: 0.4086564\ttotal: 1m 33s\tremaining: 1m 11s\n",
            "567:\tlearn: 0.4073509\ttotal: 1m 34s\tremaining: 1m 11s\n",
            "568:\tlearn: 0.4068908\ttotal: 1m 34s\tremaining: 1m 11s\n",
            "569:\tlearn: 0.4060035\ttotal: 1m 34s\tremaining: 1m 11s\n",
            "570:\tlearn: 0.4058159\ttotal: 1m 34s\tremaining: 1m 10s\n",
            "571:\tlearn: 0.4055917\ttotal: 1m 34s\tremaining: 1m 10s\n",
            "572:\tlearn: 0.4053561\ttotal: 1m 34s\tremaining: 1m 10s\n",
            "573:\tlearn: 0.4051261\ttotal: 1m 34s\tremaining: 1m 10s\n",
            "574:\tlearn: 0.4049666\ttotal: 1m 35s\tremaining: 1m 10s\n",
            "575:\tlearn: 0.4048652\ttotal: 1m 35s\tremaining: 1m 10s\n",
            "576:\tlearn: 0.4046155\ttotal: 1m 35s\tremaining: 1m 9s\n",
            "577:\tlearn: 0.4040065\ttotal: 1m 35s\tremaining: 1m 9s\n",
            "578:\tlearn: 0.4038797\ttotal: 1m 35s\tremaining: 1m 9s\n",
            "579:\tlearn: 0.4038027\ttotal: 1m 35s\tremaining: 1m 9s\n",
            "580:\tlearn: 0.4036979\ttotal: 1m 36s\tremaining: 1m 9s\n",
            "581:\tlearn: 0.4031715\ttotal: 1m 36s\tremaining: 1m 9s\n",
            "582:\tlearn: 0.4030055\ttotal: 1m 36s\tremaining: 1m 9s\n",
            "583:\tlearn: 0.4025866\ttotal: 1m 36s\tremaining: 1m 8s\n",
            "584:\tlearn: 0.4023451\ttotal: 1m 36s\tremaining: 1m 8s\n",
            "585:\tlearn: 0.4022444\ttotal: 1m 37s\tremaining: 1m 8s\n",
            "586:\tlearn: 0.4020122\ttotal: 1m 37s\tremaining: 1m 8s\n",
            "587:\tlearn: 0.4015966\ttotal: 1m 37s\tremaining: 1m 8s\n",
            "588:\tlearn: 0.4013837\ttotal: 1m 37s\tremaining: 1m 8s\n",
            "589:\tlearn: 0.4012038\ttotal: 1m 37s\tremaining: 1m 7s\n",
            "590:\tlearn: 0.4011024\ttotal: 1m 37s\tremaining: 1m 7s\n",
            "591:\tlearn: 0.4008437\ttotal: 1m 38s\tremaining: 1m 7s\n",
            "592:\tlearn: 0.4005640\ttotal: 1m 38s\tremaining: 1m 7s\n",
            "593:\tlearn: 0.3994951\ttotal: 1m 38s\tremaining: 1m 7s\n",
            "594:\tlearn: 0.3988365\ttotal: 1m 38s\tremaining: 1m 7s\n",
            "595:\tlearn: 0.3985065\ttotal: 1m 38s\tremaining: 1m 6s\n",
            "596:\tlearn: 0.3983262\ttotal: 1m 38s\tremaining: 1m 6s\n",
            "597:\tlearn: 0.3974757\ttotal: 1m 39s\tremaining: 1m 6s\n",
            "598:\tlearn: 0.3973767\ttotal: 1m 39s\tremaining: 1m 6s\n",
            "599:\tlearn: 0.3972756\ttotal: 1m 39s\tremaining: 1m 6s\n",
            "600:\tlearn: 0.3968592\ttotal: 1m 39s\tremaining: 1m 6s\n",
            "601:\tlearn: 0.3966638\ttotal: 1m 39s\tremaining: 1m 5s\n",
            "602:\tlearn: 0.3965847\ttotal: 1m 39s\tremaining: 1m 5s\n",
            "603:\tlearn: 0.3959835\ttotal: 1m 40s\tremaining: 1m 5s\n",
            "604:\tlearn: 0.3955158\ttotal: 1m 40s\tremaining: 1m 5s\n",
            "605:\tlearn: 0.3950104\ttotal: 1m 40s\tremaining: 1m 5s\n",
            "606:\tlearn: 0.3948693\ttotal: 1m 40s\tremaining: 1m 5s\n",
            "607:\tlearn: 0.3946361\ttotal: 1m 40s\tremaining: 1m 4s\n",
            "608:\tlearn: 0.3945080\ttotal: 1m 40s\tremaining: 1m 4s\n",
            "609:\tlearn: 0.3937130\ttotal: 1m 41s\tremaining: 1m 4s\n",
            "610:\tlearn: 0.3935153\ttotal: 1m 41s\tremaining: 1m 4s\n",
            "611:\tlearn: 0.3934408\ttotal: 1m 41s\tremaining: 1m 4s\n",
            "612:\tlearn: 0.3930547\ttotal: 1m 41s\tremaining: 1m 4s\n",
            "613:\tlearn: 0.3928558\ttotal: 1m 41s\tremaining: 1m 3s\n",
            "614:\tlearn: 0.3925350\ttotal: 1m 41s\tremaining: 1m 3s\n",
            "615:\tlearn: 0.3923737\ttotal: 1m 41s\tremaining: 1m 3s\n",
            "616:\tlearn: 0.3923007\ttotal: 1m 42s\tremaining: 1m 3s\n",
            "617:\tlearn: 0.3915675\ttotal: 1m 42s\tremaining: 1m 3s\n",
            "618:\tlearn: 0.3911013\ttotal: 1m 42s\tremaining: 1m 3s\n",
            "619:\tlearn: 0.3902957\ttotal: 1m 42s\tremaining: 1m 2s\n",
            "620:\tlearn: 0.3900385\ttotal: 1m 42s\tremaining: 1m 2s\n",
            "621:\tlearn: 0.3898523\ttotal: 1m 42s\tremaining: 1m 2s\n",
            "622:\tlearn: 0.3895029\ttotal: 1m 43s\tremaining: 1m 2s\n",
            "623:\tlearn: 0.3894015\ttotal: 1m 43s\tremaining: 1m 2s\n",
            "624:\tlearn: 0.3892903\ttotal: 1m 43s\tremaining: 1m 2s\n",
            "625:\tlearn: 0.3891330\ttotal: 1m 43s\tremaining: 1m 1s\n",
            "626:\tlearn: 0.3889477\ttotal: 1m 43s\tremaining: 1m 1s\n",
            "627:\tlearn: 0.3888437\ttotal: 1m 44s\tremaining: 1m 1s\n",
            "628:\tlearn: 0.3887011\ttotal: 1m 44s\tremaining: 1m 1s\n",
            "629:\tlearn: 0.3884601\ttotal: 1m 44s\tremaining: 1m 1s\n",
            "630:\tlearn: 0.3880406\ttotal: 1m 44s\tremaining: 1m 1s\n",
            "631:\tlearn: 0.3878057\ttotal: 1m 44s\tremaining: 1m 1s\n",
            "632:\tlearn: 0.3876699\ttotal: 1m 45s\tremaining: 1m\n",
            "633:\tlearn: 0.3871539\ttotal: 1m 45s\tremaining: 1m\n",
            "634:\tlearn: 0.3867364\ttotal: 1m 45s\tremaining: 1m\n",
            "635:\tlearn: 0.3863194\ttotal: 1m 45s\tremaining: 1m\n",
            "636:\tlearn: 0.3861322\ttotal: 1m 45s\tremaining: 1m\n",
            "637:\tlearn: 0.3860375\ttotal: 1m 45s\tremaining: 1m\n",
            "638:\tlearn: 0.3852280\ttotal: 1m 45s\tremaining: 59.9s\n",
            "639:\tlearn: 0.3851551\ttotal: 1m 46s\tremaining: 59.7s\n",
            "640:\tlearn: 0.3850210\ttotal: 1m 46s\tremaining: 59.5s\n",
            "641:\tlearn: 0.3846803\ttotal: 1m 46s\tremaining: 59.3s\n",
            "642:\tlearn: 0.3845288\ttotal: 1m 46s\tremaining: 59.2s\n",
            "643:\tlearn: 0.3843481\ttotal: 1m 46s\tremaining: 59s\n",
            "644:\tlearn: 0.3840558\ttotal: 1m 46s\tremaining: 58.9s\n",
            "645:\tlearn: 0.3837020\ttotal: 1m 47s\tremaining: 58.7s\n",
            "646:\tlearn: 0.3836069\ttotal: 1m 47s\tremaining: 58.5s\n",
            "647:\tlearn: 0.3828059\ttotal: 1m 47s\tremaining: 58.3s\n",
            "648:\tlearn: 0.3826368\ttotal: 1m 47s\tremaining: 58.2s\n",
            "649:\tlearn: 0.3825645\ttotal: 1m 47s\tremaining: 58s\n",
            "650:\tlearn: 0.3824119\ttotal: 1m 47s\tremaining: 57.8s\n",
            "651:\tlearn: 0.3822889\ttotal: 1m 48s\tremaining: 57.7s\n",
            "652:\tlearn: 0.3820252\ttotal: 1m 48s\tremaining: 57.5s\n",
            "653:\tlearn: 0.3818136\ttotal: 1m 48s\tremaining: 57.3s\n",
            "654:\tlearn: 0.3817180\ttotal: 1m 48s\tremaining: 57.2s\n",
            "655:\tlearn: 0.3809633\ttotal: 1m 48s\tremaining: 57s\n",
            "656:\tlearn: 0.3807622\ttotal: 1m 48s\tremaining: 56.8s\n",
            "657:\tlearn: 0.3806725\ttotal: 1m 49s\tremaining: 56.7s\n",
            "658:\tlearn: 0.3799780\ttotal: 1m 49s\tremaining: 56.5s\n",
            "659:\tlearn: 0.3798281\ttotal: 1m 49s\tremaining: 56.3s\n",
            "660:\tlearn: 0.3791355\ttotal: 1m 49s\tremaining: 56.2s\n",
            "661:\tlearn: 0.3790458\ttotal: 1m 49s\tremaining: 56s\n",
            "662:\tlearn: 0.3786272\ttotal: 1m 49s\tremaining: 55.9s\n",
            "663:\tlearn: 0.3784493\ttotal: 1m 50s\tremaining: 55.8s\n",
            "664:\tlearn: 0.3782044\ttotal: 1m 50s\tremaining: 55.6s\n",
            "665:\tlearn: 0.3781402\ttotal: 1m 50s\tremaining: 55.5s\n",
            "666:\tlearn: 0.3780592\ttotal: 1m 50s\tremaining: 55.4s\n",
            "667:\tlearn: 0.3779718\ttotal: 1m 51s\tremaining: 55.2s\n",
            "668:\tlearn: 0.3774300\ttotal: 1m 51s\tremaining: 55.1s\n",
            "669:\tlearn: 0.3772799\ttotal: 1m 51s\tremaining: 54.9s\n",
            "670:\tlearn: 0.3764976\ttotal: 1m 51s\tremaining: 54.8s\n",
            "671:\tlearn: 0.3764358\ttotal: 1m 51s\tremaining: 54.6s\n",
            "672:\tlearn: 0.3763445\ttotal: 1m 52s\tremaining: 54.5s\n",
            "673:\tlearn: 0.3759996\ttotal: 1m 52s\tremaining: 54.3s\n",
            "674:\tlearn: 0.3754316\ttotal: 1m 52s\tremaining: 54.1s\n",
            "675:\tlearn: 0.3752515\ttotal: 1m 52s\tremaining: 54s\n",
            "676:\tlearn: 0.3750738\ttotal: 1m 52s\tremaining: 53.8s\n",
            "677:\tlearn: 0.3744029\ttotal: 1m 52s\tremaining: 53.7s\n",
            "678:\tlearn: 0.3735969\ttotal: 1m 53s\tremaining: 53.5s\n",
            "679:\tlearn: 0.3728474\ttotal: 1m 53s\tremaining: 53.3s\n",
            "680:\tlearn: 0.3724451\ttotal: 1m 53s\tremaining: 53.1s\n",
            "681:\tlearn: 0.3722484\ttotal: 1m 53s\tremaining: 53s\n",
            "682:\tlearn: 0.3721792\ttotal: 1m 53s\tremaining: 52.8s\n",
            "683:\tlearn: 0.3714617\ttotal: 1m 53s\tremaining: 52.6s\n",
            "684:\tlearn: 0.3713207\ttotal: 1m 54s\tremaining: 52.5s\n",
            "685:\tlearn: 0.3711943\ttotal: 1m 54s\tremaining: 52.3s\n",
            "686:\tlearn: 0.3709280\ttotal: 1m 54s\tremaining: 52.1s\n",
            "687:\tlearn: 0.3708578\ttotal: 1m 54s\tremaining: 51.9s\n",
            "688:\tlearn: 0.3705930\ttotal: 1m 54s\tremaining: 51.8s\n",
            "689:\tlearn: 0.3705144\ttotal: 1m 54s\tremaining: 51.6s\n",
            "690:\tlearn: 0.3703460\ttotal: 1m 55s\tremaining: 51.4s\n",
            "691:\tlearn: 0.3702391\ttotal: 1m 55s\tremaining: 51.3s\n",
            "692:\tlearn: 0.3699215\ttotal: 1m 55s\tremaining: 51.1s\n",
            "693:\tlearn: 0.3696452\ttotal: 1m 55s\tremaining: 50.9s\n",
            "694:\tlearn: 0.3695810\ttotal: 1m 55s\tremaining: 50.8s\n",
            "695:\tlearn: 0.3693880\ttotal: 1m 55s\tremaining: 50.6s\n",
            "696:\tlearn: 0.3692509\ttotal: 1m 56s\tremaining: 50.4s\n",
            "697:\tlearn: 0.3691637\ttotal: 1m 56s\tremaining: 50.3s\n",
            "698:\tlearn: 0.3690299\ttotal: 1m 56s\tremaining: 50.1s\n",
            "699:\tlearn: 0.3686581\ttotal: 1m 56s\tremaining: 49.9s\n",
            "700:\tlearn: 0.3680883\ttotal: 1m 56s\tremaining: 49.7s\n",
            "701:\tlearn: 0.3680238\ttotal: 1m 56s\tremaining: 49.6s\n",
            "702:\tlearn: 0.3679648\ttotal: 1m 56s\tremaining: 49.4s\n",
            "703:\tlearn: 0.3677808\ttotal: 1m 57s\tremaining: 49.2s\n",
            "704:\tlearn: 0.3675325\ttotal: 1m 57s\tremaining: 49.1s\n",
            "705:\tlearn: 0.3674471\ttotal: 1m 57s\tremaining: 48.9s\n",
            "706:\tlearn: 0.3671050\ttotal: 1m 57s\tremaining: 48.7s\n",
            "707:\tlearn: 0.3669761\ttotal: 1m 57s\tremaining: 48.6s\n",
            "708:\tlearn: 0.3662734\ttotal: 1m 57s\tremaining: 48.4s\n",
            "709:\tlearn: 0.3661451\ttotal: 1m 58s\tremaining: 48.2s\n",
            "710:\tlearn: 0.3658158\ttotal: 1m 58s\tremaining: 48.1s\n",
            "711:\tlearn: 0.3652739\ttotal: 1m 58s\tremaining: 47.9s\n",
            "712:\tlearn: 0.3651102\ttotal: 1m 58s\tremaining: 47.8s\n",
            "713:\tlearn: 0.3647887\ttotal: 1m 58s\tremaining: 47.6s\n",
            "714:\tlearn: 0.3646985\ttotal: 1m 58s\tremaining: 47.4s\n",
            "715:\tlearn: 0.3645713\ttotal: 1m 59s\tremaining: 47.2s\n",
            "716:\tlearn: 0.3644545\ttotal: 1m 59s\tremaining: 47.1s\n",
            "717:\tlearn: 0.3643762\ttotal: 1m 59s\tremaining: 46.9s\n",
            "718:\tlearn: 0.3640484\ttotal: 1m 59s\tremaining: 46.7s\n",
            "719:\tlearn: 0.3638918\ttotal: 1m 59s\tremaining: 46.6s\n",
            "720:\tlearn: 0.3638320\ttotal: 1m 59s\tremaining: 46.4s\n",
            "721:\tlearn: 0.3637469\ttotal: 2m\tremaining: 46.2s\n",
            "722:\tlearn: 0.3636873\ttotal: 2m\tremaining: 46s\n",
            "723:\tlearn: 0.3634928\ttotal: 2m\tremaining: 45.9s\n",
            "724:\tlearn: 0.3634105\ttotal: 2m\tremaining: 45.7s\n",
            "725:\tlearn: 0.3632476\ttotal: 2m\tremaining: 45.5s\n",
            "726:\tlearn: 0.3630663\ttotal: 2m\tremaining: 45.4s\n",
            "727:\tlearn: 0.3628077\ttotal: 2m\tremaining: 45.2s\n",
            "728:\tlearn: 0.3624616\ttotal: 2m 1s\tremaining: 45s\n",
            "729:\tlearn: 0.3622625\ttotal: 2m 1s\tremaining: 44.9s\n",
            "730:\tlearn: 0.3621004\ttotal: 2m 1s\tremaining: 44.7s\n",
            "731:\tlearn: 0.3619855\ttotal: 2m 1s\tremaining: 44.5s\n",
            "732:\tlearn: 0.3615743\ttotal: 2m 1s\tremaining: 44.4s\n",
            "733:\tlearn: 0.3612835\ttotal: 2m 1s\tremaining: 44.2s\n",
            "734:\tlearn: 0.3610031\ttotal: 2m 2s\tremaining: 44s\n",
            "735:\tlearn: 0.3607411\ttotal: 2m 2s\tremaining: 43.9s\n",
            "736:\tlearn: 0.3605469\ttotal: 2m 2s\tremaining: 43.7s\n",
            "737:\tlearn: 0.3603978\ttotal: 2m 2s\tremaining: 43.5s\n",
            "738:\tlearn: 0.3602406\ttotal: 2m 2s\tremaining: 43.4s\n",
            "739:\tlearn: 0.3600650\ttotal: 2m 2s\tremaining: 43.2s\n",
            "740:\tlearn: 0.3600066\ttotal: 2m 3s\tremaining: 43s\n",
            "741:\tlearn: 0.3597519\ttotal: 2m 3s\tremaining: 42.9s\n",
            "742:\tlearn: 0.3592509\ttotal: 2m 3s\tremaining: 42.7s\n",
            "743:\tlearn: 0.3589646\ttotal: 2m 3s\tremaining: 42.5s\n",
            "744:\tlearn: 0.3588543\ttotal: 2m 3s\tremaining: 42.4s\n",
            "745:\tlearn: 0.3587728\ttotal: 2m 3s\tremaining: 42.2s\n",
            "746:\tlearn: 0.3586061\ttotal: 2m 4s\tremaining: 42s\n",
            "747:\tlearn: 0.3581133\ttotal: 2m 4s\tremaining: 41.9s\n",
            "748:\tlearn: 0.3577283\ttotal: 2m 4s\tremaining: 41.7s\n",
            "749:\tlearn: 0.3576134\ttotal: 2m 4s\tremaining: 41.5s\n",
            "750:\tlearn: 0.3569685\ttotal: 2m 4s\tremaining: 41.4s\n",
            "751:\tlearn: 0.3569089\ttotal: 2m 4s\tremaining: 41.2s\n",
            "752:\tlearn: 0.3566417\ttotal: 2m 5s\tremaining: 41.1s\n",
            "753:\tlearn: 0.3565578\ttotal: 2m 5s\tremaining: 40.9s\n",
            "754:\tlearn: 0.3563750\ttotal: 2m 5s\tremaining: 40.8s\n",
            "755:\tlearn: 0.3561720\ttotal: 2m 5s\tremaining: 40.6s\n",
            "756:\tlearn: 0.3560565\ttotal: 2m 5s\tremaining: 40.4s\n",
            "757:\tlearn: 0.3558543\ttotal: 2m 6s\tremaining: 40.3s\n",
            "758:\tlearn: 0.3556322\ttotal: 2m 6s\tremaining: 40.1s\n",
            "759:\tlearn: 0.3555678\ttotal: 2m 6s\tremaining: 40s\n",
            "760:\tlearn: 0.3554447\ttotal: 2m 6s\tremaining: 39.8s\n",
            "761:\tlearn: 0.3550813\ttotal: 2m 6s\tremaining: 39.6s\n",
            "762:\tlearn: 0.3548642\ttotal: 2m 7s\tremaining: 39.5s\n",
            "763:\tlearn: 0.3547590\ttotal: 2m 7s\tremaining: 39.3s\n",
            "764:\tlearn: 0.3543366\ttotal: 2m 7s\tremaining: 39.2s\n",
            "765:\tlearn: 0.3542532\ttotal: 2m 7s\tremaining: 39s\n",
            "766:\tlearn: 0.3536937\ttotal: 2m 7s\tremaining: 38.8s\n",
            "767:\tlearn: 0.3536112\ttotal: 2m 8s\tremaining: 38.7s\n",
            "768:\tlearn: 0.3534923\ttotal: 2m 8s\tremaining: 38.5s\n",
            "769:\tlearn: 0.3533781\ttotal: 2m 8s\tremaining: 38.4s\n",
            "770:\tlearn: 0.3526859\ttotal: 2m 8s\tremaining: 38.2s\n",
            "771:\tlearn: 0.3525255\ttotal: 2m 8s\tremaining: 38s\n",
            "772:\tlearn: 0.3524664\ttotal: 2m 8s\tremaining: 37.9s\n",
            "773:\tlearn: 0.3523162\ttotal: 2m 9s\tremaining: 37.7s\n",
            "774:\tlearn: 0.3521521\ttotal: 2m 9s\tremaining: 37.5s\n",
            "775:\tlearn: 0.3520955\ttotal: 2m 9s\tremaining: 37.4s\n",
            "776:\tlearn: 0.3520040\ttotal: 2m 9s\tremaining: 37.2s\n",
            "777:\tlearn: 0.3519219\ttotal: 2m 9s\tremaining: 37s\n",
            "778:\tlearn: 0.3514172\ttotal: 2m 9s\tremaining: 36.9s\n",
            "779:\tlearn: 0.3512718\ttotal: 2m 10s\tremaining: 36.7s\n",
            "780:\tlearn: 0.3510665\ttotal: 2m 10s\tremaining: 36.5s\n",
            "781:\tlearn: 0.3510033\ttotal: 2m 10s\tremaining: 36.4s\n",
            "782:\tlearn: 0.3509477\ttotal: 2m 10s\tremaining: 36.2s\n",
            "783:\tlearn: 0.3507182\ttotal: 2m 10s\tremaining: 36s\n",
            "784:\tlearn: 0.3505179\ttotal: 2m 10s\tremaining: 35.9s\n",
            "785:\tlearn: 0.3501937\ttotal: 2m 11s\tremaining: 35.7s\n",
            "786:\tlearn: 0.3499965\ttotal: 2m 11s\tremaining: 35.5s\n",
            "787:\tlearn: 0.3497542\ttotal: 2m 11s\tremaining: 35.4s\n",
            "788:\tlearn: 0.3492597\ttotal: 2m 11s\tremaining: 35.2s\n",
            "789:\tlearn: 0.3489583\ttotal: 2m 11s\tremaining: 35s\n",
            "790:\tlearn: 0.3489004\ttotal: 2m 11s\tremaining: 34.9s\n",
            "791:\tlearn: 0.3484513\ttotal: 2m 12s\tremaining: 34.7s\n",
            "792:\tlearn: 0.3483454\ttotal: 2m 12s\tremaining: 34.5s\n",
            "793:\tlearn: 0.3482866\ttotal: 2m 12s\tremaining: 34.4s\n",
            "794:\tlearn: 0.3477008\ttotal: 2m 12s\tremaining: 34.2s\n",
            "795:\tlearn: 0.3475221\ttotal: 2m 12s\tremaining: 34s\n",
            "796:\tlearn: 0.3473700\ttotal: 2m 12s\tremaining: 33.9s\n",
            "797:\tlearn: 0.3473186\ttotal: 2m 13s\tremaining: 33.7s\n",
            "798:\tlearn: 0.3468095\ttotal: 2m 13s\tremaining: 33.5s\n",
            "799:\tlearn: 0.3466259\ttotal: 2m 13s\tremaining: 33.4s\n",
            "800:\tlearn: 0.3465456\ttotal: 2m 13s\tremaining: 33.2s\n",
            "801:\tlearn: 0.3464352\ttotal: 2m 13s\tremaining: 33s\n",
            "802:\tlearn: 0.3463347\ttotal: 2m 14s\tremaining: 32.9s\n",
            "803:\tlearn: 0.3462604\ttotal: 2m 14s\tremaining: 32.7s\n",
            "804:\tlearn: 0.3458932\ttotal: 2m 14s\tremaining: 32.5s\n",
            "805:\tlearn: 0.3457373\ttotal: 2m 14s\tremaining: 32.4s\n",
            "806:\tlearn: 0.3456659\ttotal: 2m 14s\tremaining: 32.2s\n",
            "807:\tlearn: 0.3455105\ttotal: 2m 14s\tremaining: 32.1s\n",
            "808:\tlearn: 0.3454548\ttotal: 2m 15s\tremaining: 31.9s\n",
            "809:\tlearn: 0.3452914\ttotal: 2m 15s\tremaining: 31.7s\n",
            "810:\tlearn: 0.3452226\ttotal: 2m 15s\tremaining: 31.6s\n",
            "811:\tlearn: 0.3450335\ttotal: 2m 15s\tremaining: 31.4s\n",
            "812:\tlearn: 0.3447643\ttotal: 2m 15s\tremaining: 31.3s\n",
            "813:\tlearn: 0.3446884\ttotal: 2m 16s\tremaining: 31.1s\n",
            "814:\tlearn: 0.3446155\ttotal: 2m 16s\tremaining: 30.9s\n",
            "815:\tlearn: 0.3439940\ttotal: 2m 16s\tremaining: 30.8s\n",
            "816:\tlearn: 0.3438855\ttotal: 2m 16s\tremaining: 30.6s\n",
            "817:\tlearn: 0.3437760\ttotal: 2m 16s\tremaining: 30.4s\n",
            "818:\tlearn: 0.3432169\ttotal: 2m 16s\tremaining: 30.3s\n",
            "819:\tlearn: 0.3428306\ttotal: 2m 17s\tremaining: 30.1s\n",
            "820:\tlearn: 0.3427567\ttotal: 2m 17s\tremaining: 29.9s\n",
            "821:\tlearn: 0.3424680\ttotal: 2m 17s\tremaining: 29.8s\n",
            "822:\tlearn: 0.3421716\ttotal: 2m 17s\tremaining: 29.6s\n",
            "823:\tlearn: 0.3421137\ttotal: 2m 17s\tremaining: 29.4s\n",
            "824:\tlearn: 0.3420584\ttotal: 2m 17s\tremaining: 29.3s\n",
            "825:\tlearn: 0.3419033\ttotal: 2m 18s\tremaining: 29.1s\n",
            "826:\tlearn: 0.3417679\ttotal: 2m 18s\tremaining: 28.9s\n",
            "827:\tlearn: 0.3416443\ttotal: 2m 18s\tremaining: 28.8s\n",
            "828:\tlearn: 0.3413327\ttotal: 2m 18s\tremaining: 28.6s\n",
            "829:\tlearn: 0.3412727\ttotal: 2m 18s\tremaining: 28.4s\n",
            "830:\tlearn: 0.3407127\ttotal: 2m 19s\tremaining: 28.3s\n",
            "831:\tlearn: 0.3405779\ttotal: 2m 19s\tremaining: 28.1s\n",
            "832:\tlearn: 0.3404292\ttotal: 2m 19s\tremaining: 28s\n",
            "833:\tlearn: 0.3402924\ttotal: 2m 19s\tremaining: 27.8s\n",
            "834:\tlearn: 0.3400942\ttotal: 2m 19s\tremaining: 27.6s\n",
            "835:\tlearn: 0.3398782\ttotal: 2m 20s\tremaining: 27.5s\n",
            "836:\tlearn: 0.3397449\ttotal: 2m 20s\tremaining: 27.3s\n",
            "837:\tlearn: 0.3396899\ttotal: 2m 20s\tremaining: 27.1s\n",
            "838:\tlearn: 0.3396042\ttotal: 2m 20s\tremaining: 27s\n",
            "839:\tlearn: 0.3394930\ttotal: 2m 20s\tremaining: 26.8s\n",
            "840:\tlearn: 0.3394177\ttotal: 2m 20s\tremaining: 26.6s\n",
            "841:\tlearn: 0.3392076\ttotal: 2m 20s\tremaining: 26.5s\n",
            "842:\tlearn: 0.3391525\ttotal: 2m 21s\tremaining: 26.3s\n",
            "843:\tlearn: 0.3389952\ttotal: 2m 21s\tremaining: 26.1s\n",
            "844:\tlearn: 0.3387617\ttotal: 2m 21s\tremaining: 26s\n",
            "845:\tlearn: 0.3384757\ttotal: 2m 21s\tremaining: 25.8s\n",
            "846:\tlearn: 0.3384203\ttotal: 2m 21s\tremaining: 25.6s\n",
            "847:\tlearn: 0.3383673\ttotal: 2m 21s\tremaining: 25.5s\n",
            "848:\tlearn: 0.3382211\ttotal: 2m 22s\tremaining: 25.3s\n",
            "849:\tlearn: 0.3377829\ttotal: 2m 22s\tremaining: 25.1s\n",
            "850:\tlearn: 0.3375363\ttotal: 2m 22s\tremaining: 25s\n",
            "851:\tlearn: 0.3371453\ttotal: 2m 22s\tremaining: 24.8s\n",
            "852:\tlearn: 0.3369361\ttotal: 2m 22s\tremaining: 24.6s\n",
            "853:\tlearn: 0.3368618\ttotal: 2m 23s\tremaining: 24.5s\n",
            "854:\tlearn: 0.3367676\ttotal: 2m 23s\tremaining: 24.3s\n",
            "855:\tlearn: 0.3367172\ttotal: 2m 23s\tremaining: 24.1s\n",
            "856:\tlearn: 0.3364097\ttotal: 2m 23s\tremaining: 24s\n",
            "857:\tlearn: 0.3359332\ttotal: 2m 23s\tremaining: 23.8s\n",
            "858:\tlearn: 0.3357702\ttotal: 2m 23s\tremaining: 23.6s\n",
            "859:\tlearn: 0.3356366\ttotal: 2m 24s\tremaining: 23.5s\n",
            "860:\tlearn: 0.3354567\ttotal: 2m 24s\tremaining: 23.3s\n",
            "861:\tlearn: 0.3354002\ttotal: 2m 24s\tremaining: 23.1s\n",
            "862:\tlearn: 0.3353465\ttotal: 2m 24s\tremaining: 23s\n",
            "863:\tlearn: 0.3352720\ttotal: 2m 24s\tremaining: 22.8s\n",
            "864:\tlearn: 0.3351755\ttotal: 2m 24s\tremaining: 22.6s\n",
            "865:\tlearn: 0.3351081\ttotal: 2m 25s\tremaining: 22.5s\n",
            "866:\tlearn: 0.3349866\ttotal: 2m 25s\tremaining: 22.3s\n",
            "867:\tlearn: 0.3346998\ttotal: 2m 25s\tremaining: 22.1s\n",
            "868:\tlearn: 0.3346296\ttotal: 2m 25s\tremaining: 22s\n",
            "869:\tlearn: 0.3341161\ttotal: 2m 25s\tremaining: 21.8s\n",
            "870:\tlearn: 0.3339166\ttotal: 2m 25s\tremaining: 21.6s\n",
            "871:\tlearn: 0.3338148\ttotal: 2m 26s\tremaining: 21.4s\n",
            "872:\tlearn: 0.3337461\ttotal: 2m 26s\tremaining: 21.3s\n",
            "873:\tlearn: 0.3334717\ttotal: 2m 26s\tremaining: 21.1s\n",
            "874:\tlearn: 0.3333925\ttotal: 2m 26s\tremaining: 21s\n",
            "875:\tlearn: 0.3330177\ttotal: 2m 26s\tremaining: 20.8s\n",
            "876:\tlearn: 0.3329651\ttotal: 2m 27s\tremaining: 20.6s\n",
            "877:\tlearn: 0.3328291\ttotal: 2m 27s\tremaining: 20.5s\n",
            "878:\tlearn: 0.3326596\ttotal: 2m 27s\tremaining: 20.3s\n",
            "879:\tlearn: 0.3325904\ttotal: 2m 27s\tremaining: 20.1s\n",
            "880:\tlearn: 0.3323510\ttotal: 2m 27s\tremaining: 20s\n",
            "881:\tlearn: 0.3321892\ttotal: 2m 27s\tremaining: 19.8s\n",
            "882:\tlearn: 0.3321206\ttotal: 2m 28s\tremaining: 19.6s\n",
            "883:\tlearn: 0.3320249\ttotal: 2m 28s\tremaining: 19.5s\n",
            "884:\tlearn: 0.3317465\ttotal: 2m 28s\tremaining: 19.3s\n",
            "885:\tlearn: 0.3316935\ttotal: 2m 28s\tremaining: 19.1s\n",
            "886:\tlearn: 0.3316388\ttotal: 2m 28s\tremaining: 19s\n",
            "887:\tlearn: 0.3314977\ttotal: 2m 29s\tremaining: 18.8s\n",
            "888:\tlearn: 0.3314274\ttotal: 2m 29s\tremaining: 18.6s\n",
            "889:\tlearn: 0.3311896\ttotal: 2m 29s\tremaining: 18.5s\n",
            "890:\tlearn: 0.3309307\ttotal: 2m 29s\tremaining: 18.3s\n",
            "891:\tlearn: 0.3308349\ttotal: 2m 29s\tremaining: 18.1s\n",
            "892:\tlearn: 0.3306655\ttotal: 2m 29s\tremaining: 18s\n",
            "893:\tlearn: 0.3306163\ttotal: 2m 30s\tremaining: 17.8s\n",
            "894:\tlearn: 0.3303859\ttotal: 2m 30s\tremaining: 17.6s\n",
            "895:\tlearn: 0.3299392\ttotal: 2m 30s\tremaining: 17.5s\n",
            "896:\tlearn: 0.3295792\ttotal: 2m 30s\tremaining: 17.3s\n",
            "897:\tlearn: 0.3295136\ttotal: 2m 30s\tremaining: 17.1s\n",
            "898:\tlearn: 0.3293827\ttotal: 2m 31s\tremaining: 17s\n",
            "899:\tlearn: 0.3289672\ttotal: 2m 31s\tremaining: 16.8s\n",
            "900:\tlearn: 0.3287117\ttotal: 2m 31s\tremaining: 16.6s\n",
            "901:\tlearn: 0.3285963\ttotal: 2m 31s\tremaining: 16.5s\n",
            "902:\tlearn: 0.3285001\ttotal: 2m 31s\tremaining: 16.3s\n",
            "903:\tlearn: 0.3282202\ttotal: 2m 32s\tremaining: 16.1s\n",
            "904:\tlearn: 0.3281674\ttotal: 2m 32s\tremaining: 16s\n",
            "905:\tlearn: 0.3275094\ttotal: 2m 32s\tremaining: 15.8s\n",
            "906:\tlearn: 0.3273953\ttotal: 2m 32s\tremaining: 15.7s\n",
            "907:\tlearn: 0.3270164\ttotal: 2m 32s\tremaining: 15.5s\n",
            "908:\tlearn: 0.3267477\ttotal: 2m 33s\tremaining: 15.3s\n",
            "909:\tlearn: 0.3264590\ttotal: 2m 33s\tremaining: 15.2s\n",
            "910:\tlearn: 0.3263811\ttotal: 2m 33s\tremaining: 15s\n",
            "911:\tlearn: 0.3259869\ttotal: 2m 33s\tremaining: 14.8s\n",
            "912:\tlearn: 0.3258435\ttotal: 2m 33s\tremaining: 14.7s\n",
            "913:\tlearn: 0.3257676\ttotal: 2m 33s\tremaining: 14.5s\n",
            "914:\tlearn: 0.3257200\ttotal: 2m 34s\tremaining: 14.3s\n",
            "915:\tlearn: 0.3256682\ttotal: 2m 34s\tremaining: 14.2s\n",
            "916:\tlearn: 0.3255581\ttotal: 2m 34s\tremaining: 14s\n",
            "917:\tlearn: 0.3254459\ttotal: 2m 34s\tremaining: 13.8s\n",
            "918:\tlearn: 0.3252584\ttotal: 2m 34s\tremaining: 13.7s\n",
            "919:\tlearn: 0.3251384\ttotal: 2m 35s\tremaining: 13.5s\n",
            "920:\tlearn: 0.3249964\ttotal: 2m 35s\tremaining: 13.3s\n",
            "921:\tlearn: 0.3249282\ttotal: 2m 35s\tremaining: 13.2s\n",
            "922:\tlearn: 0.3242933\ttotal: 2m 35s\tremaining: 13s\n",
            "923:\tlearn: 0.3236743\ttotal: 2m 36s\tremaining: 12.8s\n",
            "924:\tlearn: 0.3236066\ttotal: 2m 36s\tremaining: 12.7s\n",
            "925:\tlearn: 0.3230129\ttotal: 2m 36s\tremaining: 12.5s\n",
            "926:\tlearn: 0.3229638\ttotal: 2m 36s\tremaining: 12.3s\n",
            "927:\tlearn: 0.3227034\ttotal: 2m 36s\tremaining: 12.2s\n",
            "928:\tlearn: 0.3225487\ttotal: 2m 37s\tremaining: 12s\n",
            "929:\tlearn: 0.3224518\ttotal: 2m 37s\tremaining: 11.8s\n",
            "930:\tlearn: 0.3223149\ttotal: 2m 37s\tremaining: 11.7s\n",
            "931:\tlearn: 0.3221925\ttotal: 2m 37s\tremaining: 11.5s\n",
            "932:\tlearn: 0.3220524\ttotal: 2m 37s\tremaining: 11.3s\n",
            "933:\tlearn: 0.3220030\ttotal: 2m 37s\tremaining: 11.2s\n",
            "934:\tlearn: 0.3219513\ttotal: 2m 38s\tremaining: 11s\n",
            "935:\tlearn: 0.3218502\ttotal: 2m 38s\tremaining: 10.8s\n",
            "936:\tlearn: 0.3217295\ttotal: 2m 38s\tremaining: 10.7s\n",
            "937:\tlearn: 0.3215386\ttotal: 2m 38s\tremaining: 10.5s\n",
            "938:\tlearn: 0.3214697\ttotal: 2m 39s\tremaining: 10.3s\n",
            "939:\tlearn: 0.3214020\ttotal: 2m 39s\tremaining: 10.2s\n",
            "940:\tlearn: 0.3213210\ttotal: 2m 39s\tremaining: 10s\n",
            "941:\tlearn: 0.3211595\ttotal: 2m 39s\tremaining: 9.83s\n",
            "942:\tlearn: 0.3209797\ttotal: 2m 39s\tremaining: 9.66s\n",
            "943:\tlearn: 0.3209320\ttotal: 2m 40s\tremaining: 9.5s\n",
            "944:\tlearn: 0.3205846\ttotal: 2m 40s\tremaining: 9.33s\n",
            "945:\tlearn: 0.3205072\ttotal: 2m 40s\tremaining: 9.16s\n",
            "946:\tlearn: 0.3202575\ttotal: 2m 40s\tremaining: 8.99s\n",
            "947:\tlearn: 0.3201628\ttotal: 2m 40s\tremaining: 8.83s\n",
            "948:\tlearn: 0.3200888\ttotal: 2m 41s\tremaining: 8.66s\n",
            "949:\tlearn: 0.3200406\ttotal: 2m 41s\tremaining: 8.49s\n",
            "950:\tlearn: 0.3199378\ttotal: 2m 41s\tremaining: 8.32s\n",
            "951:\tlearn: 0.3198359\ttotal: 2m 41s\tremaining: 8.16s\n",
            "952:\tlearn: 0.3196956\ttotal: 2m 42s\tremaining: 7.99s\n",
            "953:\tlearn: 0.3196037\ttotal: 2m 42s\tremaining: 7.83s\n",
            "954:\tlearn: 0.3195057\ttotal: 2m 42s\tremaining: 7.66s\n",
            "955:\tlearn: 0.3193539\ttotal: 2m 42s\tremaining: 7.49s\n",
            "956:\tlearn: 0.3191849\ttotal: 2m 42s\tremaining: 7.32s\n",
            "957:\tlearn: 0.3190662\ttotal: 2m 43s\tremaining: 7.15s\n",
            "958:\tlearn: 0.3190168\ttotal: 2m 43s\tremaining: 6.98s\n",
            "959:\tlearn: 0.3189374\ttotal: 2m 43s\tremaining: 6.81s\n",
            "960:\tlearn: 0.3188887\ttotal: 2m 43s\tremaining: 6.64s\n",
            "961:\tlearn: 0.3188380\ttotal: 2m 43s\tremaining: 6.47s\n",
            "962:\tlearn: 0.3187309\ttotal: 2m 43s\tremaining: 6.3s\n",
            "963:\tlearn: 0.3181981\ttotal: 2m 44s\tremaining: 6.13s\n",
            "964:\tlearn: 0.3179044\ttotal: 2m 44s\tremaining: 5.96s\n",
            "965:\tlearn: 0.3175188\ttotal: 2m 44s\tremaining: 5.79s\n",
            "966:\tlearn: 0.3173871\ttotal: 2m 44s\tremaining: 5.62s\n",
            "967:\tlearn: 0.3172323\ttotal: 2m 44s\tremaining: 5.45s\n",
            "968:\tlearn: 0.3171866\ttotal: 2m 44s\tremaining: 5.28s\n",
            "969:\tlearn: 0.3170847\ttotal: 2m 45s\tremaining: 5.11s\n",
            "970:\tlearn: 0.3169748\ttotal: 2m 45s\tremaining: 4.94s\n",
            "971:\tlearn: 0.3167581\ttotal: 2m 45s\tremaining: 4.77s\n",
            "972:\tlearn: 0.3165368\ttotal: 2m 45s\tremaining: 4.6s\n",
            "973:\tlearn: 0.3164424\ttotal: 2m 45s\tremaining: 4.43s\n",
            "974:\tlearn: 0.3163415\ttotal: 2m 46s\tremaining: 4.26s\n",
            "975:\tlearn: 0.3162409\ttotal: 2m 46s\tremaining: 4.09s\n",
            "976:\tlearn: 0.3161796\ttotal: 2m 46s\tremaining: 3.92s\n",
            "977:\tlearn: 0.3159752\ttotal: 2m 46s\tremaining: 3.75s\n",
            "978:\tlearn: 0.3157217\ttotal: 2m 46s\tremaining: 3.58s\n",
            "979:\tlearn: 0.3155389\ttotal: 2m 46s\tremaining: 3.4s\n",
            "980:\tlearn: 0.3154724\ttotal: 2m 47s\tremaining: 3.23s\n",
            "981:\tlearn: 0.3153085\ttotal: 2m 47s\tremaining: 3.06s\n",
            "982:\tlearn: 0.3150370\ttotal: 2m 47s\tremaining: 2.89s\n",
            "983:\tlearn: 0.3149892\ttotal: 2m 47s\tremaining: 2.72s\n",
            "984:\tlearn: 0.3149414\ttotal: 2m 47s\tremaining: 2.55s\n",
            "985:\tlearn: 0.3148665\ttotal: 2m 47s\tremaining: 2.38s\n",
            "986:\tlearn: 0.3143960\ttotal: 2m 47s\tremaining: 2.21s\n",
            "987:\tlearn: 0.3143496\ttotal: 2m 48s\tremaining: 2.04s\n",
            "988:\tlearn: 0.3142456\ttotal: 2m 48s\tremaining: 1.87s\n",
            "989:\tlearn: 0.3140572\ttotal: 2m 48s\tremaining: 1.7s\n",
            "990:\tlearn: 0.3139852\ttotal: 2m 48s\tremaining: 1.53s\n",
            "991:\tlearn: 0.3138298\ttotal: 2m 48s\tremaining: 1.36s\n",
            "992:\tlearn: 0.3137251\ttotal: 2m 48s\tremaining: 1.19s\n",
            "993:\tlearn: 0.3135739\ttotal: 2m 49s\tremaining: 1.02s\n",
            "994:\tlearn: 0.3134020\ttotal: 2m 49s\tremaining: 850ms\n",
            "995:\tlearn: 0.3131195\ttotal: 2m 49s\tremaining: 680ms\n",
            "996:\tlearn: 0.3130732\ttotal: 2m 49s\tremaining: 510ms\n",
            "997:\tlearn: 0.3130307\ttotal: 2m 49s\tremaining: 340ms\n",
            "998:\tlearn: 0.3129171\ttotal: 2m 49s\tremaining: 170ms\n",
            "999:\tlearn: 0.3128245\ttotal: 2m 50s\tremaining: 0us\n",
            "교차 검증별 정확도: [0.7555 0.7804]\n",
            "평균 검증 정확도: 0.7679\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "cb = CatBoostClassifier(class_weights= class_weights, bootstrap_type= 'MVS', #['Bayesian', 'Bernoulli', 'MVS']\n",
        "                     )\n",
        "# cb = CatBoostClassifier(learning_rate= 0.03, max_depth= 10, n_estimators= 1000, class_weights= class_weights, bootstrap_type= 'MVS', #['Bayesian', 'Bernoulli', 'MVS']\n",
        "#                      subsample = 0.8, colsample_bylevel=1.0, random_state=42, verbose =0)\n",
        "\n",
        "# 성능 지표는 정확도(accuracy) , 교차 검증 세트는 5개 \n",
        "scores = cross_val_score(cb , X_train_tfidf_vect, y_train, scoring='accuracy',cv=2)\n",
        "\n",
        "print('교차 검증별 정확도:',np.round(scores, 4))\n",
        "print('평균 검증 정확도:', np.round(np.mean(scores),4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAKgRHmuisqE"
      },
      "source": [
        "### Model4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vABSrFNYiuvL",
        "outputId": "cbade242-8a1f-43eb-b91a-15d8e0b85bc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "교차 검증별 정확도: [0.7884 0.7692 0.7395 0.7787 0.7638]\n",
            "평균 검증 정확도: 0.7679\n"
          ]
        }
      ],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "\n",
        "lgbm = LGBMClassifier()\n",
        "\n",
        "\n",
        "# 성능 지표는 정확도(accuracy) , 교차 검증 세트는 5개 \n",
        "scores = cross_val_score(lgbm , X_train_tfidf_vect, y_train, scoring='accuracy',cv=5)\n",
        "\n",
        "print('교차 검증별 정확도:',np.round(scores, 4))\n",
        "print('평균 검증 정확도:', np.round(np.mean(scores),4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5OK2Ms3jXfL"
      },
      "source": [
        "### Model5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOob7JmmjYii",
        "outputId": "7e8e6b63-dbfa-4d26-cc8e-3bec0419ab4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "교차 검증별 정확도: [0.8423 0.8205 0.8043 0.8165 0.8273]\n",
            "평균 검증 정확도: 0.8222\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "\n",
        "svc = svm.SVC(kernel = 'linear', C= 10) #{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}\n",
        "\n",
        "# 성능 지표는 정확도(accuracy) , 교차 검증 세트는 5개 \n",
        "scores = cross_val_score(svc , X_train_tfidf_vect, y_train, scoring='accuracy',cv=5)\n",
        "\n",
        "print('교차 검증별 정확도:',np.round(scores, 4))\n",
        "print('평균 검증 정확도:', np.round(np.mean(scores),4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuQBdo7iOr_P"
      },
      "source": [
        "### 3-4. Hyperparameter Tuning(Optional) \n",
        "* Manual Search, Grid search, Bayesian Optimization, TPE...\n",
        "> * [grid search tutorial sklearn](https://scikit-learn.org/stable/modules/grid_search.html)\n",
        "> * [optuna tutorial](https://optuna.org/#code_examples)\n",
        "> * [ray-tune tutorial](https://docs.ray.io/en/latest/tune/examples/tune-sklearn.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALZtPFrIOr_P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ourku94TOr_P"
      },
      "source": [
        "## 4. Deep Learning(Sequence)\n",
        "* Sequence로 전처리한 데이터를 이용하여 DNN, 1-D CNN, LSTM 등 3가지 이상의 deep learning 모델 학습 및 성능 분석\n",
        "> * [Google Tutorial](https://developers.google.com/machine-learning/guides/text-classification)\n",
        "> * [Tensorflow Tutorial](https://www.tensorflow.org/tutorials/keras/text_classification)\n",
        "> * [Keras-tutorial](https://keras.io/examples/nlp/text_classification_from_scratch/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN2BPRX9Or_P"
      },
      "source": [
        "### 4-1. DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "ACElQbm5Or_Q"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhJV_cFG4f--",
        "outputId": "4c83ff3a-ebfd-4e52-d74a-776c93b90640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "최대 길이 : 6675\n"
          ]
        }
      ],
      "source": [
        "str_len_max = np.max(X_train.str.len()) # 리뷰 길이의 최대값 계산\n",
        "print('최대 길이 :',round(str_len_max))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0FPA9UnC3s0",
        "outputId": "05f2bd62-7acf-45ce-8751-8772e69b156e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "평균 길이 : 218\n"
          ]
        }
      ],
      "source": [
        "str_len_mean = np.mean(X_train.str.len()) # 리뷰 길이의 평균값 계산\n",
        "print('평균 길이 :',round(str_len_mean))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "N5IjSmkv3yMW"
      },
      "outputs": [],
      "source": [
        "max_words = 6675 #3987 ## 위에서 40,000으로 설정함\n",
        "embedding_dim = 128 ## 단어 embedding 지원. 단어 하나당 몇 개의 특징값을 학습할 것인가\n",
        "max_len = 80 ## 문장 최대 길이"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "m5DPNQ1kjKuG"
      },
      "outputs": [],
      "source": [
        "### Tokenizer here\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=max_words, lower=False)  # lower (대문자->소문자) 옵션은 한국어를 할땐 끄자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKGPOSvbjNLS",
        "outputId": "0d801a51-353f-4192-be7e-0e5a55ba47da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 367 ms, sys: 37 µs, total: 367 ms\n",
            "Wall time: 366 ms\n"
          ]
        }
      ],
      "source": [
        "# Text --> Sequence\n",
        "%%time\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "-iBihn7h3yfy"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "#### Pad Sequences here\n",
        "X_train = pad_sequences(X_train, maxlen = max_len)\n",
        "X_test = pad_sequences(X_test, maxlen = max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzhIKC8L5aCm",
        "outputId": "d594908e-aaa2-4581-eadb-a9f4b0ab6d3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3706, 80)"
            ]
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "S8vyyZ_c3lKh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Conv1D, Bidirectional, LSTM, GRU, RNN, MaxPool1D, Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOnfhi4Q5vwv",
        "outputId": "fafb4da4-a38c-442b-f5ce-b97d3a16fe48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQtdswD5w9MI",
        "outputId": "0647e97f-e51b-4358-f6f0-e30cb8164016"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 80)]              0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 80, 128)           854400    \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 76, 64)            41024     \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 76, 64)           24832     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 76, 48)           14592     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 72, 32)            7712      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 36, 32)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1152)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              1180672   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 5125      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,128,357\n",
            "Trainable params: 2,128,357\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#####################\n",
        "# 1. 세션 초기화\n",
        "clear_session()\n",
        "\n",
        "# 2. 모델 사슬처럼 엮기\n",
        "il = Input(shape=(X_train.shape[1],))\n",
        "\n",
        "# 1. 임베딩 레이어 : 임베딩차원은 128\n",
        "el = Embedding(max_words,\n",
        "               embedding_dim,\n",
        "               input_length=max_len)(il)\n",
        "\n",
        "# 2. Conv1D 블록 : 필터수 64개, 윈도우 사이즈 5\n",
        "hl1 = Conv1D(filters=64,\n",
        "             kernel_size=5,\n",
        "             activation='swish')(el)\n",
        "# 3. Bidirectional layer :\n",
        "#     * 정방향 : LSTM, 히든스테이트 32 \n",
        "#     * 역방향 : LSTM, 히든스테이트 32\n",
        "lstm32 = LSTM(32, return_sequences=True)\n",
        "hl2 = Bidirectional(lstm32)(hl1)\n",
        "# 4. Bidirectional layer :\n",
        "#     * 정방향 : GRU, 히든스테이트 32\n",
        "#     * 역방향 : RNN, 히든스테이트 16\n",
        "forward_gru32 = GRU(32, return_sequences=True)\n",
        "backward_lstm16 = LSTM(16, return_sequences=True, go_backwards=True)\n",
        "hl3 = Bidirectional(forward_gru32, backward_layer=backward_lstm16)(hl2)\n",
        "# 5. Conv1D 블록 : 필터수 32개, 윈도우 사이즈 5\n",
        "hl4 = Conv1D(filters=32,\n",
        "             kernel_size=5,\n",
        "             activation='swish')(hl3)\n",
        "# 6. MaxPool1D 블록 : 필터사이즈2\n",
        "hl5 = MaxPool1D(pool_size=2)(hl4)\n",
        "# 7. 플래튼\n",
        "hl6 = Flatten()(hl5)\n",
        "# 8. FC Layer : 노드 1024개\n",
        "hl7 = Dense(1024, activation='relu')(hl6)\n",
        "# 9. 시그모이드 레이어\n",
        "ol = Dense(5, activation='softmax')(hl7)\n",
        "\n",
        "# 3. 모델 처음과 끝 지정\n",
        "model = Model(il, ol)\n",
        "\n",
        "# 4. 컴파일\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics='accuracy')\n",
        "\n",
        "# 요약\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKCYQ64YIhrl"
      },
      "source": [
        "* Using pre-trained word Embedding  \n",
        "* 남이 사용한 임베딩을 가져와 임베딩하기\n",
        "* GloVe, Word2Vec 등..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWFMADk8zF6I"
      },
      "source": [
        "# EarlyStopping을 이용한 학습.\n",
        "\n",
        "1. 20%는 벨리데이션 셋.\n",
        "2. 4epochs전과 비교하여 early stopping할 것."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "E3JY2jVS9FMY"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "2Fz2nd66qN-0"
      },
      "outputs": [],
      "source": [
        "#####################\n",
        "es = EarlyStopping(monitor='val_accuracy',\n",
        "                   min_delta=0,\n",
        "                   patience=10,\n",
        "                   verbose=1,\n",
        "                   restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "Lw9OxB5k7i_8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_ctg = to_categorical(y_train)\n",
        "#y_val_ctg = to_categorical(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEdHu9r-8aaT",
        "outputId": "785ae96a-caaf-484f-bb62-4d9c9773f660"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3706, 5)"
            ]
          },
          "execution_count": 193,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_ctg.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT1v-SJA8cf9",
        "outputId": "47a565df-55ea-4ec5-b5e0-d2cf36fcec51"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3706, 80)"
            ]
          },
          "execution_count": 194,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEtaBP6J9pgI",
        "outputId": "1629d456-8c1e-49ca-e263-aa55e33ccc70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 195,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_ctg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBvUETNgqQgm",
        "outputId": "d26fb273-b544-4560-8669-22dca112e08a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "93/93 [==============================] - 25s 160ms/step - loss: 1.1205 - accuracy: 0.5236 - val_loss: 0.9472 - val_accuracy: 0.6226\n",
            "Epoch 2/30\n",
            "93/93 [==============================] - 10s 105ms/step - loss: 0.6296 - accuracy: 0.7564 - val_loss: 0.7099 - val_accuracy: 0.7278\n",
            "Epoch 3/30\n",
            "93/93 [==============================] - 7s 74ms/step - loss: 0.3020 - accuracy: 0.8880 - val_loss: 0.6885 - val_accuracy: 0.7844\n",
            "Epoch 4/30\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.1649 - accuracy: 0.9423 - val_loss: 0.8544 - val_accuracy: 0.7749\n",
            "Epoch 5/30\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.1455 - accuracy: 0.9545 - val_loss: 1.0341 - val_accuracy: 0.7857\n",
            "Epoch 6/30\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 0.0932 - accuracy: 0.9703 - val_loss: 1.1963 - val_accuracy: 0.7790\n",
            "Epoch 7/30\n",
            "93/93 [==============================] - 3s 36ms/step - loss: 0.0394 - accuracy: 0.9906 - val_loss: 1.5024 - val_accuracy: 0.7951\n",
            "Epoch 8/30\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.0309 - accuracy: 0.9902 - val_loss: 1.4508 - val_accuracy: 0.7844\n",
            "Epoch 9/30\n",
            "93/93 [==============================] - 2s 22ms/step - loss: 0.0228 - accuracy: 0.9939 - val_loss: 1.5575 - val_accuracy: 0.7925\n",
            "Epoch 10/30\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.0163 - accuracy: 0.9966 - val_loss: 1.4845 - val_accuracy: 0.8073\n",
            "Epoch 11/30\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.8899 - val_accuracy: 0.8005\n",
            "Epoch 12/30\n",
            "93/93 [==============================] - 2s 23ms/step - loss: 5.9422e-04 - accuracy: 1.0000 - val_loss: 2.0860 - val_accuracy: 0.7965\n",
            "Epoch 13/30\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 2.3428e-04 - accuracy: 1.0000 - val_loss: 2.1387 - val_accuracy: 0.7938\n",
            "Epoch 14/30\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 1.3388e-04 - accuracy: 1.0000 - val_loss: 2.1794 - val_accuracy: 0.8005\n",
            "Epoch 15/30\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 9.5775e-05 - accuracy: 1.0000 - val_loss: 2.2175 - val_accuracy: 0.7992\n",
            "Epoch 16/30\n",
            "93/93 [==============================] - 2s 22ms/step - loss: 7.2950e-05 - accuracy: 1.0000 - val_loss: 2.2543 - val_accuracy: 0.7978\n",
            "Epoch 17/30\n",
            "93/93 [==============================] - 2s 22ms/step - loss: 6.0307e-05 - accuracy: 1.0000 - val_loss: 2.2877 - val_accuracy: 0.7978\n",
            "Epoch 18/30\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 4.8568e-05 - accuracy: 1.0000 - val_loss: 2.3180 - val_accuracy: 0.7965\n",
            "Epoch 19/30\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 4.0936e-05 - accuracy: 1.0000 - val_loss: 2.3430 - val_accuracy: 0.7965\n",
            "Epoch 20/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 3.4852e-05 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 10.\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 3.4852e-05 - accuracy: 1.0000 - val_loss: 2.3708 - val_accuracy: 0.7965\n",
            "Epoch 20: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbad1b91610>"
            ]
          },
          "execution_count": 196,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#####################\n",
        "model.fit(X_train, y_train_ctg, epochs=30, verbose=1, callbacks=[es], validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUWAir6nq886",
        "outputId": "031d3c1e-92e5-4dfc-806e-d27592ac335c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30/30 [==============================] - 1s 9ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9VzkgHA_kbW",
        "outputId": "d622829f-042e-4f54-f05c-7fab7dc9f085"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3, 3, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 2, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 2,\n",
              "       0, 0, 3, 0, 0, 1, 2, 0, 1, 0, 2, 0, 1, 0, 0, 3, 0, 0, 1, 0, 0, 0,\n",
              "       0, 3, 0, 2, 3, 0, 0, 2, 0, 0, 4, 3, 0, 2, 0, 0, 2, 0, 0, 0, 0, 3,\n",
              "       3, 2, 0, 3, 0, 0, 2, 0, 2, 0, 2, 0, 2, 3, 0, 3, 3, 0, 0, 0, 2, 0,\n",
              "       0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0, 1, 0, 0, 0, 3,\n",
              "       3, 3, 0, 0, 0, 1, 1, 3, 0, 0, 3, 4, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3,\n",
              "       0, 1, 0, 2, 2, 2, 0, 0, 0, 2, 2, 0, 0, 1, 2, 2, 0, 0, 0, 0, 3, 0,\n",
              "       2, 2, 2, 2, 0, 2, 2, 0, 0, 1, 2, 0, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 3, 2, 2, 3, 0, 2, 0, 3, 3, 1, 2, 2, 0, 0, 3, 2, 3, 0, 3,\n",
              "       2, 0, 2, 1, 2, 0, 2, 0, 0, 0, 4, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 2, 0, 1, 0, 2, 0, 0, 0, 2, 3, 0,\n",
              "       4, 1, 0, 0, 0, 0, 0, 3, 0, 0, 1, 1, 0, 0, 4, 3, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 3, 3, 2, 0, 3, 0, 2, 3, 0, 3, 0, 0, 0, 4, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 3, 0, 3, 0, 0, 2, 0, 0, 2, 3, 3, 2, 2, 2, 3, 2, 0, 1,\n",
              "       0, 0, 4, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0,\n",
              "       3, 2, 2, 0, 0, 0, 2, 0, 2, 3, 0, 0, 2, 3, 2, 2, 0, 3, 0, 0, 2, 0,\n",
              "       0, 2, 0, 0, 0, 2, 3, 2, 0, 2, 2, 2, 0, 3, 2, 0, 0, 1, 2, 2, 2, 2,\n",
              "       2, 0, 2, 2, 2, 2, 0, 2, 2, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 3, 3, 1, 0, 0, 2, 1, 1, 1, 0, 1, 1, 2, 0, 1, 2, 0, 0, 1,\n",
              "       2, 0, 0, 0, 0, 3, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0,\n",
              "       2, 0, 0, 0, 0, 2, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 0, 0, 0, 0,\n",
              "       0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 4, 3, 0, 2, 4, 3, 3, 0, 4, 0, 0,\n",
              "       3, 0, 0, 0, 2, 3, 2, 0, 1, 1, 2, 1, 1, 0, 3, 1, 0, 1, 1, 3, 2, 1,\n",
              "       1, 3, 3, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0,\n",
              "       3, 0, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 1, 3, 1, 1, 1, 3, 1, 1,\n",
              "       1, 1, 3, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 3, 1, 1, 1, 3, 1,\n",
              "       3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 3, 1, 0,\n",
              "       2, 2, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 3, 1, 1, 1, 1, 1,\n",
              "       1, 2, 1, 1, 1, 0, 1, 1, 4, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 2, 1, 0, 2, 1, 1, 0, 2, 2, 2, 2, 0, 1, 0, 1, 2, 0, 0, 0,\n",
              "       4, 1, 1, 1, 0, 1, 1, 3, 1, 3, 2, 3, 1, 2, 2, 1, 0, 0, 1, 0, 3, 2,\n",
              "       2, 3, 0, 1, 3, 3, 0, 2, 0, 3, 3, 3, 3, 2, 3, 0, 3, 0, 3, 3, 0, 0,\n",
              "       0, 0, 0, 1, 2, 2, 1, 1, 1, 2, 4, 1, 0, 0, 0, 3, 3, 1, 1, 1, 3, 1,\n",
              "       1, 2, 4, 3, 1, 1, 2, 3, 1, 1, 2, 2, 2, 2, 2, 1, 3, 2, 2, 1, 1, 1,\n",
              "       1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 1, 2, 0, 1, 1, 2, 2, 2, 1, 1,\n",
              "       1, 2, 2, 2, 3, 2, 1, 3, 1, 3, 3, 1, 4, 1, 2, 2, 2, 2, 2, 0, 2, 2,\n",
              "       2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 3, 2, 3, 0, 3, 1, 3, 1, 1, 1, 1, 0,\n",
              "       1, 1, 2, 3, 3, 4, 1, 1, 3, 0, 1, 0, 0, 1, 3, 0, 1, 3, 3, 3, 1, 1,\n",
              "       0, 2, 1, 0, 0, 0, 1, 1, 3, 0, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       3, 0, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 0, 1, 1, 1, 3, 0, 1, 1,\n",
              "       1, 2, 1, 1, 1, 1, 3, 1, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 0, 3, 1, 1])"
            ]
          },
          "execution_count": 199,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.argmax(y_pred, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "En_63NEcm7wW"
      },
      "outputs": [],
      "source": [
        "submission['label'] = np.argmax(y_pred, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "a6vGort3m7wW",
        "outputId": "40707ed9-55a7-4e11-e4a4-09ba72bb0b0d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b10aab34-2fe0-4098-8799-e95ab03c0196\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>924</th>\n",
              "      <td>924</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>925</th>\n",
              "      <td>925</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>926</th>\n",
              "      <td>926</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>927</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>928</th>\n",
              "      <td>928</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>929 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b10aab34-2fe0-4098-8799-e95ab03c0196')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b10aab34-2fe0-4098-8799-e95ab03c0196 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b10aab34-2fe0-4098-8799-e95ab03c0196');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      id  label\n",
              "0      0      3\n",
              "1      1      3\n",
              "2      2      0\n",
              "3      3      0\n",
              "4      4      2\n",
              "..   ...    ...\n",
              "924  924      3\n",
              "925  925      0\n",
              "926  926      3\n",
              "927  927      1\n",
              "928  928      1\n",
              "\n",
              "[929 rows x 2 columns]"
            ]
          },
          "execution_count": 203,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "id": "n3-O7uENm7wX"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('world_submission_3.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLicKxu4_1rQ",
        "outputId": "4d9c2686-9ad9-432a-a82c-52e464e7044b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    코드1,2(0)       0.78      0.85      0.81       462\n",
            "        웹(1)       0.50      0.54      0.52       217\n",
            "       이론(2)       0.52      0.59      0.55       239\n",
            "    시스템운영(3)       0.78      0.43      0.55       162\n",
            "       원격(4)       0.56      0.31      0.40        32\n",
            "\n",
            "    accuracy                           0.66      1112\n",
            "   macro avg       0.63      0.54      0.57      1112\n",
            "weighted avg       0.66      0.66      0.65      1112\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "y = y_val\n",
        "p = np.argmax(y_pred, axis=1)\n",
        "\n",
        "target_names = ['코드1,2(0)', '웹(1)', '이론(2)', '시스템운영(3)', '원격(4)']\n",
        "\n",
        "label_dict = {\n",
        "    '코드1': 0,\n",
        "    '코드2': 0,\n",
        "    '웹': 1,\n",
        "    '이론': 2,\n",
        "    '시스템 운영': 3,\n",
        "    '원격': 4\n",
        "}\n",
        "\n",
        "preprocessed_df = train.replace({'label' : label_dict}).copy()\n",
        "\n",
        "print(classification_report(y, p, \n",
        "                            target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yz2TELOBZL6",
        "outputId": "c8620dcc-5314-45d6-887b-e516f1c798a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy   : 0.656\n",
            "Precision  : 0.781\n",
            "Recall     : 0.848\n",
            "Specificyty: 0.544\n",
            "F1-Score   : 0.813\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "## performance metrics\n",
        "accuracy = accuracy_score(y, p)\n",
        "\n",
        "precision, recall, fscore, support = \\\n",
        "    precision_recall_fscore_support(y, p)\n",
        "\n",
        "print('Accuracy   : %.3f' %accuracy) # (102+164)/(102+16+3+164)\n",
        "print('Precision  : %.3f' %precision[0]) # 102/(102+3)\n",
        "print('Recall     : %.3f' %recall[0]) # 102/(102+16)\n",
        "print('Specificyty: %.3f' %recall[1]) # 164/(3+164)\n",
        "print('F1-Score   : %.3f' %fscore[0]) # 2/(1/precision + 1/recall) = 2/(1/0.971+1/0.864)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HH2D-nJOr_Q"
      },
      "source": [
        "### 4-2. 1-D CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnKAt_kdOr_Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylUnaqCLOr_Q"
      },
      "source": [
        "### 4-3. LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_Lha3VPOr_Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDXHj9FxOr_Q"
      },
      "source": [
        "## 5. Using pre-trained model(Optional)\n",
        "* 한국어 pre-trained model로 fine tuning 및 성능 분석\n",
        "> * [BERT-tutorial](https://www.tensorflow.org/text/guide/bert_preprocessing_guide)\n",
        "> * [HuggingFace-Korean](https://huggingface.co/models?language=korean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLTB4E3wOr_R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
